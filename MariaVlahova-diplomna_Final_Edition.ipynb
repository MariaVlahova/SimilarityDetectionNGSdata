{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"********************Methods*********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leveshteinDistance(s1, s2):\n",
    "    \"\"\"Computes the Levenshtein distance between two arrays (strings too).\n",
    "    Such distance is the minimum number of operations needed to transform one array into\n",
    "    the other, where an operation is an insertion, deletion, or substitution of a single\n",
    "    item (like a char). This implementation (Wagner-Fischer algorithm with just 2 lines)\n",
    "    uses O(min(|s1|, |s2|)) space.\n",
    "    \"\"\"\n",
    "    if s1 == s2: return 0\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    r1 = list(range(len(s2) + 1))\n",
    "    r2 = [0] * len(r1)\n",
    "    i = 0\n",
    "    for c1 in s1:\n",
    "        r2[0] = i + 1\n",
    "        j = 0\n",
    "        for c2 in s2:\n",
    "            if c1 == c2:\n",
    "                r2[j+1] = r1[j]\n",
    "            else:\n",
    "                a1 = r2[j]\n",
    "                a2 = r1[j]\n",
    "                a3 = r1[j+1]\n",
    "                if a1 > a2:\n",
    "                    if a2 > a3:\n",
    "                        r2[j+1] = 1 + a3\n",
    "                    else:\n",
    "                        r2[j+1] = 1 + a2\n",
    "                else:\n",
    "                    if a1 > a3:\n",
    "                        r2[j+1] = 1 + a3\n",
    "                    else:\n",
    "                        r2[j+1] = 1 + a1\n",
    "            j += 1\n",
    "        aux = r1; r1 = r2; r2 = aux\n",
    "        i += 1\n",
    "    return r1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''if both seq are the same the score will be 0'''\n",
    "def rankDistance(seq1,seq2):\n",
    "    score=0\n",
    "    seq1_arr=list(seq1)\n",
    "    seq2_arr=list(seq2)\n",
    "\n",
    "    for i in range(len(seq1_arr)):\n",
    "        index=seq2_arr.index(seq1_arr[i]) if seq1_arr[i] in seq2_arr else 0\n",
    "        score=score+abs(i-index)\n",
    "        seq1_arr[i]='*'\n",
    "        seq2_arr[index]='*'\n",
    "    if(seq1_arr==seq2_arr):\n",
    "        for i in range(len(seq1_arr)):\n",
    "            j= i if seq1_arr[i]!='*' else 0\n",
    "            score=score+j\n",
    "            k= -i if seq2_arr[i]!='*' else 0\n",
    "            score=score+j\n",
    "    else:\n",
    "        for i in range(len(seq1_arr)):\n",
    "            j= i if seq1_arr[i]!='*' else 0\n",
    "            score=score+j\n",
    "        for i in range(len(seq2_arr)):\n",
    "            j= i if seq2_arr[i]!='*' else 0\n",
    "            score=score+j\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#localAlighnment\n",
    "'''\n",
    "for the calculation is used bio python\n",
    "gap_open_penalty and gap_extend_penalty neeed to have negative value\n",
    "'''\n",
    "def local_alighn_score(seq1,seq2,gap_open_penalty,gap_extend_penalty):\n",
    "    from Bio import pairwise2\n",
    "    from Bio.SubsMat.MatrixInfo import blosum62\n",
    "    a = pairwise2.align.localds(seq1, seq2, blosum62, gap_open_penalty,gap_extend_penalty)\n",
    "    (s1,s2,score,start,end) = a[0]\n",
    "    gaps=s1.count(\"-\")+s2.count(\"-\")\n",
    "    return score,gaps;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globalAlighnment\n",
    "'''\n",
    "for the calculation is used bio python\n",
    "gap_open_penalty and gap_extend_penalty neeed to have negative value\n",
    "'''\n",
    "def global_alighn_score(seq1,seq2,gap_open_penalty,gap_extend_penalty):\n",
    "    from Bio.SubsMat import MatrixInfo as matlist\n",
    "    from Bio import pairwise2\n",
    "    matrix = matlist.blosum62\n",
    "    a = pairwise2.align.globalds(seq1,seq2,matrix,gap_open_penalty,gap_extend_penalty)\n",
    "    (s1,s2,score,start,end) = a[0]\n",
    "    gaps=s1.count(\"-\")+s2.count(\"-\")\n",
    "    return score,gaps;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(global_alighn_score,local_alighn_score):\n",
    "    if(global_alighn_score > local_alighn_score):\n",
    "        return global_alighn_score\n",
    "    else:\n",
    "        return local_alighn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation(N,ratioComp): \n",
    "    import math\n",
    "    import time\n",
    "    from functools import reduce\n",
    "    mean=ratioComp.similarity.sum()/N\n",
    "    sum1=reduce(lambda x: (x -mean) / 2, ratioComp.similarity)\n",
    "    stand_dev=math.sqrt(pow(sum1, 2)/N)\n",
    "    signalToNoise=mean/stand_dev\n",
    "    for x in ratioComp:\n",
    "        x.mean=mean\n",
    "        x.standart_dev=standart_dev\n",
    "        x.signalToNoise=signalToNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The center star method'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitutionCost(a, b):\n",
    "    import numpy\n",
    "    import pandas\n",
    "    \"\"\"Return the cost of substituting character a with character b\"\"\"\n",
    "    return 0 if a == b else 3\n",
    "\n",
    "def calculateCostMatrix(a, b, gapCost=2):\n",
    "    import numpy\n",
    "    import pandas\n",
    "    \"\"\"For two sequences a, b, calculate their edit distance matrix\"\"\"\n",
    "    #Initialize n+1 x m+1 matrix. x axis <--> a, y axis <--> b\n",
    "    xdim = len(b) + 1\n",
    "    ydim = len(a) + 1\n",
    "    matrix = numpy.zeros((xdim, ydim))\n",
    "    #Initialize first row and first col with n*gap cost\n",
    "    matrix[0,:] = numpy.arange(0, gapCost*ydim, step=gapCost)\n",
    "    matrix[:,0] = numpy.arange(0, gapCost*xdim, step=gapCost)\n",
    "    #Fill array\n",
    "    for y in range(1, ydim):\n",
    "        for x in range(1, xdim):\n",
    "            substCost = matrix[x-1, y-1] + substitutionCost(b[x-1], a[y-1])\n",
    "            matrix[x,y] = min(substCost, matrix[x-1, y] + gapCost, matrix[x, y-1] + gapCost)\n",
    "    return matrix\n",
    "\n",
    "def getCentralStarDistance(a, b, gapCost=2):\n",
    "    import numpy\n",
    "    import pandas\n",
    "    \"\"\"Get the edit distance of two sequences a and b\"\"\"\n",
    "    return calculateCostMatrix(a, b, gapCost)[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regressor to predict global alighnement score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''naighbourhood count'''\n",
    "def word_neighborhood_count_score(seq1, seq2):\n",
    "    score = 0\n",
    "    W=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]\n",
    "    # for each base in the match\n",
    "    for i in range(0,len(seq1)):\n",
    "        counter=0\n",
    "        start=i\n",
    "        end=i+9\n",
    "        seq1_len=len(seq1)-1\n",
    "        seq2_len=len(seq2)-1\n",
    "        while start < end:\n",
    "            if(start >= seq1_len or start >= seq2_len):\n",
    "                score = score - W[counter]\n",
    "            elif(seq1[i] == seq2[i+counter]):\n",
    "                score = score + W[counter] \n",
    "                break\n",
    "            else:\n",
    "                score = score - W[counter]\n",
    "            counter = counter + 1\n",
    "            start=start+1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher \n",
    "  \n",
    "def longestSubstring(str1,str2): \n",
    "    seqMatch = SequenceMatcher(None,str1,str2) \n",
    "    match = seqMatch.find_longest_match(0, len(str1), 0, len(str2)) \n",
    "    return match.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************Data Structures******************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetInfo:\n",
    "    def __init__(self,first_org_name,second_org_name,chunk_index_first_org,chunk_index_second_org,first_chunk_value,second_chunk_value,\n",
    "                global_alighn_score,global_alighn_gap,local_alighn_score,local_alighn_gap,similarity,\n",
    "                 word_count_score,longest_seq,rank_distance,levenshtein_distance,central_star_distance):\n",
    "        self.first_org_name = first_org_name\n",
    "        self.second_org_name = second_org_name\n",
    "        self.chunk_index_first_org = chunk_index_first_org\n",
    "        self.chunk_index_second_org  = chunk_index_second_org\n",
    "        self.first_chunk_value = first_chunk_value\n",
    "        self.second_chunk_value = second_chunk_value\n",
    "        #alighnment based\n",
    "        self.global_alighn_score = global_alighn_score\n",
    "        self.global_alighn_gap=global_alighn_gap\n",
    "        self.local_alighn_score = local_alighn_score\n",
    "        self.local_alighn_gap=local_alighn_gap\n",
    "        self.similarity = similarity\n",
    "        #alignment_free\n",
    "        self.word_count_score = word_count_score\n",
    "        self.longest_seq = longest_seq \n",
    "        self.rank_distance = rank_distance \n",
    "        self.levenshtein_distance = levenshtein_distance\n",
    "        self.central_star_distance=central_star_distance\n",
    "        #other metrics\n",
    "        self.mean = None \n",
    "        self.standart_dev = None\n",
    "        self.signalToNoise = None\n",
    "\n",
    "    def as_dict(self):\n",
    "        return {'org1': self.first_org_name, 'org2': self.second_org_name, 'chunk_or1': self.first_chunk_value,\n",
    "               'chunk_or2': self.second_chunk_value,'global_align': self.global_alighn_score,\n",
    "                'global_alighn_gap':self.global_alighn_gap,'local_align': self.local_alighn_score,\n",
    "                'local_alighn_gap':self.local_alighn_gap,'similarity':self.similarity,\n",
    "                'word_count_score':self.word_count_score,'longest_seq':self.longest_seq,\n",
    "                'rank_distance':self.rank_distance,'levenshtein_distance':self.levenshtein_distance,\n",
    "                'central_star_distance':self.central_star_distance,\n",
    "               'mean': self.mean,'STD':self.standart_dev,'signalToNoise':self.signalToNoise}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************Pre-Processing******************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "from Bio import SeqIO\n",
    "sequence_virus_hiv = \"\"\n",
    "for seq_record in SeqIO.parse(\"HIV.fasta\", \"fasta\"):\n",
    "    sequence_virus_hiv=sequence_virus_hiv+seq_record.seq\n",
    "sequence_virus_covid= \"\"\n",
    "for seq_record in SeqIO.parse(\"coronavirus.fasta\", \"fasta\"):\n",
    "    print(seq_record.seq)\n",
    "    sequence_virus_covid=sequence_virus_covid+seq_record.seq\n",
    "sequence_virus_tuberculosis= \"\"\n",
    "for seq_record in SeqIO.parse(\"tuberculosis.fasta\", \"fasta\"):\n",
    "    sequence_virus_tuberculosis=sequence_virus_tuberculosis+seq_record.seq\n",
    "sequence_virus_flu= \"\"\n",
    "for seq_record in SeqIO.parse(\"influenca.fasta\", \"fasta\"):\n",
    "    sequence_virus_flu=sequence_virus_flu+seq_record.seq\n",
    "sequence_virus_sars= \"\"\n",
    "for seq_record in SeqIO.parse(\"SARS-CoV-2.fasta\", \"fasta\"):\n",
    "    sequence_virus_sars=sequence_virus_sars+seq_record.seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sliding windows to split data in k-mers'''\n",
    "def split_to_k_mers(seq,step,window):\n",
    "    result=[]\n",
    "    for i in range(0,(len(seq)-window),step):\n",
    "        result.append(seq[i:i + window])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=60\n",
    "chunks_seq_virus_hiv=[sequence_virus_hiv[i:i+k] for i in range(0, len(sequence_virus_hiv), k)]\n",
    "chunks_seq_virus_covid=[sequence_virus_covid[i:i+k] for i in range(0, len(sequence_virus_covid), k)]\n",
    "chunks_seq_virus_tubercolosis=[sequence_virus_tuberculosis[i:i+k] for i in range(0, len(sequence_virus_tuberculosis), k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=60\n",
    "chunks_seq_virus_flu=[sequence_virus_flu[i:i+k] for i in range(0, len(sequence_virus_flu), k)]\n",
    "chunks_seq_virus_sars=[sequence_virus_sars[i:i+k] for i in range(0, len(sequence_virus_sars), k)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_preprocessing(org1Name,Org2Name,chunks_seq_virus1,chunks_seq_virus2,seq1\n",
    "                                       ,seq2,gap_open_penalty,gap_extend_penalty,result):\n",
    "    global_alighnment ,global_alighn_gaps= global_alighn_score(seq1,seq2,gap_open_penalty,gap_extend_penalty)\n",
    "    local_alighnment,local_alighn_gaps= local_alighn_score(seq1,seq2,gap_open_penalty,gap_extend_penalty)\n",
    "    sim_score = similarity(global_alighnment,local_alighnment)  \n",
    "    \n",
    "    word_count=word_neighborhood_count_score(seq1, seq2)\n",
    "    central_star_distance=getCentralStarDistance(seq1, seq2)\n",
    "    rank_distance=rankDistance(seq1, seq2)\n",
    "    longest_substring=longestSubstring(seq1, seq2)\n",
    "    leveshtein_distance=leveshteinDistance(seq1, seq2)\n",
    "    \n",
    "    \n",
    "    info =  DataSetInfo(org1Name,Org2Name,chunks_seq_virus1,chunks_seq_virus2,seq1,seq2,\n",
    "                        global_alighnment,global_alighn_gaps,local_alighnment,local_alighn_gaps,sim_score,\n",
    "                        word_count,longest_substring,rank_distance,leveshtein_distance,central_star_distance)\n",
    "    #global_alighnment,global_alighn_gaps,local_alighnment,local_alighn_gaps,sim_score,\n",
    "    result.put(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, queue\n",
    "  \n",
    "def paraller_preprocessing(org1Name,Org2Name,chunks_seq_virus1,chunks_seq_virus2,gap_open_penalty,gap_extend_penalty):\n",
    "    q = queue.Queue()\n",
    "    threads = []\n",
    "    for x in range(int(len(chunks_seq_virus1))):\n",
    "        for y in range(int(len(chunks_seq_virus2))):\n",
    "            seq1 = chunks_seq_virus1[x]\n",
    "            seq2 = chunks_seq_virus2[y]\n",
    "            t=threading.Thread(target=chunk_preprocessing, args=(org1Name,Org2Name,chunks_seq_virus1,chunks_seq_virus2,seq1,seq2,gap_open_penalty,gap_extend_penalty,q))\n",
    "            threads.append(t)\n",
    "            t.start()\n",
    "     # Wait for all threads to finish\n",
    "    for x in threads:\n",
    "        x.join()\n",
    "    result=list(q.queue)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# result=paraller_preprocessing(\"HIV\",\"Tubercolosis\",chunks_seq_virus_hiv,chunks_seq_virus_tubercolosis,-10,-1)\n",
    "# #tuberculosis\n",
    "# end = time.time()\n",
    "# print(\"Time for executing model\")\n",
    "# print(end - start)\n",
    "# print(\" in seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ml_metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from ml_metrics import rmse\n",
    "import numpy as np\n",
    "\n",
    "def regression_results(y_true, y_pred):# Regression metrics\n",
    "    explained_variance=explained_variance_score(y_true, y_pred)\n",
    "    mae=mean_absolute_error(y_true, y_pred) \n",
    "    mse=mean_squared_error(y_true, y_pred) \n",
    "    r2=r2_score(y_true, y_pred)\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mae,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install progressbar\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import progressbar\n",
    "from time import sleep\n",
    "bar = progressbar.ProgressBar(maxval=1000, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "l=int(len(chunks_seq_virus_tubercolosis)/1000)\n",
    "\n",
    "bar.start()\n",
    "for i in range(910, 1000):\n",
    "    bar.update(i+1)\n",
    "    result=paraller_preprocessing(\"Covid\",\"HIV\",chunks_seq_virus_covid,chunks_seq_virus_tubercolosis[i*l:(i+1)*l],-10,-1)\n",
    "    dataFrame = pd.DataFrame([x.as_dict() for x in result])\n",
    "    filename=\"data_Covid_HIV_real\"+str(i)+\".csv\"\n",
    "    dataFrame.to_csv(filename,index = False, header=True)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import joblib\n",
    "print('The sklearn version is {}.'.format(sklearn.__version__))\n",
    "print('The joblib version is {}.'.format(joblib.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#all_filename_HT = [i for i in glob.glob('data_HIV_Tubercolosis*.{}'.format('csv'))]\n",
    "#combined_csv_HT = pd.concat([pd.read_csv(f) for f in all_filenamesHT ])\n",
    "all_filename_CT = [i for i in glob.glob('data_Covid_Tubercolosis*.{}'.format('csv'))]\n",
    "combined_csv_CT = pd.concat([pd.read_csv(f) for f in all_filename_CT ])\n",
    "data3=pd.read_csv(\"tuberculasis_HIV.csv\")\n",
    "data1= pd.read_csv(\"data_SARS_Flu.csv\")\n",
    "data2= pd.read_csv(\"data_HIV_Flu.csv\")\n",
    "data_hiv_hiv=pd.read_csv(\"data_HIV_HIV.csv\")\n",
    "df = pd.concat([data1,data2,data3,combined_csv_CT,data_hiv_hiv])\n",
    "data_hiv_covid=pd.read_csv(\"data_HIV_Covid19.csv\")\n",
    "#combined_csv_CT.to_csv( \"tuberculasis_covid.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data=df.drop(['org1', 'org2','mean', 'STD','signalToNoise', 'similarity'], axis=1)\n",
    "data=df_data.dropna()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Alignn GAp Predictor- 'local_alighn_gap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler() \n",
    "gap_pred_data=data.drop(['local_align','global_align', 'global_alighn_gap'], axis=1)\n",
    "X=gap_pred_data.copy()\n",
    "y=gap_pred_data['local_alighn_gap']\n",
    "X_trainBase, X_testBase, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle=False)\n",
    "X_train=X_trainBase.drop(['chunk_or1','chunk_or2','local_alighn_gap'], axis=1)\n",
    "X_train=X_train.astype('int32')\n",
    "X_train =scaler.fit_transform(X_train)\n",
    "    #X_train = scaler.transform(X_train)\n",
    "X_test=X_testBase.drop(['chunk_or1','chunk_or2','local_alighn_gap'], axis=1)\n",
    "X_test=X_test.astype('int32')\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "param_grid = {'hidden_layer_sizes': [i for i in range(1,15)],\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['adam'],\n",
    "              'learning_rate': ['constant'],\n",
    "              'learning_rate_init': [0.001],\n",
    "              'power_t': [0.5],\n",
    "              'alpha': [0.0001],\n",
    "              'max_iter': [1000],\n",
    "              'early_stopping': [False],\n",
    "              'warm_start': [False]}\n",
    "grid = GridSearchCV(mlp, param_grid=param_grid, verbose=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regr = MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "             hidden_layer_sizes=11, learning_rate='constant',\n",
    "             learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
    "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "             validation_fraction=0.1, verbose=False, warm_start=False).fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07, 0.1], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7,8],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [200,300,500,600,700]}\n",
    "\n",
    "grid = GridSearchCV(model,parameters, cv=2,n_jobs = 5,\n",
    "                        verbose=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=4, monotone_constraints='()',\n",
    "             n_estimators=600, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "             scale_pos_weight=1, silent=1, subsample=0.7, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_local_alighn_gap = LinearRegression({'copy_X': True, 'fit_intercept': False, 'normalize': True}).fit(X_train, y_train)\n",
    "y_pred=reg_local_alighn_gap.predict(X_test)\n",
    "regression_results(y_test, y_pred)\n",
    "reg_local_alighn_gap.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib\n",
    "import joblib\n",
    "# save the model to disk\n",
    "filename = 'local_aligh_gap_predictor.sav'\n",
    "joblib.dump(reg_local_alighn_gap, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.predict(X_test)\n",
    "regression_results(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Alighn predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler() \n",
    "gap_pred_data=data.drop(['global_alighn_gap','global_align'], axis=1)\n",
    "X=gap_pred_data.copy()\n",
    "y=gap_pred_data['local_align']\n",
    "X_trainBase, X_testBase, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle=False)\n",
    "X_train_la=X_trainBase.drop(['chunk_or1','chunk_or2','local_align','local_alighn_gap'], axis=1)\n",
    "#X_train_la['local_alighn_gap_pred']=reg_local_alighn_gap.predict(X_train)\n",
    "X_train_la=X_train_la.astype('int32')\n",
    "X_train_la =scaler.fit_transform(X_train_la)\n",
    "    #X_train = scaler.transform(X_train)\n",
    "X_test_la=X_testBase.drop(['chunk_or1','chunk_or2','local_align','local_alighn_gap'], axis=1)\n",
    "#X_test_la['local_alighn_gap_pred']=reg_local_alighn_gap.predict(X_test)\n",
    "X_test_la=X_test_la.astype('int32')\n",
    "X_test_la = scaler.transform(X_test_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "param_grid = {'hidden_layer_sizes': [i for i in range(1,15)],\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['adam'],\n",
    "              'learning_rate': ['constant'],\n",
    "              'learning_rate_init': [0.001],\n",
    "              'power_t': [0.5],\n",
    "              'alpha': [0.0001],\n",
    "              'max_iter': [1000],\n",
    "              'early_stopping': [False],\n",
    "              'warm_start': [False]}\n",
    "grid = GridSearchCV(mlp, param_grid=param_grid, verbose=True)\n",
    "grid.fit(X_train_la, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regr = MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "             hidden_layer_sizes=11, learning_rate='constant',\n",
    "             learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
    "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "             validation_fraction=0.1, verbose=False, warm_start=False).fit(X_train_la, y_train)\n",
    "y_pred = regr.predict(X_test_la)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07, 0.1], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7,8],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [200,300,500,600,700]}\n",
    "\n",
    "grid = GridSearchCV(model,parameters, cv=2,n_jobs = 5,\n",
    "                        verbose=True)\n",
    "grid.fit(X_train_la, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=4, monotone_constraints='()',\n",
    "             n_estimators=600, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "             scale_pos_weight=1, silent=1, subsample=0.7, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None)\n",
    "\n",
    "xgb_model.fit(X_train_la, y_train)\n",
    "y_pred = xgb_model.predict(X_test_la)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "# save the model to disk\n",
    "filename = 'local_aligh_predictor.sav'\n",
    "#joblib.dump(reg_local_alighn, filename)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "# result = loaded_model.predict(X_test_la)\n",
    "# regression_results(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.fit(X_train_la,y_train)\n",
    "result = loaded_model.predict(X_test_la)\n",
    "regression_results(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_local_alighn = LinearRegression({'copy_X': True, 'fit_intercept': False, 'normalize': True}).fit(X_train_la, y_train)\n",
    "y_pred=reg_local_alighn.predict(X_test_la)\n",
    "regression_results(y_test, y_pred)\n",
    "reg_local_alighn.fit(X_test_la,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install joblib\n",
    "# import joblib\n",
    "# # save the model to disk\n",
    "# filename = 'local_aligh_predictor.sav'\n",
    "# joblib.dump(reg_local_alighn, filename)\n",
    "# # load the model from disk\n",
    "# loaded_model = joblib.load(filename)\n",
    "# result = loaded_model.predict(X_test_la)\n",
    "# regression_results(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global_alighn_gap predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler() \n",
    "gap_pred_data=data.drop(['local_align','local_alighn_gap','global_align'], axis=1)\n",
    "X=gap_pred_data.copy()\n",
    "y=gap_pred_data['global_alighn_gap']\n",
    "X_trainBase, X_testBase, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle=False)\n",
    "X_train_ga_gap=X_trainBase.drop(['chunk_or1','chunk_or2','global_alighn_gap'], axis=1)\n",
    "X_train_ga_gap=X_train_ga_gap.astype('int32')\n",
    "X_train_ga_gap =scaler.fit_transform(X_train_ga_gap)\n",
    "    #X_train = scaler.transform(X_train)\n",
    "X_test_ga_gap=X_testBase.drop(['chunk_or1','chunk_or2','global_alighn_gap'], axis=1)\n",
    "X_test_ga_gap=X_test_ga_gap.astype('int32')\n",
    "X_test_ga_gap = scaler.transform(X_test_ga_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "param_grid = {'hidden_layer_sizes': [i for i in range(1,15)],\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['adam'],\n",
    "              'learning_rate': ['constant'],\n",
    "              'learning_rate_init': [0.001],\n",
    "              'power_t': [0.5],\n",
    "              'alpha': [0.0001],\n",
    "              'max_iter': [1000],\n",
    "              'early_stopping': [False],\n",
    "              'warm_start': [False]}\n",
    "grid = GridSearchCV(mlp, param_grid=param_grid, verbose=True)\n",
    "grid.fit(X_train_ga_gap, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regr = MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "             hidden_layer_sizes=11, learning_rate='constant',\n",
    "             learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
    "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "             validation_fraction=0.1, verbose=False, warm_start=False).fit(X_train_ga_gap, y_train)\n",
    "y_pred = regr.predict(X_test_ga_gap)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07, 0.1], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7,8],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [200,300,500,600,700]}\n",
    "\n",
    "grid = GridSearchCV(model,parameters, cv=2,n_jobs = 5,\n",
    "                        verbose=True)\n",
    "grid.fit(X_train_ga_gap, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=4, monotone_constraints='()',\n",
    "             n_estimators=600, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "             scale_pos_weight=1, silent=1, subsample=0.7, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None)\n",
    "\n",
    "xgb_model.fit(X_train_ga_gap, y_train)\n",
    "y_pred = xgb_model.predict(X_test_ga_gap)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_global_alighn_gap = LinearRegression({'copy_X': True, 'fit_intercept': False, 'normalize': True}).fit(X_train_ga_gap, y_train)\n",
    "y_pred=reg_global_alighn_gap.predict(X_test_ga_gap)\n",
    "regression_results(y_test, y_pred)\n",
    "reg_global_alighn_gap.fit(X_test_ga_gap,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib\n",
    "import joblib\n",
    "# save the model to disk\n",
    "filename = 'global_aligh_gap_predictor.sav'\n",
    "joblib.dump(reg_global_alighn_gap, filename)\n",
    "# load the model from disk\n",
    "loaded_model_ga_gap = joblib.load(filename)\n",
    "loaded_model_ga_gap.fit(X_train_ga_gap,y_train)\n",
    "result = loaded_model_ga_gap.predict(X_test_ga_gap)\n",
    "regression_results(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global_alighn predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler() \n",
    "gap_pred_data=data.drop(['local_align','local_alighn_gap','global_alighn_gap'], axis=1)\n",
    "X=gap_pred_data.copy()\n",
    "y=gap_pred_data['global_align']\n",
    "X_trainBase, X_testBase, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle=False)\n",
    "X_train_ga=X_trainBase.drop(['chunk_or1','chunk_or2','global_align'], axis=1)\n",
    "X_train_ga['local_alighn_pred']=loaded_model.predict(X_train_ga)\n",
    "temp=X_trainBase.drop(['chunk_or1','chunk_or2','global_align'], axis=1)\n",
    "X_train_ga['global_alighn_gap_pred']=loaded_model_ga_gap.predict(temp)\n",
    "X_train_ga=X_train_ga.astype('int32')\n",
    "X_train_ga =scaler.fit_transform(X_train_ga)\n",
    "    #X_train = scaler.transform(X_train)\n",
    "X_test_ga=X_testBase.drop(['chunk_or1','chunk_or2','global_align'], axis=1)\n",
    "X_test_ga['local_alighn_pred']=loaded_model.predict(X_test_ga)\n",
    "temp=X_testBase.drop(['chunk_or1','chunk_or2','global_align'], axis=1)\n",
    "X_test_ga['global_alighn_gap_pred']=loaded_model_ga_gap.predict(temp)\n",
    "X_test_ga=X_test_ga.astype('int32')\n",
    "X_test_ga = scaler.transform(X_test_ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "param_grid = {'hidden_layer_sizes': [i for i in range(1,15)],\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['adam'],\n",
    "              'learning_rate': ['constant'],\n",
    "              'learning_rate_init': [0.001],\n",
    "              'power_t': [0.5],\n",
    "              'alpha': [0.0001],\n",
    "              'max_iter': [1000],\n",
    "              'early_stopping': [False],\n",
    "              'warm_start': [False]}\n",
    "grid = GridSearchCV(mlp, param_grid=param_grid, verbose=True)\n",
    "grid.fit(X_train_ga, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regr = MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "             hidden_layer_sizes=11, learning_rate='constant',\n",
    "             learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
    "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "             validation_fraction=0.1, verbose=False, warm_start=False).fit(X_train_ga, y_train)\n",
    "y_pred = regr.predict(X_test_ga)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07, 0.1], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7,8],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [200,300,500,600,700]}\n",
    "\n",
    "grid = GridSearchCV(model,parameters, cv=2,n_jobs = 5,\n",
    "                        verbose=True)\n",
    "grid.fit(X_train_ga, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBRegressor\n",
    "reg_model_ga= XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=4, monotone_constraints='()',\n",
    "             n_estimators=600, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "             scale_pos_weight=1, silent=1, subsample=0.7, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None).fit(X_train_ga, y_train)\n",
    "y_pred=reg_model_ga.predict(X_test_ga)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib\n",
    "import joblib\n",
    "!pip install xgboost\n",
    "from xgboost import XGBRegressor\n",
    "# save the model to disk\n",
    "filename = 'global_aligh_predictor.sav'\n",
    "joblib.dump(reg_model_ga, filename)\n",
    "# load the model from disk\n",
    "loaded_model_ga = joblib.load(filename)\n",
    "loaded_model_ga.fit(X_train_ga,y_train)\n",
    "result = loaded_model_ga.predict(X_test_ga)\n",
    "regression_results(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************************Clustering start**********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_cluster(labels_true, labels_pred,X_test):\n",
    "    import sklearn\n",
    "    ami_score=sklearn.metrics.adjusted_mutual_info_score(labels_true, labels_pred)\n",
    "    compl_score=sklearn.metrics.completeness_score(labels_true, labels_pred)\n",
    "    adj_rand_score=sklearn.metrics.adjusted_rand_score(labels_true, labels_pred)\n",
    "    calinski_harabasz_score=sklearn.metrics.calinski_harabasz_score(X_test, labels_pred)\n",
    "    davies_bouldin_score=sklearn.metrics.davies_bouldin_score(X_test, labels_pred)\n",
    "    fowlkes_mallows_score=sklearn.metrics.fowlkes_mallows_score(labels_true, labels_pred)\n",
    "    homogenity_score=sklearn.metrics.homogeneity_score(labels_true, labels_pred)\n",
    "    mutual_info_score=sklearn.metrics.mutual_info_score(labels_true, labels_pred)\n",
    "    silhouette_score=sklearn.metrics.silhouette_score(X_test, labels_pred)\n",
    "    print(\"**************************\")\n",
    "    print(\"ami_score: {}\".format(ami_score))\n",
    "    print(\"compl_score: {}\".format(compl_score))\n",
    "    print(\"adj_rand_score: {}\".format(adj_rand_score))\n",
    "    print(\"calinski_harabasz_score: {}\".format(calinski_harabasz_score))\n",
    "    print(\"davies_bouldin_score: {}\".format(davies_bouldin_score))\n",
    "    print(\"fowlkes_mallows_score: {}\".format(fowlkes_mallows_score))\n",
    "    print(\"homogenity_score: {}\".format(homogenity_score))\n",
    "    print(\"mutual_info_score: {}\".format(mutual_info_score))\n",
    "    print(\"silhouette_score: {}\".format(silhouette_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data_to_clusters(X_train,X_test):\n",
    "    from sklearn.cluster import KMeans\n",
    "    cluster = KMeans(n_clusters=15, init='k-means++', random_state=0)\n",
    "    cluster.fit_predict(X_train)\n",
    "    return cluster.predict(X_test),cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hiv_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_set=data.copy()\n",
    "train_set=train_set.drop(['chunk_or1','chunk_or2','local_align','local_alighn_gap','global_alighn_gap','global_align'], axis=1)\n",
    "#train_set_transform =scaler.fit_transform(train_set)\n",
    "train_set['local_alighn_pred']=data['local_align']\n",
    "train_set['global_alighn_gap_pred']=data['global_alighn_gap']\n",
    "train_set['global_alighn_pred']=data['global_align']\n",
    "train_set=train_set.dropna()\n",
    "#loaded_model_ga.predict(train_set_transform)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "test_set=dataFrame.copy()\n",
    "test_set=test_set.drop(['org1', 'org2','chunk_or1','chunk_or2','mean', 'STD','signalToNoise', 'similarity','local_align','local_alighn_gap','global_alighn_gap','global_align'], axis=1)\n",
    "test_set=test_set.dropna()\n",
    "test_set=test_set.astype('int32')\n",
    "test_set_transform =scaler.fit_transform(test_set)\n",
    "test_set['local_alighn_pred']=loaded_model.predict(test_set_transform)\n",
    "test_set['global_alighn_gap_pred']=loaded_model_ga_gap.predict(test_set_transform)\n",
    "test_set_transform =scaler.fit_transform(test_set)\n",
    "test_set['global_alighn_pred']=loaded_model_ga.predict(test_set_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which you need and which you don`t\n",
    "!pip install pyeasyga\n",
    "import time\n",
    "from pyeasyga import pyeasyga\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import MeanShift\n",
    "train_data = pd.DataFrame(train_set, columns=['global_alighn_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "clustering_free = MeanShift()\n",
    "cluster_labels_free = clustering.fit_predict(train_data)\n",
    "print(\"Best cluster num is :\", len(list(set(cluster_labels_free))))\n",
    "silhouette_avg = silhouette_score(df1, cluster_labels_free)\n",
    "print(\"The average silhouette_score is :\", silhouette_avg)\n",
    "end = time.time()\n",
    "print(\"Time for executing mean shift model\")\n",
    "print(end - start)\n",
    "print(\" in seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(individual, data):\n",
    "    temp=0;\n",
    "    cNum=1\n",
    "    for x in data:\n",
    "        if temp < x['score']:\n",
    "            temp=x['score']\n",
    "            cNum=x['clusterNum']\n",
    "    return cNum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#KMeans++\n",
    "data=[];\n",
    "for i in range(2,20):\n",
    "    cluster_labels = KMeans(n_clusters=i, init='k-means++').fit_predict(train_data)\n",
    "    data.append({'clusterNum': i , 'score': silhouette_score(train_data, cluster_labels)})\n",
    "ga = pyeasyga.GeneticAlgorithm(data)\n",
    "ga.fitness_function = fitness               # set the GA's fitness function\n",
    "ga.run()                                    # run the GA\n",
    "print(ga.best_individual())\n",
    "end = time.time()\n",
    "print(\"Time for executing Kmeans++ with GA\")\n",
    "print(end - start)\n",
    "print(\" in seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "import numpy as np\n",
    "\n",
    "start = time.time()\n",
    "clustering = AffinityPropagation().fit_predict(train_data)\n",
    "print(\"Best cluster num is :\", len(list(set(clustering))))\n",
    "print('score '+ str(silhouette_score(train_data, clustering)))\n",
    "end = time.time()\n",
    "print(\"Time for executing Kmeans++ with GA\")\n",
    "print(end - start)\n",
    "print(\" in seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = pd.DataFrame(train_set, columns=['global_alighn_pred'])\n",
    "prediction_test = pd.DataFrame(test_set, columns=['global_alighn_pred'])\n",
    "baseline_train = pd.DataFrame(data, columns=['global_align'])\n",
    "baseline_test = pd.DataFrame(dataFrame, columns=['global_align'])\n",
    "pred_labels,cluster_pred=map_data_to_clusters(prediction_train,prediction_test)\n",
    "baseline_labels,cluster_base=map_data_to_clusters(baseline_train,baseline_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cluster(baseline_labels, pred_labels,prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************************Clustering end**********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***********************************RESULT start************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetInfo_test:\n",
    "    def __init__(self,first_org_name,second_org_name,chunk_index_first_org,chunk_index_second_org,first_chunk_value,second_chunk_value,\n",
    "                word_count_score,longest_seq,rank_distance,levenshtein_distance,central_star_distance):\n",
    "        self.first_org_name = first_org_name\n",
    "        self.second_org_name = second_org_name\n",
    "        self.chunk_index_first_org = chunk_index_first_org\n",
    "        self.chunk_index_second_org  = chunk_index_second_org\n",
    "        self.first_chunk_value = first_chunk_value\n",
    "        self.second_chunk_value = second_chunk_value\n",
    "        #alignment_free\n",
    "        self.word_count_score = word_count_score\n",
    "        self.longest_seq = longest_seq \n",
    "        self.rank_distance = rank_distance \n",
    "        self.levenshtein_distance = levenshtein_distance\n",
    "        self.central_star_distance=central_star_distance\n",
    "        #other metrics\n",
    "        self.mean = None \n",
    "        self.standart_dev = None\n",
    "        self.signalToNoise = None\n",
    "\n",
    "    def as_dict(self):\n",
    "        return {'org1': self.first_org_name, 'org2': self.second_org_name, 'chunk_or1': self.first_chunk_value,\n",
    "               'chunk_or2': self.second_chunk_value,\n",
    "                'word_count_score':self.word_count_score,'longest_seq':self.longest_seq,\n",
    "                'rank_distance':self.rank_distance,'levenshtein_distance':self.levenshtein_distance,\n",
    "                'central_star_distance':self.central_star_distance,\n",
    "               'mean': self.mean,'STD':self.standart_dev,'signalToNoise':self.signalToNoise}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_preprocessing_test(org1Name,Org2Name,chunks_seq_virus1,chunks_seq_virus2,seq1\n",
    "                                       ,seq2,gap_open_penalty,gap_extend_penalty,result): \n",
    "    \n",
    "    word_count=word_neighborhood_count_score(seq1, seq2)\n",
    "    central_star_distance=getCentralStarDistance(seq1, seq2)\n",
    "    rank_distance=rankDistance(seq1, seq2)\n",
    "    longest_substring=longestSubstring(seq1, seq2)\n",
    "    leveshtein_distance=leveshteinDistance(seq1, seq2)\n",
    "    \n",
    "    \n",
    "    info =  DataSetInfo_test(org1Name,Org2Name,chunks_seq_virus1,chunks_seq_virus2,seq1,seq2,\n",
    "                        word_count,longest_substring,rank_distance,leveshtein_distance,central_star_distance)\n",
    "    result.put(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, queue\n",
    "  \n",
    "def paraller_preprocessing_test(org1Name,Org2Name,chunks_seq_virus1,chunks_seq_virus2,gap_open_penalty,gap_extend_penalty):\n",
    "    q = queue.Queue()\n",
    "    threads = []\n",
    "    for x in range(int(len(chunks_seq_virus1))):\n",
    "        for y in range(int(len(chunks_seq_virus2))):\n",
    "            seq1 = chunks_seq_virus1[x]\n",
    "            seq2 = chunks_seq_virus2[y]\n",
    "            t=threading.Thread(target=chunk_preprocessing_test, args=(org1Name,Org2Name,chunks_seq_virus1,chunks_seq_virus2,seq1,seq2,gap_open_penalty,gap_extend_penalty,q))\n",
    "            threads.append(t)\n",
    "            t.start()\n",
    "     # Wait for all threads to finish\n",
    "    for x in threads:\n",
    "        x.join()\n",
    "    result=list(q.queue)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "result=paraller_preprocessing(\"Covid\",\"HIV\",chunks_seq_virus_covid,chunks_seq_virus_hiv,-10,-1)\n",
    "filename=\"data_Covid_HIV_real.csv\"\n",
    "result.to_csv(filename,index = False, header=True)\n",
    "#tuberculosis\n",
    "end = time.time()\n",
    "print(\"Time for executing model\")\n",
    "print(end - start)\n",
    "print(\" in seconds\")\n",
    "data_hiv_covid=pd.read_csv(\"data_Covid_HIV_real.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_hc=test_set.copy()\n",
    "# prediction_train = pd.DataFrame(train_set, columns=['global_alighn_pred'])\n",
    "# prediction_test = pd.DataFrame(test_set, columns=['global_alighn_pred'])\n",
    "X_test_hc = pd.concat([prediction_train ,prediction_test])\n",
    "\n",
    "X_test_hc['clusters']=cluster_pred.predict(X_test_hc)\n",
    "#X_test_hc['chunk_or1']=data_hiv_covid['chunk_or1']\n",
    "#X_test_hc['chunk_or2']=data_hiv_covid['chunk_or2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_hc=test_set.copy()\n",
    "X_test_hc['clusters']=pred_labels\n",
    "X_test_hc['chunk_or1']=dataFrame['chunk_or1']\n",
    "X_test_hc['chunk_or2']=dataFrame['chunk_or2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find metrics for clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_num=14\n",
    "print(\"   {}:{} \".format(clust_num,len(X_test_hc[(X_test_hc['clusters']==clust_num)])))\n",
    "print(\"    {}:{} \".format(clust_num,X_test_hc[(X_test_hc['clusters']==clust_num)]['global_alighn_pred'].max()))\n",
    "print(\"    {}:{} \".format(clust_num,X_test_hc[(X_test_hc['clusters']==clust_num)]['global_alighn_pred'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plot data with seaborn\n",
    "facet = sns.lmplot(data=X_test_hc, x='global_alighn_pred', y='rank_distance', hue='clusters', \n",
    "                   fit_reg=False, legend=True, legend_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with cluster omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_hc_r=X_test_hc[['clusters','chunk_or1','chunk_or2','global_alighn_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testM=X_test_hc_r[X_test_hc_r['chunk_or1'].str.contains('TCTGACAAATTCACAGATGGTGTATGCCTATTTTGGAA', regex=False)]\n",
    "testA=testM[testM['chunk_or2'].str.contains('TCGAGCTTGCTACAAGGGACTTTCCGCTGGGGAC', regex=False)]\n",
    "testA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testM['chunk_or2'][33265]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=X_test_hc[(X_test_hc.clusters==9)]\n",
    "test1=test.sort_values('global_alighn_pred')\n",
    "test1[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chunk_or1'][15784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "start = time.time()\n",
    "result=paraller_preprocessing(\"Covid\",\"HIV\",chunks_seq_virus_covid,chunks_seq_virus_hiv,-10,-1)\n",
    "dataFrame = pd.DataFrame([x.as_dict() for x in result])\n",
    "scaler=StandardScaler()\n",
    "test_set=dataFrame.copy()\n",
    "test_set=test_set.drop(['org1', 'org2','chunk_or1','chunk_or2','mean', 'STD','signalToNoise',], axis=1)\n",
    "test_set=test_set.dropna()\n",
    "test_set=test_set.astype('int32')\n",
    "test_set_transform =scaler.fit_transform(test_set)\n",
    "test_set['local_alighn_pred']=loaded_model.predict(test_set_transform)\n",
    "test_set['global_alighn_gap_pred']=loaded_model_ga_gap.predict(test_set_transform)\n",
    "test_set_transform =scaler.fit_transform(test_set)\n",
    "test_set['global_alighn_pred']=loaded_model_ga.predict(test_set_transform)\n",
    "end = time.time()\n",
    "print(\"Time for executing model\")\n",
    "print(end - start)\n",
    "print(\" in seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "start = time.time()\n",
    "prediction_train = pd.DataFrame(test_set, columns=['global_alighn_pred'])\n",
    "cluster = KMeans(n_clusters=15, init='k-means++', random_state=0)\n",
    "cluster.fit_predict(prediction_train)\n",
    "end = time.time()\n",
    "print(\"Time for executing model\")\n",
    "print(end - start)\n",
    "print(\" in seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***********************************RESULT end************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([x.as_dict() for x in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv (r'C:\\workspace\\data_HIV_Tubercolosis.csv', index = False, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**********************************HIV**********HIV************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, queue\n",
    "  \n",
    "def paraller_preprocessing(org1Name,chunks_seq_virus1,gap_open_penalty,gap_extend_penalty):\n",
    "    q = queue.Queue()\n",
    "    threads = []\n",
    "    for x in range(int(len(chunks_seq_virus1))):\n",
    "        seq1 = chunks_seq_virus1[x]\n",
    "        t=threading.Thread(target=chunk_preprocessing, args=(org1Name,org1Name,chunks_seq_virus1,chunks_seq_virus1,seq1,seq1,gap_open_penalty,gap_extend_penalty,q))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "     # Wait for all threads to finish\n",
    "    for x in threads:\n",
    "        x.join()\n",
    "    result=list(q.queue)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "result=paraller_preprocessing(\"HIV\",chunks_seq_virus_hiv,-10,-1)\n",
    "#tuberculosis\n",
    "end = time.time()\n",
    "print(\"Time for executing model\")\n",
    "print(end - start)\n",
    "print(\" in seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([x.as_dict() for x in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv (r'C:\\workspace\\data_HIV_HIV.csv', index = False, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
