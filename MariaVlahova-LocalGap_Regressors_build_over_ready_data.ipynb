{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# #train\n",
    "# data1= pd.read_csv(\"data_Tuberculosis_HIV1.csv\")\n",
    "# data1['comparison']='tuberculosis_HIV'\n",
    "# data2= pd.read_csv(\"data_Tuberculosis_Covid19.csv\")\n",
    "# data2['comparison']='tuberculosis_Covid19'\n",
    "# data3= pd.read_csv(\"data_Flu_COVID19.csv\")\n",
    "# data3['comparison']='Flu_Covid19'\n",
    "# data4= pd.read_csv(\"data_SARS_Covid19.csv\")\n",
    "# data4['comparison']='SARS_Covid19'\n",
    "# data5= pd.read_csv(\"data_HIV_HIV.csv\")\n",
    "# data5['comparison']='HIV_HIV'\n",
    "# #test\n",
    "# data6= pd.read_csv(\"data_HIV1_Covid19.csv\")\n",
    "# data6['comparison']='HIV_Covid19'\n",
    "\n",
    "# df = pd.concat([data1,data2,data3,data4,data5])\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data1= pd.read_csv(\"data_SARS_Flu.csv\")\n",
    "data1['comparison']='SARS_Flu'\n",
    "data2= pd.read_csv(\"data_HIV_Flu.csv\")\n",
    "data2['comparison']='HIV_Flu'\n",
    "df = pd.concat([data1,data2])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data=df.drop(['org1', 'org2','mean', 'STD','signalToNoise', 'comparison'], axis=1)\n",
    "data=df_data.dropna()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Alighn Gap Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler() \n",
    "gap_pred_data=data.drop(['local_align','global_align', 'local_alighn_gap', 'similarity'], axis=1)\n",
    "X=gap_pred_data.copy()\n",
    "y=gap_pred_data['global_alighn_gap']\n",
    "X_trainBase, X_testBase, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle=False)\n",
    "X_train=X_trainBase.drop(['chunk_or1','chunk_or2','global_alighn_gap'], axis=1)\n",
    "X_train=X_train.astype('int32')\n",
    "X_train =scaler.fit_transform(X_train)\n",
    "    #X_train = scaler.transform(X_train)\n",
    "X_test=X_testBase.drop(['chunk_or1','chunk_or2','global_alighn_gap'], axis=1)\n",
    "X_test=X_test.astype('int32')\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_global_alighn_gap = LinearRegression({'copy_X': True, 'fit_intercept': False, 'normalize': True}).fit(X_train, y_train)\n",
    "y_pred=reg_global_alighn_gap.predict(X_test)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full=X_trainBase.copy()\n",
    "X_test_full=X_testBase.copy()\n",
    "X_train_full['global_alighn_gap_pred']=reg_global_alighn_gap.predict(X_train)\n",
    "X_test_full['global_alighn_gap_pred']=reg_global_alighn_gap.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainBase['global_alighn_gap_pred']=reg.predict(X_train)\n",
    "X_testBase['global_alighn_gap_pred']=reg.predict(X_test)\n",
    "X_train_=X_trainBase.drop(['chunk_or1','chunk_or2','global_alighn_gap','local_align','local_alighn_gap'], axis=1)\n",
    "X_test_=X_testBase.drop(['chunk_or1','chunk_or2','global_alighn_gap'], axis=1)\n",
    "\n",
    "model= XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=4, monotone_constraints='()',\n",
    "             n_estimators=600, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "             scale_pos_weight=1, silent=1, subsample=0.7, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None).fit(X_train_, y_train)\n",
    "y_pred=model.predict(X_test_)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "param_grid = {'hidden_layer_sizes': [i for i in range(1,25)],\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['adam'],\n",
    "              'learning_rate': ['constant'],\n",
    "              'learning_rate_init': [0.001,0.005,0.5,0.1],\n",
    "              'power_t': [0.5],\n",
    "              'alpha': [0.0001],\n",
    "              'max_iter': [1000],\n",
    "              'early_stopping': [False],\n",
    "              'warm_start': [False]}\n",
    "grid = GridSearchCV(mlp, param_grid=param_grid, verbose=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regr =MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "             hidden_layer_sizes=20, learning_rate='constant',\n",
    "             learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
    "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "             validation_fraction=0.1, verbose=False, warm_start=False).fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Alignn GAp Predictor- 'local_alighn_gap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler() \n",
    "gap_pred_data=data.drop(['local_align','global_align', 'global_alighn_gap', 'similarity'], axis=1)\n",
    "X=gap_pred_data.copy()\n",
    "y=gap_pred_data['local_alighn_gap']\n",
    "X_trainBase, X_testBase, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle=False)\n",
    "X_train=X_trainBase.drop(['chunk_or1','chunk_or2','local_alighn_gap'], axis=1)\n",
    "X_train=X_train.astype('int32')\n",
    "X_train =scaler.fit_transform(X_train)\n",
    "    #X_train = scaler.transform(X_train)\n",
    "X_test=X_testBase.drop(['chunk_or1','chunk_or2','local_alighn_gap'], axis=1)\n",
    "X_test=X_test.astype('int32')\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_local_alighn_gap = LinearRegression({'copy_X': True, 'fit_intercept': False, 'normalize': True}).fit(X_train, y_train)\n",
    "y_pred=reg_local_alighn_gap.predict(X_test)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full['local_alighn_gap_pred']=reg_local_alighn_gap.predict(X_train)\n",
    "X_test_full['local_alighn_gap_pred']=reg_local_alighn_gap.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainBase['local_alighn_gap_pred']=reg.predict(X_train)\n",
    "X_testBase['local_alighn_gap_pred']=reg.predict(X_test)\n",
    "X_train_=X_trainBase.drop(['chunk_or1','chunk_or2','local_alighn_gap'], axis=1)\n",
    "X_test_=X_testBase.drop(['chunk_or1','chunk_or2','local_alighn_gap'], axis=1)\n",
    "\n",
    "model= XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=4, monotone_constraints='()',\n",
    "             n_estimators=600, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "             scale_pos_weight=1, silent=1, subsample=0.7, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None).fit(X_train_, y_train)\n",
    "y_pred=model.predict(X_test_)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Alighn predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler() \n",
    "gap_pred_data=data.drop(['global_alighn_gap','global_align', 'similarity'], axis=1)\n",
    "X=gap_pred_data.copy()\n",
    "y=gap_pred_data['local_align']\n",
    "X_trainBase, X_testBase, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle=False)\n",
    "X_train=X_trainBase.drop(['chunk_or1','chunk_or2','local_align','local_alighn_gap'], axis=1)\n",
    "X_train=X_train.astype('int32')\n",
    "X_train =scaler.fit_transform(X_train)\n",
    "    #X_train = scaler.transform(X_train)\n",
    "X_test=X_testBase.drop(['chunk_or1','chunk_or2','local_align','local_alighn_gap'], axis=1)\n",
    "X_test=X_test.astype('int32')\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_local_alighn = LinearRegression({'copy_X': True, 'fit_intercept': False, 'normalize': True}).fit(X_train, y_train)\n",
    "y_pred=reg_local_alighn.predict(X_test)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full['local_alighn_pred']=reg_local_alighn.predict(X_train)\n",
    "X_test_full['local_alighn_pred']=reg_local_alighn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_=X_train_full.drop(['chunk_or1','chunk_or2','global_alighn_gap','local_alighn_gap_pred'], axis=1)\n",
    "X_test_=X_test_full.drop(['chunk_or1','chunk_or2','global_alighn_gap','local_alighn_gap_pred'], axis=1)\n",
    "\n",
    "model= XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=4, monotone_constraints='()',\n",
    "             n_estimators=600, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "             scale_pos_weight=1, silent=1, subsample=0.7, tree_method='exact',\n",
    "             validate_parameters=1, verbosity=None).fit(X_train_, y_train)\n",
    "y_pred=model.predict(X_test_)\n",
    "regression_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Alighn and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ml_metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from ml_metrics import rmse\n",
    "import numpy as np\n",
    "\n",
    "def regression_results(y_true, y_pred):# Regression metrics\n",
    "    explained_variance=explained_variance_score(y_true, y_pred)\n",
    "    mae=mean_absolute_error(y_true, y_pred) \n",
    "    mse=mean_squared_error(y_true, y_pred) \n",
    "    r2=r2_score(y_true, y_pred)\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mae,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,X_test,X_testBase,X_trainBase,X_train=getRegressor(data,200,20,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificate result of train and test\n",
    "X_testBase['globalAlign_pred']=model.predict(X_test)\n",
    "X_trainBase['globalAlign_pred']=model.predict(X_train)\n",
    "prediction_test = pd.DataFrame(X_testBase, columns=['globalAlign_pred'])\n",
    "prediction_train = pd.DataFrame(X_trainBase, columns=['globalAlign_pred'])\n",
    "baseline_test = pd.DataFrame(X_testBase, columns=['global_score'])\n",
    "baseline_train = pd.DataFrame(X_trainBase, columns=['global_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMeanStdAndSignalToNoise(pred_df,column):\n",
    "    prediction=pred_df.copy\n",
    "    prediction['mean'] = prediction[column].rolling(window=3).mean()\n",
    "    prediction['STD'] = prediction[column].rolling(window=3).std()\n",
    "    prediction['signalToNoise']=prediction['mean']/prediction['STD']\n",
    "    prediction=prediction.replace([np.inf, -np.inf], np.nan)\n",
    "    prediction=prediction.fillna(0)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=calcMeanStdAndSignalToNoise(prediction_train,'globalAlign_pred')\n",
    "pred_test=calcMeanStdAndSignalToNoise(prediction_test,'globalAlign_pred')\n",
    "base_train=calcMeanStdAndSignalToNoise(baseline_train,'global_score')\n",
    "base_test=calcMeanStdAndSignalToNoise(baseline_test,'global_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction['mean'] = data['globalAlign_pred'].rolling(window=3).mean()\n",
    "# prediction['STD'] = data['globalAlign_pred'].rolling(window=3).std()\n",
    "# prediction['signalToNoise']=data['mean']/data['STD']\n",
    "# prediction=prediction.replace([np.inf, -np.inf], np.nan)\n",
    "# prediction=prediction.fillna(0)\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# prediction=scaler.fit_transform(prediction)\n",
    "# baseline['mean'] =baseline['global_score'].rolling(window=3).mean()\n",
    "# baseline['STD'] = baseline['global_score'].rolling(window=3).std()\n",
    "# baseline['signalToNoise']=baseline['mean']/baseline['STD']\n",
    "# baseline=baseline.replace([np.inf, -np.inf], np.nan)\n",
    "# baseline=baseline.fillna(0)\n",
    "# baseline=scaler.fit_transform(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data_to_clusters(X_train,X_test):\n",
    "    from sklearn.cluster import KMeans\n",
    "    cluster = KMeans(n_clusters=5, init='k-means++', random_state=0)\n",
    "    cluster.fit_predict(X_train)\n",
    "    return cluster.predict(X_test),cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_cluster(labels_true, labels_pred,X_test):\n",
    "    import sklearn\n",
    "    ami_score=sklearn.metrics.adjusted_mutual_info_score(labels_true, labels_pred)\n",
    "    compl_score=sklearn.metrics.completeness_score(labels_true, labels_pred)\n",
    "    adj_rand_score=sklearn.metrics.adjusted_rand_score(labels_true, labels_pred)\n",
    "    calinski_harabasz_score=sklearn.metrics.calinski_harabasz_score(X_test, labels_pred)\n",
    "    davies_bouldin_score=sklearn.metrics.davies_bouldin_score(X_test, labels_pred)\n",
    "    fowlkes_mallows_score=sklearn.metrics.fowlkes_mallows_score(labels_true, labels_pred)\n",
    "    homogenity_score=sklearn.metrics.homogeneity_score(labels_true, labels_pred)\n",
    "    mutual_info_score=sklearn.metrics.mutual_info_score(labels_true, labels_pred)\n",
    "    silhouette_score=sklearn.metrics.silhouette_score(X_test, labels_pred)\n",
    "    print(\"**************************\")\n",
    "    print(\"ami_score: {}\".format(ami_score))\n",
    "    print(\"compl_score: {}\".format(compl_score))\n",
    "    print(\"adj_rand_score: {}\".format(adj_rand_score))\n",
    "    print(\"calinski_harabasz_score: {}\".format(calinski_harabasz_score))\n",
    "    print(\"davies_bouldin_score: {}\".format(davies_bouldin_score))\n",
    "    print(\"fowlkes_mallows_score: {}\".format(fowlkes_mallows_score))\n",
    "    print(\"homogenity_score: {}\".format(homogenity_score))\n",
    "    print(\"mutual_info_score: {}\".format(mutual_info_score))\n",
    "    print(\"silhouette_score: {}\".format(silhouette_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels,cluster_pred=map_data_to_clusters(pred_train,pred_test)\n",
    "baseline_labels,cluster_base=map_data_to_clusters(base_train,base_test)\n",
    "# prediction_test = pd.DataFrame(X_testBase, columns=['globalAlign_pred'])\n",
    "# prediction_train = pd.DataFrame(X_trainBase, columns=['globalAlign_pred'])\n",
    "# baseline_test = pd.DataFrame(X_testBase, columns=['global_score'])\n",
    "# baseline_train = pd.DataFrame(X_trainBase, columns=['global_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cluster(baseline_labels, pred_labels,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result analysis-test with hiv/covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globalAlighnment\n",
    "'''\n",
    "for the calculation is used bio python\n",
    "gap_open_penalty and gap_extend_penalty neeed to have negative value\n",
    "'''\n",
    "def global_alighn_score(seq1,seq2,gap_open_penalty=-10,gap_extend_penalty=-1):\n",
    "    from Bio.SubsMat import MatrixInfo as matlist\n",
    "    from Bio import pairwise2\n",
    "    matrix = matlist.blosum62\n",
    "    a = pairwise2.align.globalds(seq1,seq2,matrix,gap_open_penalty,gap_extend_penalty)\n",
    "    (s1,s2,score,start,end) = a[0]\n",
    "    return score;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best posible score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1=\"GCCAGGGGGAAAGAAAAAATATAAATTAAAACATATAGTATGGGCAAGCAGGGAGCTAGAACGATTCGCAGTTAATCCTGGCCTGTTAGAAACATCAGAAGGCTGTAGACAAATACTGGGACAGCTACAACCATCCCTTCAGACAGGATCAGAAGAACTTAGATCATTATATAATACAGTAGCAACCCTCTATTGTGTGC\"\n",
    "seq2=\"GCCAGGGGGAAAGAAAAAATATAAATTAAAACATATAGTATGGGCAAGCAGGGAGCTAGAACGATTCGCAGTTAATCCTGGCCTGTTAGAAACATCAGAAGGCTGTAGACAAATACTGGGACAGCTACAACCATCCCTTCAGACAGGATCAGAAGAACTTAGATCATTATATAATACAGTAGCAACCCTCTATTGTGTGC\"\n",
    "global_alighn_score(seq1,seq2,gap_open_penalty=-10,gap_extend_penalty=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['global_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worst score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['global_score'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_train=prediction_train.replace([np.inf, -np.inf], np.nan)\n",
    "# prediction_train=prediction_train.fillna(0)\n",
    "# prediction_test=prediction_test.replace([np.inf, -np.inf], np.nan)\n",
    "# prediction_test=prediction_test.fillna(0)\n",
    "# baseline_train=baseline_train.replace([np.inf, -np.inf], np.nan)\n",
    "# baseline_train=baseline_train.fillna(0)\n",
    "# baseline_test=baseline_test.replace([np.inf, -np.inf], np.nan)\n",
    "# baseline_test=baseline_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels,cluster_pred=map_data_to_clusters(prediction_train,prediction_test)\n",
    "baseline_labels,cluster_base=map_data_to_clusters(baseline_train,baseline_test)\n",
    "# prediction_test = pd.DataFrame(X_testBase, columns=['globalAlign_pred'])\n",
    "# prediction_train = pd.DataFrame(X_trainBase, columns=['globalAlign_pred'])\n",
    "# baseline_test = pd.DataFrame(X_testBase, columns=['global_score'])\n",
    "# baseline_train = pd.DataFrame(X_trainBase, columns=['global_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df=data3.copy()\n",
    "scaler = StandardScaler()  \n",
    "X_hc=data3.copy()\n",
    "y_hc=df['global_score']\n",
    "X_test_hc=data3.drop(['chunk_or1','chunk_or2','global_score','mean','STD','signalToNoise','comparison'], axis=1)\n",
    "X_test_hc=X_test_hc.astype('int32')\n",
    "X_test_hc_scaled =scaler.fit_transform(X_test_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_hc['globalAlign_pred']\n",
    "cluster_data = pd.DataFrame(model.predict(X_test_hc_scaled), columns=['globalAlign_pred'], index=X_test_hc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_hc['globalAlign_pred']=model.predict(X_test_hc_scaled)\n",
    "X_test_hc['clusters']=cluster_pred.predict(cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_hc['chunk_or1']=data3['chunk_or1']\n",
    "X_test_hc['chunk_or2']=data3['chunk_or2']\n",
    "X_test_hc['comparison']=data3['comparison']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STATISTICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"дължина на клъстер {}:{} примера\".format(4,len(X_test_hc[(X_test_hc['clusters']==4)])))\n",
    "print(\"максимален скор в клъстер {}:{} \".format(4,X_test_hc[(X_test_hc['clusters']==4)]['globalAlign_pred'].max()))\n",
    "print(\"минимален скор в клъстер {}:{} \".format(4,X_test_hc[(X_test_hc['clusters']==4)]['globalAlign_pred'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_hc[(X_test_hc['clusters']==4)]['globalAlign_pred'].min())\n",
    "print(X_test_hc[(X_test_hc['clusters']==4)]['globalAlign_pred'].max())\n",
    "print(X_test_hc[(X_test_hc['clusters']==4)]['globalAlign_pred'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gfg_csv_data = df.to_csv('result_HIV_COVID.csv', index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=X_test_hc[(X_test_hc['clusters']==4)]\n",
    "a['globalAlign_pred'][6893]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testM=X_test_hc[X_test_hc['chunk_or1'].str.contains('CTGGTATAGTGCAGCAGCAGA', regex=False)]\n",
    "testA=testM[testM['chunk_or2'].str.contains('CTGGACAAATGCTGGTGATTA', regex=False)]\n",
    "testA[['clusters','chunk_or1','chunk_or2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plot data with seaborn\n",
    "facet = sns.lmplot(data=X_test_hc, x='globalAlign_pred', y='rank_distance', hue='clusters', \n",
    "                   fit_reg=False, legend=True, legend_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cluster(baseline_labels, pred_labels,prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "labelsAB=map_data_to_clusters(baseline)\n",
    "labelsAF=map_data_to_clusters(data)\n",
    "#print(cluster_ab_1['data_index'])\n",
    "'''here manually decid ewhich cluster is with P example and which is with negative examples'''\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "score=adjusted_rand_score(labelsAB,labelsAF)\n",
    "print(score)\n",
    "NBClust(labelsAB,labelsAF,X_test)\n",
    "NBClust(labels_true, labels_pred,X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyeasyga\n",
    "import time\n",
    "from pyeasyga import pyeasyga\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(individual, data):\n",
    "    temp=0;\n",
    "    cNum=1\n",
    "    for x in data:\n",
    "        if temp < x['score']:\n",
    "            temp=x['score']\n",
    "            cNum=x['clusterNum']\n",
    "    return cNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data\n",
    "#print(X.head(5))\n",
    "start = time.time()\n",
    "#KMeans++\n",
    "arr=[];\n",
    "for i in range(2,20):\n",
    "    cluster_labels = KMeans(n_clusters=i, init='k-means++').fit_predict(X)\n",
    "    arr.append({'clusterNum': i , 'score': silhouette_score(X, cluster_labels)})\n",
    "    print({'clusterNum': i , 'score': silhouette_score(X, cluster_labels)})\n",
    "#initialise the GA with data\n",
    "ga = pyeasyga.GeneticAlgorithm(arr)\n",
    "ga.fitness_function = fitness               # set the GA's fitness function\n",
    "ga.run()                                    # run the GA\n",
    "print(ga.best_individual())\n",
    "end = time.time()\n",
    "print(\"Time for executing Kmeans++ with GA\")\n",
    "print(end - start)\n",
    "print(\" in seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBClust(labels_true, labels_pred,X_test):\n",
    "    import sklearn\n",
    "    ami_score=sklearn.metrics.adjusted_mutual_info_score(labels_true, labels_pred)\n",
    "    compl_score=sklearn.metrics.completeness_score(labels_true, labels_pred)\n",
    "    adj_rand_score=sklearn.metrics.adjusted_rand_score(labels_true, labels_pred)\n",
    "    calinski_harabasz_score=sklearn.metrics.calinski_harabasz_score(X_test, labels_pred)\n",
    "    davies_bouldin_score=sklearn.metrics.davies_bouldin_score(X_test, labels_pred)\n",
    "    fowlkes_mallows_score=sklearn.metrics.fowlkes_mallows_score(labels_true, labels_pred)\n",
    "    homogenity_score=sklearn.metrics.homogeneity_score(labels_true, labels_pred)\n",
    "    mutual_info_score=sklearn.metrics.mutual_info_score(labels_true, labels_pred)\n",
    "    silhouette_score=sklearn.metrics.silhouette_score(X_test, labels_pred)\n",
    "    print(\"**************************\")\n",
    "    print(\"ami_score: {}\".format(ami_score))\n",
    "    print(\"compl_score: {}\".format(compl_score))\n",
    "    print(\"adj_rand_score: {}\".format(adj_rand_score))\n",
    "    print(\"calinski_harabasz_score: {}\".format(calinski_harabasz_score))\n",
    "    print(\"davies_bouldin_score: {}\".format(davies_bouldin_score))\n",
    "    print(\"fowlkes_mallows_score: {}\".format(fowlkes_mallows_score))\n",
    "    print(\"homogenity_score: {}\".format(homogenity_score))\n",
    "    print(\"mutual_info_score: {}\".format(mutual_info_score))\n",
    "    print(\"silhouette_score: {}\".format(silhouette_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
