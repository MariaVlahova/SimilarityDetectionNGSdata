{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGGCTGCATGCTTAGTGCACTCACGCAGTATAATTAATAACTAATTACTGTCGTTGACAGGACACGAGTAACTCGTCTATCTTCTGCAGGCTGCTTACGGTTTCGTCCGTGTTGCAGCCGATCATCAGCACATCTAGGTTTCGTCCGGGTGTGACCGAAAGGTAAGATGGAGAGCCTTGTCCCTGGTTTCAACGAGAAAACACACGTCCAACTCAGTTTGCCTGTTTTACAGGTTCGCGACGTGCTCGTACGTGGCTTTGGAGACTCCGTGGAGGAGGTCTTATCAGAGGCACGTCAACATCTTAAAGATGGCACTTGTGGCTTAGTAGAAGTTGAAAAAGGCGTTTTGCCTCAACTTGAACAGCCCTATGTGTTCATCAAACGTTCGGATGCTCGAACTGCACCTCATGGTCATGTTATGGTTGAGCTGGTAGCAGAACTCGAAGGCATTCAGTACGGTCGTAGTGGTGAGACACTTGGTGTCCTTGTCCCTCATGTGGGCGAAATACCAGTGGCTTACCGCAAGGTTCTTCTTCGTAAGAACGGTAATAAAGGAGCTGGTGGCCATAGTTACGGCGCCGATCTAAAGTCATTTGACTTAGGCGACGAGCTTGGCACTGATCCTTATGAAGATTTTCAAGAAAACTGGAACACTAAACATAGCAGTGGTGTTACCCGTGAACTCATGCGTGAGCTTAACGGAGGGGCATACACTCGCTATGTCGATAACAACTTCTGTGGCCCTGATGGCTACCCTCTTGAGTGCATTAAAGACCTTCTAGCACGTGCTGGTAAAGCTTCATGCACTTTGTCCGAACAACTGGACTTTATTGACACTAAGAGGGGTGTATACTGCTGCCGTGAACATGAGCATGAAATTGCTTGGTACACGGAACGTTCTGAAAAGAGCTATGAATTGCAGACACCTTTTGAAATTAAATTGGCAAAGAAATTTGACACCTTCAATGGGGAATGTCCAAATTTTGTATTTCCCTTAAATTCCATAATCAAGACTATTCAACCAAGGGTTGAAAAGAAAAAGCTTGATGGCTTTATGGGTAGAATTCGATCTGTCTATCCAGTTGCGTCACCAAATGAATGCAACCAAATGTGCCTTTCAACTCTCATGAAGTGTGATCATTGTGGTGAAACTTCATGGCAGACGGGCGATTTTGTTAAAGCCACTTGCGAATTTTGTGGCACTGAGAATTTGACTAAAGAAGGTGCCACTACTTGTGGTTACTTACCCCAAAATGCTGTTGTTAAAATTTATTGTCCAGCATGTCACAATTCAGAAGTAGGACCTGAGCATAGTCTTGCCGAATACCATAATGAATCTGGCTTGAAAACCATTCTTCGTAAGGGTGGTCGCACTATTGCCTTTGGAGGCTGTGTGTTCTCTTATGTTGGTTGCCATAACAAGTGTGCCTATTGGGTTCCACGTGCTAGCGCTAACATAGGTTGTAACCATACAGGTGTTGTTGGAGAAGGTTCCGAAGGTCTTAATGACAACCTTCTTGAAATACTCCAAAAAGAGAAAGTCAACATCAATATTGTTGGTGACTTTAAACTTAATGAAGAGATCGCCATTATTTTGGCATCTTTTTCTGCTTCCACAAGTGCTTTTGTGGAAACTGTGAAAGGTTTGGATTATAAAGCATTCAAACAAATTGTTGAATCCTGTGGTAATTTTAAAGTTACAAAAGGAAAAGCTAAAAAAGGTGCCTGGAATATTGGTGAACAGAAATCAATACTGAGTCCTCTTTATGCATTTGCATCAGAGGCTGCTCGTGTTGTACGATCAATTTTCTCCCGCACTCTTGAAACTGCTCAAAATTCTGTGCGTGTTTTACAGAAGGCCGCTATAACAATACTAGATGGAATTTCACAGTATTCACTGAGACTCATTGATGCTATGATGTTCACATCTGATTTGGCTACTAACAATCTAGTTGTAATGGCCTACATTACAGGTGGTGTTGTTCAGTTGACTTCGCAGTGGCTAACTAACATCTTTGGCACTGTTTATGAAAAACTCAAACCCGTCCTTGATTGGCTTGAAGAGAAGTTTAAGGAAGGTGTAGAGTTTCTTAGAGACGGTTGGGAAATTGTTAAATTTATCTCAACCTGTGCTTGTGAAATTGTCGGTGGACAAATTGTCACCTGTGCAAAGGAAATTAAGGAGAGTGTTCAGACATTCTTTAAGCTTGTAAATAAATTTTTGGCTTTGTGTGCTGACTCTATCATTATTGGTGGAGCTAAACTTAAAGCCTTGAATTTAGGTGAAACATTTGTCACGCACTCAAAGGGATTGTACAGAAAGTGTGTTAAATCCAGAGAAGAAACTGGCCTACTCATGCCTCTAAAAGCCCCAAAAGAAATTATCTTCTTAGAGGGAGAAACACTTCCCACAGAAGTGTTAACAGAGGAAGTTGTCTTGAAAACTGGTGATTTACAACCATTAGAACAACCTACTAGTGAAGCTGTTGAAGCTCCATTGGTTGGTACACCAGTTTGTATTAACGGGCTTATGTTGCTCGAAATCAAAGACACAGAAAAGTACTGTGCCCTTGCACCTAATATGATGGTAACAAACAATACCTTCACACTCAAAGGCGGTGCACCAACAAAGGTTACTTTTGGTGATGACACTGTGATAGAAGTGCAAGGTTACAAGAGTGTGAATATCACTTTTGAACTTGATGAAAGGATTGATAAAGTACTTAATGAGAAGTGCTCTGCCTATACAGTTGAACTCGGTACAGAAGTAAATGAGTTCGCCTGTGTTGTGGCAGATGCTGTCATAAAAACTTTGCAACCAGTATCTGAATTACTTACACCACTGGGCATTGATTTAGATGAGTGGAGTATGGCTACATACTACTTATTTGATGAGTCTGGTGAGTTTAAATTGGCTTCACATATGTATTGTTCTTTCTACCCTCCAGATGAGGATGAAGAAGAAGGTGATTGTGAAGAAGAAGAGTTTGAGCCATCAACTCAATATGAGTATGGTACTGAAGATGATTACCAAGGTAAACCTTTGGAATTTGGTGCCACTTCTGCTGCTCTTCAACCTGAAGAAGAGCAAGAAGAAGATTGGTTAGATGATGATAGTCAACAAACTGTTGGTCAACAAGACGGCAGTGAGGACAATCAGACAACTACTATTCAAACAATTGTTGAGGTTCAACCTCAATTAGAGATGGAACTTACACCAGTTGTTCAGACTATTGAAGTGAATAGTTTTAGTGGTTATTTAAAACTTACTGACAATGTATACATTAAAAATGCAGACATTGTGGAAGAAGCTAAAAAGGTAAAACCAACAGTGGTTGTTAATGCAGCCAATGTTTACCTTAAACATGGAGGAGGTGTTGCAGGAGCCTTAAATAAGGCTACTAACAATGCCATGCAAGTTGAATCTGATGATTACATAGCTACTAATGGACCACTTAAAGTGGGTGGTAGTTGTGTTTTAAGCGGACACAATCTTGCTAAACACTGTCTTCATGTTGTCGGCCCAAATGTTAACAAAGGTGAAGACATTCAACTTCTTAAGAGTGCTTATGAAAATTTTAATCAGCACGAAGTTCTACTTGCACCATTATTATCAGCTGGTATTTTTGGTGCTGACCCTATACATTCTTTAAGAGTTTGTGTAGATACTGTTCGCACAAATGTCTACTTAGCTGTCTTTGATAAAAATCTCTATGACAAACTTGTTTCAAGCTTTTTGGAAATGAAGAGTGAAAAGCAAGTTGAACAAAAGATCGCTGAGATTCCTAAAGAGGAAGTTAAGCCATTTATAACTGAAAGTAAACCTTCAGTTGAACAGAGAAAACAAGATGATAAGAAAATCAAAGCTTGTGTTGAAGAAGTTACAACAACTCTGGAAGAAACTAAGTTCCTCACAGAAAACTTGTTACTTTATATTGACATTAATGGCAATCTTCATCCAGATTCTGCCACTCTTGTTAGTGACATTGACATCACTTTCTTAAAGAAAGATGCTCCATATATAGTGGGTGATGTTGTTCAAGAGGGTGTTTTAACTGCTGTGGTTATACCTACTAAAAAGGCTGGTGGCACTACTGAAATGCTAGCGAAAGCTTTGAGAAAAGTGCCAACAGACAATTATATAACCACTTACCCGGGTCAGGGTTTAAATGGTTACACTGTAGAGGAGGCAAAGACAGTGCTTAAAAAGTGTAAAAGTGCCTTTTACATTCTACCATCTATTATCTCTAATGAGAAGCAAGAAATTCTTGGAACTGTTTCTTGGAATTTGCGAGAAATGCTTGCACATGCAGAAGAAACACGCAAATTAATGCCTGTCTGTGTGGAAACTAAAGCCATAGTTTCAACTATACAGCGTAAATATAAGGGTATTAAAATACAAGAGGGTGTGGTTGATTATGGTGCTAGATTTTACTTTTACACCAGTAAAACAACTGTAGCGTCACTTATCAACACACTTAACGATCTAAATGAAACTCTTGTTACAATGCCACTTGGCTATGTAACACATGGCTTAAATTTGGAAGAAGCTGCTCGGTATATGAGATCTCTCAAAGTGCCAGCTACAGTTTCTGTTTCTTCACCTGATGCTGTTACAGCGTATAATGGTTATCTTACTTCTTCTTCTAAAACACCTGAAGAACATTTTATTGAAACCATCTCACTTGCTGGTTCCTATAAAGATTGGTCCTATTCTGGACAATCTACACAACTAGGTATAGAATTTCTTAAGAGAGGTGATAAAAGTGTATATTACACTAGTAATCCTACCACATTCCACCTAGATGGTGAAGTTATCACCTTTGACAATCTTAAGACACTTCTTTCTTTGAGAGAAGTGAGGACTATTAAGGTGTTTACAACAGTAGACAACATTAACCTCCACACGCAAGTTGTGGACATGTCAATGACATATGGACAACAGTTTGGTCCAACTTATTTGGATGGAGCTGATGTTACTAAAATAAAACCTCATAATTCACATGAAGGTAAAACATTTTATGTTTTACCTAATGATGACACTCTACGTGTTGAGGCTTTTGAGTACTACCACACAACTGATCCTAGTTTTCTGGGTAGGTACATGTCAGCATTAAATCACACTAAAAAGTGGAAATACCCACAAGTTAATGGTTTAACTTCTATTAAATGGGCAGATAACAACTGTTATCTTGCCACTGCATTGTTAACACTCCAACAAATAGAGTTGAAGTTTAATCCACCTGCTCTACAAGATGCTTATTACAGAGCAAGGGCTGGTGAAGCTGCTAACTTTTGTGCACTTATCTTAGCCTACTGTAATAAGACAGTAGGTGAGTTAGGTGATGTTAGAGAAACAATGAGTTACTTGTTTCAACATGCCAATTTAGATTCTTGCAAAAGAGTCTTGAACGTGGTGTGTAAAACTTGTGGACAACAGCAGACAACCCTTAAGGGTGTAGAAGCTGTTATGTACATGGGCACACTTTCTTATGAACAATTTAAGAAAGGTGTTCAGATACCTTGTACGTGTGGTAAACAAGCTACAAAATATCTAGTACAACAGGAGTCACCTTTTGTTATGATGTCAGCACCACCTGCTCAGTATGAACTTAAGCATGGTACATTTACTTGTGCTAGTGAGTACACTGGTAATTACCAGTGTGGTCACTATAAACATATAACTTCTAAAGAAACTTTGTATTGCATAGACGGTGCTTTACTTACAAAGTCCTCAGAATACAAAGGTCCTATTACGGATGTTTTCTACAAAGAAAACAGTTACACAACAACCATAAAACCAGTTACTTATAAATTGGATGGTGTTGTTTGTACAGAAATTGACCCTAAGTTGGACAATTATTATAAGAAAGACAATTCTTATTTCACAGAGCAACCAATTGATCTTGTACCAAACCAACCATATCCAAACGCAAGCTTCGATAATTTTAAGTTTGTATGTGATAATATCAAATTTGCTGATGATTTAAACCAGTTAACTGGTTATAAGAAACCTGCTTCAAGAGAGCTTAAAGTTACATTTTTCCCTGACTTAAATGGTGATGTGGTGGCTATTGATTATAAACACTACACACCCTCTTTTAAGAAAGGAGCTAAATTGTTACATAAACCTATTGTTTGGCATGTTAACAATGCAACTAATAAAGCCACGTATAAACCAAATACCTGGTGTATACGTTGTCTTTGGAGCACAAAACCAGTTGAAACATCAAATTCGTTTGATGTACTGAAGTCAGAGGACGCGCAGGGAATGGATAATCTTGCCTGCGAAGATCTAAAACCAGTCTCTGAAGAAGTAGTGGAAAATCCTACCATACAGAAAGACGTTCTTGAGTGTAATGTGAAAACTACCGAAGTTGTAGGAGACATTATACTTAAACCAGCAAATAATAGTTTAAAAATTACAGAAGAGGTTGGCCACACAGATCTAATGGCTGCTTATGTAGACAATTCTAGTCTTACTATTAAGAAACCTAATGAATTATCTAGAGTATTAGGTTTGAAAACCCTTGCTACTCATGGTTTAGCTGCTGTTAATAGTGTCCCTTGGGATACTATAGCTAATTATGCTAAGCCTTTTCTTAACAAAGTTGTTAGTACAACTACTAACATAGTTACACGGTGTTTAAACCGTGTTTGTACTAATTATATGCCTTATTTCTTTACTTTATTGCTACAATTGTGTACTTTTACTAGAAGTACAAATTCTAGAATTAAAGCATCTATGCCGACTACTATAGCAAAGAATACTGTTAAGAGTGTCGGTAAATTTTGTCTAGAGGCTTCATTTAATTATTTGAAGTCACCTAATTTTTCTAAACTGATAAATATTATAATTTGGTTTTTACTATTAAGTGTTTGCCTAGGTTCTTTAATCTACTCAACCGCTGCTTTAGGTGTTTTAATGTCTAATTTAGGCATGCCTTCTTACTGTACTGGTTACAGAGAAGGCTATTTGAACTCTACTAATGTCACTATTGCAACCTACTGTACTGGTTCTATACCTTGTAGTGTTTGTCTTAGTGGTTTAGATTCTTTAGACACCTATCCTTCTTTAGAAACTATACAAATTACCATTTCATCTTTTAAATGGGATTTAACTGCTTTTGGCTTAGTTGCAGAGTGGTTTTTGGCATATATTCTTTTCACTAGGTTTTTCTATGTACTTGGATTGGCTGCAATCATGCAATTGTTTTTCAGCTATTTTGCAGTACATTTTATTAGTAATTCTTGGCTTATGTGGTTAATAATTAATCTTGTACAAATGGCCCCGATTTCAGCTATGGTTAGAATGTACATCTTCTTTGCATCATTTTATTATGTATGGAAAAGTTATGTGCATGTTGTAGACGGTTGTAATTCATCAACTTGTATGATGTGTTACAAACGTAATAGAGCAACAAGAGTCGAATGTACAACTATTGTTAATGGTGTTAGAAGGTCCTTTTATGTCTATGCTAATGGAGGTAAAGGCTTTTGCAAACTACACAATTGGAATTGTGTTAATTGTGATACATTCTGTGCTGGTAGTACATTTATTAGTGATGAAGTTGCGAGAGACTTGTCACTACAGTTTAAAAGACCAATAAATCCTACTGACCAGTCTTCTTACATCGTTGATAGTGTTACAGTGAAGAATGGTTCCATCCATCTTTACTTTGATAAAGCTGGTCAAAAGACTTATGAAAGACATTCTCTCTCTCATTTTGTTAACTTAGACAACCTGAGAGCTAATAACACTAAAGGTTCATTGCCTATTAATGTTATAGTTTTTGATGGTAAATCAAAATGTGAAGAATCATCTGCAAAATCAGCGTCTGTTTACTACAGTCAGCTTATGTGTCAACCTATACTGTTACTAGATCAGGCATTAGTGTCTGATGTTGGTGATAGTGCGGAAGTTGCAGTTAAAATGTTTGATGCTTACGTTAATACGTTTTCATCAACTTTTAACGTACCAATGGAAAAACTCAAAACACTAGTTGCAACTGCAGAAGCTGAACTTGCAAAGAATGTGTCCTTAGACAATGTCTTATCTACTTTTATTTCAGCAGCTCGGCAAGGGTTTGTTGATTCAGATGTAGAAACTAAAGATGTTGTTGAATGTCTTAAATTGTCACATCAATCTGACATAGAAGTTACTGGCGATAGTTGTAATAACTATATGCTCACCTATAACAAAGTTGAAAACATGACACCCCGTGACCTTGGTGCTTGTATTGACTGTAGTGCGCGTCATATTAATGCGCAGGTAGCAAAAAGTCACAACATTGCTTTGATATGGAACGTTAAAGATTTCATGTCATTGTCTGAACAACTACGAAAACAAATACGTAGTGCTGCTAAAAAGAATAACTTACCTTTTAAGTTGACATGTGCAACTACTAGACAAGTTGTTAATGTTGTAACAACAAAGATAGCACTTAAGGGTGGTAAAATTGTTAATAATTGGTTGAAGCAGTTAATTAAAGTTACACTTGTGTTCCTTTTTGTTGCTGCTATTTTCTATTTAATAACACCTGTTCATGTCATGTCTAAACATACTGACTTTTCAAGTGAAATCATAGGATACAAGGCTATTGATGGTGGTGTCACTCGTGACATAGCATCTACAGATACTTGTTTTGCTAACAAACATGCTGATTTTGACACATGGTTTAGCCAGCGTGGTGGTAGTTATACTAATGACAAAGCTTGCCCATTGATTGCTGCAGTCATAACAAGAGAAGTGGGTTTTGTCGTGCCTGGTTTGCCTGGCACGATATTACGCACAACTAATGGTGACTTTTTGCATTTCTTACCTAGAGTTTTTAGTGCAGTTGGTAACATCTGTTACACACCATCAAAACTTATAGAGTACACTGACTTTGCAACATCAGCTTGTGTTTTGGCTGCTGAATGTACAATTTTTAAAGATGCTTCTGGTAAGCCAGTACCATATTGTTATGATACCAATGTACTAGAAGGTTCTGTTGCTTATGAAAGTTTACGCCCTGACACACGTTATGTGCTCATGGATGGCTCTATTATTCAATTTCCTAACACCTACCTTGAAGGTTCTGTTAGAGTGGTAACAACTTTTGATTCTGAGTACTGTAGGCACGGCACTTGTGAAAGATCAGAAGCTGGTGTTTGTGTATCTACTAGTGGTAGATGGGTACTTAACAATGATTATTACAGATCTTTACCAGGAGTTTTCTGTGGTGTAGATGCTGTAAATTTACTTACTAATATGTTTACACCACTAATTCAACCTATTGGTGCTTTGGACATATCAGCATCTATAGTAGCTGGTGGTATTGTAGCTATCGTAGTAACATGCCTTGCCTACTATTTTATGAGGTTTAGAAGAGCTTTTGGTGAATACAGTCATGTAGTTGCCTTTAATACTTTACTATTCCTTATGTCATTCACTGTACTCTGTTTAACACCAGTTTACTCATTCTTACCTGGTGTTTATTCTGTTATTTACTTGTACTTGACATTTTATCTTACTAATGATGTTTCTTTTTTAGCACATATTCAGTGGATGGTTATGTTCACACCTTTAGTACCTTTCTGGATAACAATTGCTTATATCATTTGTATTTCCACAAAGCATTTCTATTGGTTCTTTAGTAATTACCTAAAGAGACGTGTAGTCTTTAATGGTGTTTCCTTTAGTACTTTTGAAGAAGCTGCGCTGTGCACCTTTTTGTTAAATAAAGAAATGTATCTAAAGTTGCGTAGTGATGTGCTATTACCTCTTACGCAATATAATAGATACTTAGCTCTTTATAATAAGTACAAGTATTTTAGTGGAGCAATGGATACAACTAGCTACAGAGAAGCTGCTTGTTGTCATCTCGCAAAGGCTCTCAATGACTTCAGTAACTCAGGTTCTGATGTTCTTTACCAACCACCACAAACCTCTATCACCTCAGCTGTTTTGCAGAGTGGTTTTAGAAAAATGGCATTCCCATCTGGTAAAGTTGAGGGTTGTATGGTACAAGTAACTTGTGGTACAACTACACTTAACGGTCTTTGGCTTGATGACGTAGTTTACTGTCCAAGACATGTGATCTGCACCTCTGAAGACATGCTTAACCCTAATTATGAAGATTTACTCATTCGTAAGTCTAATCATAATTTCTTGGTACAGGCTGGTAATGTTCAACTCAGGGTTATTGGACATTCTATGCAAAATTGTGTACTTAAGCTTAAGGTTGATACAGCCAATCCTAAGACACCTAAGTATAAGTTTGTTCGCATTCAACCAGGACAGACTTTTTCAGTGTTAGCTTGTTACAATGGTTCACCATCTGGTGTTTACCAATGTGCTATGAGGCCCAATTTCACTATTAAGGGTTCATTCCTTAATGGTTCATGTGGTAGTGTTGGTTTTAACATAGATTATGACTGTGTCTCTTTTTGTTACATGCACCATATGGAATTACCAACTGGAGTTCATGCTGGCACAGACTTAGAAGGTAACTTTTATGGACCTTTTGTTGACAGGCAAACAGCACAAGCAGCTGGTACGGACACAACTATTACAGTTAATGTTTTAGCTTGGTTGTACGCTGCTGTTATAAATGGAGACAGGTGGTTTCTCAATCGATTTACCACAACTCTTAATGACTTTAACCTTGTGGCTATGAAGTACAATTATGAACCTCTAACACAAGACCATGTTGACATACTAGGACCTCTTTCTGCTCAAACTGGAATTGCCGTTTTAGATATGTGTGCTTCATTAAAAGAATTACTGCAAAATGGTATGAATGGACGTACCATATTGGGTAGTGCTTTATTAGAAGATGAATTTACACCTTTTGATGTTGTTAGACAATGCTCAGGTGTTACTTTCCAAAGTGCAGTGAAAAGAACAATCAAGGGTACACACCACTGGTTGTTACTCACAATTTTGACTTCACTTTTAGTTTTAGTCCAGAGTACTCAATGGTCTTTGTTCTTTTTTTTGTATGAAAATGCCTTTTTACCTTTTGCTATGGGTATTATTGCTATGTCTGCTTTTGCAATGATGTTTGTCAAACATAAGCATGCATTTCTCTGTTTGTTTTTGTTACCTTCTCTTGCCACTGTAGCTTATTTTAATATGGTCTATATGCCTGCTAGTTGGGTGATGCGTATTATGACATGGTTGGATATGGTTGATACTAGTTTGTCTGGTTTTAAGCTAAAAGACTGTGTTATGTATGCATCAGCTGTAGTGTTACTAATCCTTATGACAGCAAGAACTGTGTATGATGATGGTGCTAGGAGAGTGTGGACACTTATGAATGTCTTGACACTCGTTTATAAAGTTTATTATGGTAATGCTTTAGATCAAGCCATTTCCATGTGGGCTCTTATAATCTCTGTTACTTCTAACTACTCAGGTGTAGTTACAACTGTCATGTTTTTGGCCAGAGGTATTGTTTTTATGTGTGTTGAGTATTGCCCTATTTTCTTCATAACTGGTAATACACTTCAGTGTATAATGCTAGTTTATTGTTTCTTAGGCTATTTTTGTACTTGTTACTTTGGCCTCTTTTGTTTACTCAACCGCTACTTTAGACTGACTCTTGGTGTTTATGATTACTTAGTTTCTACACAGGAGTTTAGATATATGAATTCACAGGGACTACTCCCACCCAAGAATAGCATAGATGCCTTCAAACTCAACATTAAATTGTTGGGTGTTGGTGGCAAACCTTGTATCAAAGTAGCCACTGTACAGTCTAAAATGTCAGATGTAAAGTGCACATCAGTAGTCTTACTCTCAGTTTTGCAACAACTCAGAGTAGAATCATCATCTAAATTGTGGGCTCAATGTGTCCAGTTACACAATGACATTCTCTTAGCTAAAGATACTACTGAAGCCTTTGAAAAAATGGTTTCACTACTTTCTGTTTTGCTTTCCATGCAGGGTGCTGTAGACATAAACAAGCTTTGTGAAGAAATGCTGGACAACAGGGCAACCTTACAAGCTATAGCCTCAGAGTTTAGTTCCCTTCCATCATATGCAGCTTTTGCTACTGCTCAAGAAGCTTATGAGCAGGCTGTTGCTAATGGTGATTCTGAAGTTGTTCTTAAAAAGTTGAAGAAGTCTTTGAATGTGGCTAAATCTGAATTTGACCGTGATGCAGCCATGCAACGTAAGTTGGAAAAGATGGCTGATCAAGCTATGACCCAAATGTATAAACAGGCTAGATCTGAGGACAAGAGGGCAAAAGTTACTAGTGCTATGCAGACAATGCTTTTCACTATGCTTAGAAAGTTGGATAATGATGCACTCAACAACATTATCAACAATGCAAGAGATGGTTGTGTTCCCTTGAACATAATACCTCTTACAACAGCAGCCAAACTAATGGTTGTCATACCAGACTATAACACATATAAAAATACGTGTGATGGTACAACATTTACTTATGCATCAGCATTGTGGGAAATCCAACAGGTTGTAGATGCAGATAGTAAAATTGTTCAACTTAGTGAAATTAGTATGGACAATTCACCTAATTTAGCATGGCCTCTTATTGTAACAGCTTTAAGGGCCAATTCTGCTGTCAAATTACAGAATAATGAGCTTAGTCCTGTTGCACTACGACAGATGTCTTGTGCTGCCGGTACTACACAAACTGCTTGCACTGATGACAATGCGTTAGCTTACTACAACACAACAAAGGGAGGTAGGTTTGTACTTGCACTGTTATCCGATTTACAGGATTTGAAATGGGCTAGATTCCCTAAGAGTGATGGAACTGGTACTATCTATACAGAACTGGAACCACCTTGTAGGTTTGTTACAGACACACCTAAAGGTCCTAAAGTGAAGTATTTATACTTTATTAAAGGATTAAACAACCTAAATAGAGGTATGGTACTTGGTAGTTTAGCTGCCACAGTACGTCTACAAGCTGGTAATGCAACAGAAGTGCCTGCCAATTCAACTGTATTATCTTTCTGTGCTTTTGCTGTAGATGCTGCTAAAGCTTACAAAGATTATCTAGCTAGTGGGGGACAACCAATCACTAATTGTGTTAAGATGTTGTGTACACACACTGGTACTGGTCAGGCAATAACAGTTACACCGGAAGCCAATATGGATCAAGAATCCTTTGGTGGTGCATCGTGTTGTCTGTACTGCCGTTGCCACATAGATCATCCAAATCCTAAAGGATTTTGTGACTTAAAAGGTAAGTATGTACAAATACCTACAACTTGTGCTAATGACCCTGTGGGTTTTACACTTAAAAACACAGTCTGTACCGTCTGCGGTATGTGGAAAGGTTATGGCTGTAGTTGTGATCAACTCCGCGAACCCATGCTTCAGTCAGCTGATGCACAATCGTTTTTAAACGGGTTTGCGGTGTAAGTGCAGCCCGTCTTACACCGTGCGGCACAGGCACTAGTACTGATGTCGTATACAGGGCTTTTGACATCTACAATGATAAAGTAGCTGGTTTTGCTAAATTCCTAAAAACTAATTGTTGTCGCTTCCAAGAAAAGGACGAAGATGACAATTTAATTGATTCTTACTTTGTAGTTAAGAGACACACTTTCTCTAACTACCAACATGAAGAAACAATTTATAATTTACTTAAGGATTGTCCAGCTGTTGCTAAACATGACTTCTTTAAGTTTAGAATAGACGGTGACATGGTACCACATATATCACGTCAACGTCTTACTAAATACACAATGGCAGACCTCGTCTATGCTTTAAGGCATTTTGATGAAGGTAATTGTGACACATTAAAAGAAATACTTGTCACATACAATTGTTGTGATGATGATTATTTCAATAAAAAGGACTGGTATGATTTTGTAGAAAACCCAGATATATTACGCGTATACGCCAACTTAGGTGAACGTGTACGCCAAGCTTTGTTAAAAACAGTACAATTCTGTGATGCCATGCGAAATGCTGGTATTGTTGGTGTACTGACATTAGATAATCAAGATCTCAATGGTAACTGGTATGATTTCGGTGATTTCATACAAACCACGCCAGGTAGTGGAGTTCCTGTTGTAGATTCTTATTATTCATTGTTAATGCCTATATTAACCTTGACCAGGGCTTTAACTGCAGAGTCACATGTTGACACTGACTTAACAAAGCCTTACATTAAGTGGGATTTGTTAAAATATGACTTCACGGAAGAGAGGTTAAAACTCTTTGACCGTTATTTTAAATATTGGGATCAGACATACCACCCAAATTGTGTTAACTGTTTGGATGACAGATGCATTCTGCATTGTGCAAACTTTAATGTTTTATTCTCTACAGTGTTCCCACCTACAAGTTTTGGACCACTAGTGAGAAAAATATTTGTTGATGGTGTTCCATTTGTAGTTTCAACTGGATACCACTTCAGAGAGCTAGGTGTTGTACATAATCAGGATGTAAACTTACATAGCTCTAGACTTAGTTTTAAGGAATTACTTGTGTATGCTGCTGACCCTGCTATGCACGCTGCTTCTGGTAATCTATTACTAGATAAACGCACTACGTGCTTTTCAGTAGCTGCACTTACTAACAATGTTGCTTTTCAAACTGTCAAACCCGGTAATTTTAACAAAGACTTCTATGACTTTGCTGTGTCTAAGGGTTTCTTTAAGGAAGGAAGTTCTGTTGAATTAAAACACTTCTTCTTTGCTCAGGATGGTAATGCTGCTATCAGCGATTATGACTACTATCGTTATAATCTACCAACAATGTGTGATATCAGACAACTACTATTTGTAGTTGAAGTTGTTGATAAGTACTTTGATTGTTACGATGGTGGCTGTATTAATGCTAACCAAGTCATCGTCAACAACCTAGACAAATCAGCTGGTTTTCCATTTAATAAATGGGGTAAGGCTAGACTTTATTATGATTCAATGAGTTATGAGGATCAAGATGCACTTTTCGCATATACAAAACGTAATGTCATCCCTACTATAACTCAAATGAATCTTAAGTATGCCATTAGTGCAAAGAATAGAGCTCGCACCGTAGCTGGTGTCTCTATCTGTAGTACTATGACCAATAGACAGTTTCATCAAAAATTATTGAAATCAATAGCCGCCACTAGAGGAGCTACTGTAGTAATTGGAACAAGCAAATTCTATGGTGGTTGGCACAACATGTTAAAAACTGTTTATAGTGATGTAGAAAACCCTCACCTTATGGGTTGGGATTATCCTAAATGTGATAGAGCCATGCCTAACATGCTTAGAATTATGGCCTCACTTGTTCTTGCTCGCAAACATACAACGTGTTGTAGCTTGTCACACCGTTTCTATAGATTAGCTAATGAGTGTGCTCAAGTATTGAGTGAAATGGTCATGTGTGGCGGTTCACTATATGTTAAACCAGGTGGAACCTCATCAGGAGATGCCACAACTGCTTATGCTAATAGTGTTTTTAACATTTGTCAAGCTGTCACGGCCAATGTTAATGCACTTTTATCTACTGATGGTAACAAAATTGCCGATAAGTATGTCCGCAATTTACAACACAGACTTTATGAGTGTCTCTATAGAAATAGAGATGTTGACACAGACTTTGTGAATGAGTTTTACGCATATTTGCGTAAACATTTCTCAATGATGATACTCTCTGACGATGCTGTTGTGTGTTTCAATAGCACTTATGCATCTCAAGGTCTAGTGGCTAGCATAAAGAACTTTAAGTCAGTTCTTTATTATCAAAACAATGTTTTTATGTCTGAAGCAAAATGTTGGACTGAGACTGACCTTACTAAAGGACCTCATGAATTTTGCTCTCAACATACAATGCTAGTTAAACAGGGTGATGATTATGTGTACCTTCCTTACCCAGATCCATCAAGAATCCTAGGGGCCGGCTGTTTTGTAGATGATATCGTAAAAACAGATGGTACACTTATGATTGAACGGTTCGTGTCTTTAGCTATAGATGCTTACCCACTTACTAAACATCCTAATCAGGAGTATGCTGATGTCTTTCATTTGTACTTACAATACATAAGAAAGCTACATGATGAGTTAACAGGACACATGTTAGACATGTATTCTGTTATGCTTACTAATGATAACACTTCAAGGTATTGGGAACCTGAGTTTTATGAGGCTATGTACACACCGCATACAGTCTTACAGGCTGTTGGGGCTTGTGTTCTTTGCAATTCACAGACTTCATTAAGATGTGGTGCTTGCATACGTAGACCATTCTTATGTTGTAAATGCTGTTACGACCATGTCATATCAACATCACATAAATTAGTCTTGTCTGTTAATCCGTATGTTTGCAATGCTCCAGGTTGTGATGTCACAGATGTGACTCAACTTTACTTAGGAGGTATGAGCTATTATTGTAAATCACATAAACCACCCATTAGTTTTCCATTGTGTGCTAATGGACAAGTTTTTGGTTTATATAAAAATACATGTGTTGGTAGCGATAATGTTACTGACTTTAATGCAATTGCAACATGTGACTGGACAAATGCTGGTGATTACATTTTAGCTAACACCTGTACTGAAAGACTCAAGCTTTTTGCAGCAGAAACGCTCAAAGCTACTGAGGAGACATTTAAACTGTCTTATGGTATTGCTACTGTACGTGAAGTGCTGTCTGACAGAGAATTACATCTTTCATGGGAAGTTGGTAAACCTAGACCACCACTTAACCGAAATTATGTCTTTACTGGTTATCGTGTAACTAAAAACAGTAAAGTACAAATAGGAGAGTACACCTTTGAAAAAGGTGACTATGGTGATGCTGTTGTTTACCGAGGTACAACAACTTACAAATTAAATGTTGGTGATTATTTTGTGCTGACATCACATACAGTAATGCCATTAAGTGCACCTACACTAGTGCCACAAGAGCACTATGTTAGAATTACTGGCTTATACCCAACACTCAATATCTCAGATGAGTTTTCTAGCAATGTTGCAAATTATCAAAAGGTTGGTATGCAAAAGTATTCTACACTCCAGGGACCACCTGGTACTGGTAAGAGTCATTTTGCTATTGGCCTAGCTCTCTACTACCCTTCTGCTCGCATAGTGTATACAGCTTGCTCTCATGCCGCTGTTGATGCACTATGTGAGAAGGCATTAAAATATTTGCCTATAGATAAATGTAGTAGAATTATACCTGCACGTGCTCGTGTAGAGTGTTTTGATAAATTCAAAGTGAATTCAACATTAGAACAGTATGTCTTTTGTACTGTAAATGCATTGCCTGAGACGACAGCAGATATAGTTGTCTTTGATGAAATTTCAATGGCCACAAATTATGATTTGAGTGTTGTCAATGCCAGATTACGTGCTAAGCACTATGTGTACATTGGCGACCCTGCTCAATTACCTGCACCACGCACATTGCTAACTAAGGGCACACTAGAACCAGAATATTTCAATTCAGTGTGTAGACTTATGAAAACTATAGGTCCAGACATGTTCCTCGGAACTTGTCGGCGTTGTCCTGCTGAAATTGTTGACACTGTGAGTGCTTTGGTTTATGATAATAAGCTTAAAGCACATAAAGACAAATCAGCTCAATGCTTTAAAATGTTTTATAAGGGTGTTATCACGCATGATGTTTCATCTGCAATTAACAGGCCACAAATAGGCGTGGTAAGAGAATTCCTTACACGTAACCCTGCTTGGAGAAAAGCTGTCTTTATTTCACCTTATAATTCACAGAATGCTGTAGCCTCAAAGATTTTGGGACTACCAACTCAAACTGTTGATTCATCACAGGGCTCAGAATATGACTATGTCATATTCACTCAAACCACTGAAACAGCTCACTCTTGTAATGTAAACAGATTTAATGTTGCTATTACCAGAGCAAAAGTAGGCATACTTTGCATAATGTCTGATAGAGACCTTTATGACAAGTTGCAATTTACAAGTCTTGAAATTCCACGTAGGAATGTGGCAACTTTACAAGCTGAAAATGTAACAGGACTCTTTAAAGATTGTAGTAAGGTAATCACTGGGTTACATCCTACACAGGCACCTACACACCTCAGTGTTGACACTAAATTCAAAACTGAAGGTTTATGTGTTGACATACCTGGCATACCTAAGGACATGACCTATAGAAGACTCATCTCTATGATGGGTTTTAAAATGAATTATCAAGTTAATGGTTACCCTAACATGTTTATCACCCGCGAAGAAGCTATAAGACATGTACGTGCATGGATTGGCTTCGATGTCGAGGGGTGTCATGCTACTAGAGAAGCTGTTGGTACCAATTTACCTTTACAGCTAGGTTTTTCTACAGGTGTTAACCTAGTTGCTGTACCTACAGGTTATGTTGATACACCTAATAATACAGATTTTTCCAGAGTTAGTGCTAAACCACCGCCTGGAGATCAATTTAAACACCTCATACCACTTATGTACAAAGGACTTCCTTGGAATGTAGTGCGTATAAAGATTGTACAAATGTTAAGTGACACACTTAAAAATCTCTCTGACAGAGTCGTATTTGTCTTATGGGCACATGGCTTTGAGTTGACATCTATGAAGTATTTTGTGAAAATAGGACCTGAGCGCACCTGTTGTCTATGTGATAGACGTGCCACATGCTTTTCCACTGCTTCAGACACTTATGCCTGTTGGCATCATTCTATTGGATTTGATTACGTCTATAATCCGTTTATGATTGATGTTCAACAATGGGGTTTTACAGGTAACCTACAAAGCAACCATGATCTGTATTGTCAAGTCCATGGTAATGCACATGTAGCTAGTTGTGATGCAATCATGACTAGGTGTCTAGCTGTCCACGAGTGCTTTGTTAAGCGTGTTGACTGGACTATTGAATATCCTATAATTGGTGATGAACTGAAGATTAATGCGGCTTGTAGAAAGGTTCAACACATGGTTGTTAAAGCTGCATTATTAGCAGACAAATTCCCAGTTCTTCACGACATTGGTAACCCTAAAGCTATTAAGTGTGTACCTCAAGCTGATGTAGAATGGAAGTTCTATGATGCACAGCCTTGTAGTGACAAAGCTTATAAAATAGAAGAATTATTCTATTCTTATGCCACACATTCTGACAAATTCACAGATGGTGTATGCCTATTTTGGAATTGCAATGTCGATAGATATCCTGCTAATTCCATTGTTTGTAGATTTGACACTAGAGTGCTATCTAACCTTAACTTGCCTGGTTGTGATGGTGGCAGTTTGTATGTAAATAAACATGCATTCCACACACCAGCTTTTGATAAAAGTGCTTTTGTTAATTTAAAACAATTACCATTTTTCTATTACTCTGACAGTCCATGTGAGTCTCATGGAAAACAAGTAGTGTCAGATATAGATTATGTACCACTAAAGTCTGCTACGTGTATAACACGTTGCAATTTAGGTGGTGCTGTCTGTAGACATCATGCTAATGAGTACAGATTGTATCTCGATGCTTATAACATGATGATCTCAGCTGGCTTTAGCTTGTGGGTTTACAAACAATTTGATACTTATAACCTCTGGAACACTTTTACAAGACTTCAGAGTTTAGAAAATGTGGCTTTTAATGTTGTAAATAAGGGACACTTTGATGGACAACAGGGTGAAGTACCAGTTTCTATCATTAATAACACTGTTTACACAAAAGTTGATGGTGTTGATGTAGAATTGTTTGAAAATAAAACAACATTACCTGTTAATGTAGCATTTGAGCTTTGGGCTAAGCGCAACATTAAACCAGTACCAGAGGTGAAAATACTCAATAATTTGGGTGTGGACATTGCTGCTAATACTGTGATCTGGGACTACAAAAGAGATGCTCCAGCACATATATCTACTATTGGTGTTTGTTCTATGACTGACATAGCCAAGAAACCAACTGAAACGATTTGTGCACCACTCACTGTCTTTTTTGATGGTAGAGTTGATGGTCAAGTAGACTTATTTAGAAATGCCCGTAATGGTGTTCTTATTACAGAAGGTAGTGTTAAAGGTTTACAACCATCTGTAGGTCCCAAACAAGCTAGTCTTAATGGAGTCACATTAATTGGAGAAGCCGTAAAAACACAGTTCAATTATTATAAGAAAGTTGATGGTGTTGTCCAACAATTACCTGAAACTTACTTTACTCAGAGTAGAAATTTACAAGAATTTAAACCCAGGAGTCAAATGGAAATTGATTTCTTAGAATTAGCTATGGATGAATTCATTGAACGGTATAAATTAGAAGGCTATGCCTTCGAACATATCGTTTATGGAGATTTTAGTCATAGTCAGTTAGGTGGTTTACATCTACTGATTGGACTAGCTAAACGTTTTAAGGAATCACCTTTTGAATTAGAAGATTTTATTCCTATGGACAGTACAGTTAAAAACTATTTCATAACAGATGCGCAAACAGGTTCATCTAAGTGTGTGTGTTCTGTTATTGATTTATTACTTGATGATTTTGTTGAAATAATAAAATCCCAAGATTTATCTGTAGTTTCTAAGGTTGTCAAAGTGACTATTGACTATACAGAAATTTCATTTATGCTTTGGTGTAAAGATGGCCATGTAGAAACATTTTACCCAAAATTACAATCTAGTCAAGCGTGGCAACCGGGTGTTGCTATGCCTAATCTTTACAAAATGCAAAGAATGCTATTAGAAAAGTGTGACCTTCAAAATTATGGTGATAGTGCAACATTACCTAAAGGCATAATGATGAATGTCGCAAAATATACTCAACTGTGTCAATATTTAAACACATTAACATTAGCTGTACCCTATAATATGAGAGTTATACATTTTGGTGCTGGTTCTGATAAAGGAGTTGCACCAGGTACAGCTGTTTTAAGACAGTGGTTGCCTACGGGTACGCTGCTTGTCGATTCAGATCTTAATGACTTTGTCTCTGATGCAGATTCAACTTTGATTGGTGATTGTGCAACTGTACATACAGCTAATAAATGGGATCTCATTATTAGTGATATGTACGACCCTAAGACTAAAAATGTTACAAAAGAAAATGACTCTAAAGAGGGTTTTTTCACTTACATTTGTGGGTTTATACAACAAAAGCTAGCTCTTGGAGGTTCCGTGGCTATAAAGATAACAGAACATTCTTGGAATGCTGATCTTTATAAGCTCATGGGACACTTCGCATGGTGGACAGCCTTTGTTACTAATGTGAATGCGTCATCATCTGAAGCATTTTTAATTGGATGTAATTATCTTGGCAAACCACGCGAACAAATAGATGGTTATGTCATGCATGCAAATTACATATTTTGGAGGAATACAAATCCAATTCAGTTGTCTTCCTATTCTTTATTTGACATGAGTAAATTTCCCCTTAAATTAAGGGGTACTGCTGTTATGTCTTTAAAAGAAGGTCAAATCAATGATATGATTTTATCTCTTCTTAGTAAAGGTAGACTTATAATTAGAGAAAACAACAGAGTTGTTATTTCTAGTGATGTTCTTGTTAACAACTAAACGAACAATGTTTGTTTTTCTTGTTTTATTGCCACTAGTCTCTAGTCAGTGTGTTAATCTTACAACCAGAACTCAATTACCCCCTGCATACACTAATTCTTTCACACGTGGTGTTTATTACCCTGACAAAGTTTTCAGATCCTCAGTTTTACATTCAACTCAGGACTTGTTCTTACCTTTCTTTTCCAATGTTACTTGGTTCCATGCTATACATGTCTCTGGGACCAATGGTACTAAGAGGTTTGATAACCCTGTCCTACCATTTAATGATGGTGTTTATTTTGCTTCCACTGAGAAGTCTAACATAATAAGAGGCTGGATTTTTGGTACTACTTTAGATTCGAAGACCCAGTCCCTACTTATTGTTAATAACGCTACTAATGTTGTTATTAAAGTCTGTGAATTTCAATTTTGTAATGATCCATTTTTGGGTGTTTATTACCACAAAAACAACAAAAGTTGGATGGAAAGTGAGTTCAGAGTTTATTCTAGTGCGAATAATTGCACTTTTGAATATGTCTCTCAGCCTTTTCTTATGGACCTTGAAGGAAAACAGGGTAATTTCAAAAATCTTAGGGAATTTGTGTTTAAGAATATTGATGGTTATTTTAAAATATATTCTAAGCACACGCCTATTAATTTAGTGCGTGATCTCCCTCAGGGTTTTTCGGCTTTAGAACCATTGGTAGATTTGCCAATAGGTATTAACATCACTAGGTTTCAAACTTTACTTGCTTTACATAGAAGTTATTTGACTCCTGGTGATTCTTCTTCAGGTTGGACAGCTGGTGCTGCAGCTTATTATGTGGGTTATCTTCAACCTAGGACTTTTCTATTAAAATATAATGAAAATGGAACCATTACAGATGCTGTAGACTGTGCACTTGACCCTCTCTCAGAAACAAAGTGTACGTTGAAATCCTTCACTGTAGAAAAAGGAATCTATCAAACTTCTAACTTTAGAGTCCAACCAACAGAATCTATTGTTAGATTTCCTAATATTACAAACTTGTGCCCTTTTGGTGAAGTTTTTAACGCCACCAGATTTGCATCTGTTTATGCTTGGAACAGGAAGAGAATCAGCAACTGTGTTGCTGATTATTCTGTCCTATATAATTCCGCATCATTTTCCACTTTTAAGTGTTATGGAGTGTCTCCTACTAAATTAAATGATCTCTGCTTTACTAATGTCTATGCAGATTCATTTGTAATTAGAGGTGATGAAGTCAGACAAATCGCTCCAGGGCAAACTGGAAAGATTGCTGATTATAATTATAAATTACCAGATGATTTTACAGGCTGCGTTATAGCTTGGAATTCTAACAATCTTGATTCTAAGGTTGGTGGTAATTATAATTACCTGTATAGATTGTTTAGGAAGTCTAATCTCAAACCTTTTGAGAGAGATATTTCAACTGAAATCTATCAGGCCGGTAGCACACCTTGTAATGGTGTTGAAGGTTTTAATTGTTACTTTCCTTTACAATCATATGGTTTCCAACCCACTAATGGTGTTGGTTACCAACCATACAGAGTAGTAGTACTTTCTTTTGAACTTCTACATGCACCAGCAACTGTTTGTGGACCTAAAAAGTCTACTAATTTGGTTAAAAACAAATGTGTCAATTTCAACTTCAATGGTTTAACAGGCACAGGTGTTCTTACTGAGTCTAACAAAAAGTTTCTGCCTTTCCAACAATTTGGCAGAGACATTGCTGACACTACTGATGCTGTCCGTGATCCACAGACACTTGAGATTCTTGACATTACACCATGTTCTTTTGGTGGTGTCAGTGTTATAACACCAGGAACAAATACTTCTAACCAGGTTGCTGTTCTTTATCAGGATGTTAACTGCACAGAAGTCCCTGTTGCTATTCATGCAGATCAACTTACTCCTACTTGGCGTGTTTATTCTACAGGTTCTAATGTTTTTCAAACACGTGCAGGCTGTTTAATAGGGGCTGAACATGTCAACAACTCATATGAGTGTGACATACCCATTGGTGCAGGTATATGCGCTAGTTATCAGACTCAGACTAATTCTCCTCGGCGGGCACGTAGTGTAGCTAGTCAATCCATCATTGCCTACACTATGTCACTTGGTGCAGAAAATTCAGTTGCTTACTCTAATAACTCTATTGCCATACCCACAAATTTTACTATTAGTGTTACCACAGAAATTCTACCAGTGTCTATGACCAAGACATCAGTAGATTGTACAATGTACATTTGTGGTGATTCAACTGAATGCAGCAATCTTTTGTTGCAATATGGCAGTTTTTGTACACAATTAAACCGTGCTTTAACTGGAATAGCTGTTGAACAAGACAAAAACACCCAAGAAGTTTTTGCACAAGTCAAACAAATTTACAAAACACCACCAATTAAAGATTTTGGTGGTTTTAATTTTTCACAAATATTACCAGATCCATCAAAACCAAGCAAGAGGTCATTTATTGAAGATCTACTTTTCAACAAAGTGACACTTGCAGATGCTGGCTTCATCAAACAATATGGTGATTGCCTTGGTGATATTGCTGCTAGAGACCTCATTTGTGCACAAAAGTTTAACGGCCTTACTGTTTTGCCACCTTTGCTCACAGATGAAATGATTGCTCAATACACTTCTGCACTGTTAGCGGGTACAATCACTTCTGGTTGGACCTTTGGTGCAGGTGCTGCATTACAAATACCATTTGCTATGCAAATGGCTTATAGGTTTAATGGTATTGGAGTTACACAGAATGTTCTCTATGAGAACCAAAAATTGATTGCCAACCAATTTAATAGTGCTATTGGCAAAATTCAAGACTCACTTTCTTCCACAGCAAGTGCACTTGGAAAACTTCAAGATGTGGTCAACCAAAATGCACAAGCTTTAAACACGCTTGTTAAACAACTTAGCTCCAATTTTGGTGCAATTTCAAGTGTTTTAAATGATATCCTTTCACGTCTTGACAAAGTTGAGGCTGAAGTGCAAATTGATAGGTTGATCACAGGCAGACTTCAAAGTTTGCAGACATATGTGACTCAACAATTAATTAGAGCTGCAGAAATCAGAGCTTCTGCTAATCTTGCTGCTACTAAAATGTCAGAGTGTGTACTTGGACAATCAAAAAGAGTTGATTTTTGTGGAAAGGGCTATCATCTTATGTCCTTCCCTCAGTCAGCACCTCATGGTGTAGTCTTCTTGCATGTGACTTATGTCCCTGCACAAGAAAAGAACTTCACAACTGCTCCTGCCATTTGTCATGATGGAAAAGCACACTTTCCTCGTGAAGGTGTCTTTGTTTCAAATGGCACACACTGGTTTGTAACACAAAGGAATTTTTATGAACCACAAATCATTACTACAGACAACACATTTGTGTCTGGTAACTGTGATGTTGTAATAGGAATTGTCAACAACACAGTTTATGATCCTTTGCAACCTGAATTAGACTCATTCAAGGAGGAGTTAGATAAATATTTTAAGAATCATACATCACCAGATGTTGATTTAGGTGACATCTCTGGCATTAATGCTTCAGTTGTAAACATTCAAAAAGAAATTGACCGCCTCAATGAGGTTGCCAAGAATTTAAATGAATCTCTCATCGATCTCCAAGAACTTGGAAAGTATGAGCAGTATATAAAATGGCCATGGTACATTTGGCTAGGTTTTATAGCTGGCTTGATTGCCATAGTAATGGTGACAATTATGCTTTGCTGTATGACCAGTTGCTGTAGTTGTCTCAAGGGCTGTTGTTCTTGTGGATCCTGCTGCAAATTTGATGAAGACGACTCTGAGCCAGTGCTCAAAGGAGTCAAATTACATTACACATAAACGAACTTATGGATTTGTTTATGAGAATCTTCACAATTGGAACTGTAACTTTGAAGCAAGGTGAAATCAAGGATGCTACTCCTTCAGATTTTGTTCGCGCTACTGCAACGATACCGATACAAGCCTCACTCCCTTTCGGATGGCTTATTGTTGGCGTTGCACTTCTTGCTGTTTTTCAGAGCGCTTCCAAAATCATAACCCTCAAAAAGAGATGGCAACTAGCACTCTCCAAGGGTGTTCACTTTGTTTGCAACTTGCTGTTGTTGTTTGTAACAGTTTACTCACACCTTTTGCTCGTTGCTGCTGGCCTTGAAGCCCCTTTTCTCTATCTTTATGCTTTAGTCTACTTCTTGCAGAGTATAAACTTTGTAAGAATAATAATGAGGCTTTGGCTTTGCTGGAAATGCCGTTCCAAAAACCCATTACTTTATGATGCCAACTATTTTCTTTGCTGGCATACTAATTGTTACGACTATTGTATACCTTACAATAGTGTAACTTCTTCAATTGTCATTACTTCAGGTGATGGCACAACAAGTCCTATTTCTGAACATGACTACCAGATTGGTGGTTATACTGAAAAATGGGAATCTGGAGTAAAAGACTGTGTTGTATTACACAGTTACTTCACTTCAGACTATTACCAGCTGTACTCAACTCAATTGAGTACAGACACTGGTGTTGAACATGTTACCTTCTTCATCTACAATAAAATTGTTGATGAGCCTGAAGAACATGTCCAAATTCACACAATCGACGGTTCATCCGGAGTTGTTAATCCAGTAATGGAACCAATTTATGATGAACCGACGACGACTACTAGCGTGCCTTTGTAAGCACAAGCTGATGAGTACGAACTTATGTACTCATTCGTTTCGGAAGAGACAGGTACGTTAATAGTTAATAGCGTACTTCTTTTTCTTGCTTTCGTGGTATTCTTGCTAGTTACACTAGCCATCCTTACTGCGCTTCGATTGTGTGCGTACTGCTGCAATATTGTTAACGTGAGTCTTGTAAAACCTTCTTTTTACGTTTACTCTCGTGTTAAAAATCTGAATTCTTCTAGAGTTCCTGATCTTCTGGTCTAAACGAACTAAATATTATATTAGTTTTTCTGTTTGGAACTTTAATTTTAGCCATGGCAGATTCCAACGGTACTATTACCGTTGAAGAGCTTAAAAAGCTCCTTGAACAATGGAACCTAGTAATAGGTTTCCTATTCCTTACATGGATTTGTCTTCTACAATTTGCCTATGCCAACAGGAATAGGTTTTTGTATATAATTAAGTTAATTTTCCTCTGGCTGTTATGGCCAGTAACTTTAGCTTGTTTTGTGCTTGCTGCTGTTTACAGAATAAATTGGATCACCGGTGGAATTGCTATCGCAATGGCTTGTCTTGTAGGCTTGATGTGGCTCAGCTACTTCATTGCTTCTTTCAGACTGTTTGCGCGTACGCGTTCCATGTGGTCATTCAATCCAGAAACTAACATTCTTCTCAACGTGCCACTCCATGGCACTATTCTGACCAGACCGCTTCTAGAAAGTGAACTCGTAATCGGAGCTGTGATCCTTCGTGGACATCTTCGTATTGCTGGACACCATCTAGGACGCTGTGACATCAAGGACCTGCCTAAAGAAATCACTGTTGCTACATCACGAACGCTTTCTTATTACAAATTGGGAGCTTCGCAGCGTGTAGCAGGTGACTCAGGTTTTGCTGCATACAGTCGCTACAGGATTGGCAACTATAAATTAAACACAGACCATTCCAGTAGCAGTGACAATATTGCTTTGCTTGTACAGTAAGTGACAACAGATGTTTCATCTCGTTGACTTTCAGGTTACTATAGCAGAGATATTACTAATTATTATGAGGACTTTTAAAGTTTCCATTTGGAATCTTGATTACATCATAAACCTCATAATTAAAAATTTATCTAAGTCACTAACTGAGAATAAATATTCTCAATTAGATGAAGAGCAACCAATGGAGATTGATTAAACGAACATGAAAATTATTCTTTTCTTGGCACTGATAACACTCGCTACTTGTGAGCTTTATCACTACCAAGAGTGTGTTAGAGGTACAACAGTACTTTTAAAAGAACCTTGCTCTTCTGGAACATACGAGGGCAATTCACCATTTCATCCTCTAGCTGATAACAAATTTGCACTGACTTGCTTTAGCACTCAATTTGCTTTTGCTTGTCCTGACGGCGTAAAACACGTCTATCAGTTACGTGCCAGATCAGTTTCACCTAAACTGTTCATCAGACAAGAGGAAGTTCAAGAACTTTACTCTCCAATTTTTCTTATTGTTGCGGCAATAGTGTTTATAACACTTTGCTTCACACTCAAAAGAAAGACAGAATGATTGAACTTTCATTAATTGACTTCTATTTGTGCTTTTTAGCCTTTCTGCTATTCCTTGTTTTAATTATGCTTATTATCTTTTGGTTCTCACTTGAACTGCAAGATCATAATGAAACTTGTCACGCCTAAACGAACATGAAATTTCTTGTTTTCTTAGGAATCATCACAACTGTAGCTGCATTTCACCAAGAATGTAGTTTACAGTCATGTACTCAACATCAACCATATGTAGTTGATGACCCGTGTCCTATTCACTTCTATTCTAAATGGTATATTAGAGTAGGAGCTAGAAAATCAGCACCTTTAATTGAATTGTGCGTGGATGAGGCTGGTTCTAAATCACCCATTCAGTACATCGATATCGGTAATTATACAGTTTCCTGTTTACCTTTTACAATTAATTGCCAGGAACCTAAATTGGGTAGTCTTGTAGTGCGTTGTTCGTTCTATGAAGACTTTTTAGAGTATCATGACGTTCGTGTTGTTTTAGATTTCATCTAAACGAACAAACTAAAATGTCTGATAATGGACCCCAAAATCAGCGAAATGCACCCCGCATTACGTTTGGTGGACCCTCAGATTCAACTGGCAGTAACCAGAATGGAGAACGCAGTGGGGCGCGATCAAAACAACGTCGGCCCCAAGGTTTACCCAATAATACTGCGTCTTGGTTCACCGCTCTCACTCAACATGGCAAGGAAGACCTTAAATTCCCTCGAGGACAAGGCGTTCCAATTAACACCAATAGCAGTCCAGATGACCAAATTGGCTACTACCGAAGAGCTACCAGACGAATTCGTGGTGGTGACGGTAAAATGAAAGATCTCAGTCCAAGATGGTATTTCTACTACCTAGGAACTGGGCCAGAAGCTGGACTTCCCTATGGTGCTAACAAAGACGGCATCATATGGGTTGCAACTGAGGGAGCCTTGAATACACCAAAAGATCACATTGGCACCCGCAATCCTGCTAACAATGCTGCAATCGTGCTACAACTTCCTCAAGGAACAACATTGCCAAAAGGCTTCTACGCAGAAGGGAGCAGAGGCGGCAGTCAAGCCTCTTCTCGTTCCTCATCACGTAGTCGCAACAGTTCAAGAAATTCAACTCCAGGCAGCAGTAGGGGAACTTCTCCTGCTAGAATGGCTGGCAATGGCGGTGATGCTGCTCTTGCTTTGCTGCTGCTTGACAGATTGAACCAGCTTGAGAGCAAAATGTCTGGTAAAGGCCAACAACAACAAGGCCAAACTGTCACTAAGAAATCTGCTGCTGAGGCTTCTAAGAAGCCTCGGCAAAAACGTACTGCCACTAAAGCATACAATGTAACACAAGCTTTCGGCAGACGTGGTCCAGAACAAACCCAAGGAAATTTTGGGGACCAGGAACTAATCAGACAAGGAACTGATTACAAACATTGGCCGCAAATTGCACAATTTGCCCCCAGCGCTTCAGCGTTCTTCGGAATGTCGCGCATTGGCATGGAAGTCACACCTTCGGGAACGTGGTTGACCTACACAGGTGCCATCAAATTGGATGACAAAGATCCAAATTTCAAAGATCAAGTCATTTTGCTGAATAAGCATATTGACGCATACAAAACATTCCCACCAACAGAGCCTAAAAAGGACAAAAAGAAGAAGGCTGATGAAACTCAAGCCTTACCGCAGAGACAGAAGAAACAGCAAACTGTGACTCTTCTTCCTGCTGCAGATTTGGATGATTTCTCCAAACAATTGCAACAATCCATGAGCAGTGCTGACTCAACTCAGGCCTAAACTCATGCAGACCACACAAGGCAGATGGGCTATATAAACGTTTTCGCTTTTCCGTTTACGATATATAGTCTACTCTTGTGCAGAATGAATTCTCGTAACTACATAGCACAAGTAGATGTAGTTAACTTTAATCTCACATAGCAATCTTTAATCAGTGTGTAACATTAGGGAGGACTTGAAAGAGCCACCACATTTTCACCGAGGCCACGCGGAGTACGATCGAGTGTACAGTGAACAATGCTAGGGAGAGCTGCCTATATGGAAGAGCCCTAATGTGTAAAATTAATTTTAGTAGTGCTATCCCCATGTGATTTTAATAGCTTCTTAGGAGAATGACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n"
     ]
    }
   ],
   "source": [
    "#Import Data\n",
    "from Bio import SeqIO\n",
    "sequence_virus1 = \"\"\n",
    "for seq_record in SeqIO.parse(\"HIV.fasta\", \"fasta\"):\n",
    "    sequence_virus1=sequence_virus1+seq_record.seq\n",
    "sequence_virus2= \"\"\n",
    "for seq_record in SeqIO.parse(\"coronavirus.fasta\", \"fasta\"):\n",
    "    print(seq_record.seq)\n",
    "    sequence_virus2=sequence_virus2+seq_record.seq\n",
    "sequence_virus3= \"\"\n",
    "for seq_record in SeqIO.parse(\"tuberculosis.fasta\", \"fasta\"):\n",
    "    sequence_virus3=sequence_virus3+seq_record.seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str('AAAATTAAGGCCTGCATTGATGAGGTTACCACAACACTGGAAGAAACTAAGTTTCTTACC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12-25-25-29-31-12-29-12-12-12-12-12-29-12-25-29-12-12-29-29-31-29-31-31-25-12-25-29-12-12-12-12-25-12-25-25-31-31-31-29-12-25-12-25-31-31-31-25-25-12-12-12-25-25-31-12\n"
     ]
    }
   ],
   "source": [
    "s = 'TGGCATCTTTTTCTGCTTCCACAAGTGCTTTTGTGGAAACTGTGAAAGGTTTGGAT'\n",
    "s = ''.join([(str(ord(x)-96) if x.isalpha() else x) for x in list(s)])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sliding windows to split data in k-mers'''\n",
    "def split_to_k_mers(seq,step,window):\n",
    "    result=[]\n",
    "    for i in range(0,(len(seq)-window),step):\n",
    "        result.append(str(seq[i:i + window]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=100\n",
    "window=10\n",
    "chunks_seq_virus1=split_to_k_mers(sequence_virus1,window,k)\n",
    "chunks_seq_virus2=split_to_k_mers(sequence_virus3,window,k)\n",
    "#chunks_seq_virus3=split_to_k_mers(sequence_virus3,window,k)\n",
    "# chunks_seq_virus1=[sequence_virus1[i:i+k] for i in range(0, len(sequence_virus1), k)]\n",
    "# chunks_seq_virus2=[sequence_virus2[i:i+k] for i in range(0, len(sequence_virus2), k)]\n",
    "# chunks_seq_virus3=[sequence_virus2[i:i+k] for i in range(0, len(sequence_virus2), k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes\n",
    "df_hiv = pd.DataFrame(chunks_seq_virus1)\n",
    "df_hiv['org']='HIV'\n",
    "df_covid = pd.DataFrame(chunks_seq_virus2)\n",
    "df_covid['org']='COVID_19'\n",
    "df_tubercolosa = pd.DataFrame(chunks_seq_virus3)\n",
    "df_tubercolosa['org']='Tubercolosa'\n",
    "df_not_transform = pd.concat([df_tubercolosa,df_covid,df_hiv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformArrayofStringToArrayofNum(arr):\n",
    "    result=[]\n",
    "    for i in arr:\n",
    "        temp=[]\n",
    "        for j in i:\n",
    "            temp.append(-(ord(j)-96))\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_hiv=transformArrayofStringToArrayofNum(chunks_seq_virus1)\n",
    "transform_corona=transformArrayofStringToArrayofNum(chunks_seq_virus2)\n",
    "#transform_tubercolosa=transformArrayofStringToArrayofNum(chunks_seq_virus3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the dataframes\n",
    "df_hiv = pd.DataFrame(transform_hiv)\n",
    "df_hiv['org']='HIV'\n",
    "df_covid = pd.DataFrame(transform_corona)\n",
    "df_covid['org']='COVID_19'\n",
    "# df_tubercolosa = pd.DataFrame(transform_tubercolosa)\n",
    "# df_tubercolosa['org']='Tubercolosa'\n",
    "df = pd.concat([df_covid,df_hiv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "# x=df_covid\n",
    "# for num_clusters in range(2,10):\n",
    "#     clusterer = KMeans(n_clusters=num_clusters, n_jobs=4)\n",
    "#     preds = clusterer.fit_predict(x)\n",
    "#     # centers = clusterer.cluster_centers_\n",
    "#     score = silhouette_score (x, preds, metric='euclidean')\n",
    "#     print (\"For n_clusters = {}, Kmeans silhouette score is {})\".format(num_clusters, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_model_generator(data,n_clusters=3):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_jobs=4)\n",
    "    y_pred_kmeans = kmeans.fit_predict(data)\n",
    "    return y_pred_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x):\n",
    "    train_size=int(len(x)*0.85)\n",
    "    train=x[0:train_size]\n",
    "    test=x[train_size:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_=df.copy()\n",
    "df_=df_.drop(['org'], axis=1)\n",
    "X_train,X_test = train_test_split(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375745, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/autoencoder-for-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "23485/23485 - 69s - loss: 39.7747 - val_loss: 32.0881\n",
      "Epoch 2/1000\n",
      "23485/23485 - 70s - loss: 31.6596 - val_loss: 28.3266\n",
      "Epoch 3/1000\n",
      "23485/23485 - 71s - loss: 29.1980 - val_loss: 26.8532\n",
      "Epoch 4/1000\n",
      "23485/23485 - 77s - loss: 28.1197 - val_loss: 25.8336\n",
      "Epoch 5/1000\n",
      "23485/23485 - 79s - loss: 27.5160 - val_loss: 25.7046\n",
      "Epoch 6/1000\n",
      "23485/23485 - 93s - loss: 27.1948 - val_loss: 25.3041\n",
      "Epoch 7/1000\n",
      "23485/23485 - 91s - loss: 27.0070 - val_loss: 25.3928\n",
      "Epoch 8/1000\n",
      "23485/23485 - 90s - loss: 26.8925 - val_loss: 25.6667\n",
      "Epoch 9/1000\n",
      "23485/23485 - 92s - loss: 26.7899 - val_loss: 25.2332\n",
      "Epoch 10/1000\n",
      "23485/23485 - 93s - loss: 26.6274 - val_loss: 25.0624\n",
      "Epoch 11/1000\n",
      "23485/23485 - 91s - loss: 26.4752 - val_loss: 24.7136\n",
      "Epoch 12/1000\n",
      "23485/23485 - 90s - loss: 26.3325 - val_loss: 24.8727\n",
      "Epoch 13/1000\n",
      "23485/23485 - 92s - loss: 26.2035 - val_loss: 25.0459\n",
      "Epoch 14/1000\n",
      "23485/23485 - 92s - loss: 26.0877 - val_loss: 24.5575\n",
      "Epoch 15/1000\n",
      "23485/23485 - 93s - loss: 25.9440 - val_loss: 24.3048\n",
      "Epoch 16/1000\n",
      "23485/23485 - 76s - loss: 25.7904 - val_loss: 24.2228\n",
      "Epoch 17/1000\n",
      "23485/23485 - 69s - loss: 25.6752 - val_loss: 23.7121\n",
      "Epoch 18/1000\n",
      "23485/23485 - 69s - loss: 25.5792 - val_loss: 23.6742\n",
      "Epoch 19/1000\n",
      "23485/23485 - 69s - loss: 25.4842 - val_loss: 23.7673\n",
      "Epoch 20/1000\n",
      "23485/23485 - 69s - loss: 25.3938 - val_loss: 23.2928\n",
      "Epoch 21/1000\n",
      "23485/23485 - 80s - loss: 25.3002 - val_loss: 23.8561\n",
      "Epoch 22/1000\n",
      "23485/23485 - 70s - loss: 25.2072 - val_loss: 23.2815\n",
      "Epoch 23/1000\n",
      "23485/23485 - 77s - loss: 25.1316 - val_loss: 23.0947\n",
      "Epoch 24/1000\n",
      "23485/23485 - 81s - loss: 25.0639 - val_loss: 22.7888\n",
      "Epoch 25/1000\n",
      "23485/23485 - 81s - loss: 25.0051 - val_loss: 22.8820\n",
      "Epoch 26/1000\n",
      "23485/23485 - 82s - loss: 24.9301 - val_loss: 22.7136\n",
      "Epoch 27/1000\n",
      "23485/23485 - 69s - loss: 24.8826 - val_loss: 22.6945\n",
      "Epoch 28/1000\n",
      "23485/23485 - 69s - loss: 24.8475 - val_loss: 23.2966\n",
      "Epoch 29/1000\n",
      "23485/23485 - 70s - loss: 24.8245 - val_loss: 22.7313\n",
      "Epoch 30/1000\n",
      "23485/23485 - 69s - loss: 24.7949 - val_loss: 22.6316\n",
      "Epoch 31/1000\n",
      "23485/23485 - 69s - loss: 24.7782 - val_loss: 22.6917\n",
      "Epoch 32/1000\n",
      "23485/23485 - 70s - loss: 24.7488 - val_loss: 22.7361\n",
      "Epoch 33/1000\n",
      "23485/23485 - 71s - loss: 24.7348 - val_loss: 22.7446\n",
      "Epoch 34/1000\n",
      "23485/23485 - 70s - loss: 24.7081 - val_loss: 22.8067\n",
      "Epoch 35/1000\n",
      "23485/23485 - 70s - loss: 24.6930 - val_loss: 22.4156\n",
      "Epoch 36/1000\n",
      "23485/23485 - 70s - loss: 24.6713 - val_loss: 22.5446\n",
      "Epoch 37/1000\n",
      "23485/23485 - 70s - loss: 24.6608 - val_loss: 22.4514\n",
      "Epoch 38/1000\n",
      "23485/23485 - 70s - loss: 24.6470 - val_loss: 22.5231\n",
      "Epoch 39/1000\n",
      "23485/23485 - 72s - loss: 24.6253 - val_loss: 22.4866\n",
      "Epoch 40/1000\n",
      "23485/23485 - 72s - loss: 24.5882 - val_loss: 22.5942\n",
      "Epoch 41/1000\n",
      "23485/23485 - 72s - loss: 24.5608 - val_loss: 22.7677\n",
      "Epoch 42/1000\n",
      "23485/23485 - 86s - loss: 24.5378 - val_loss: 22.8227\n",
      "Epoch 43/1000\n",
      "23485/23485 - 87s - loss: 24.5211 - val_loss: 22.4094\n",
      "Epoch 44/1000\n",
      "23485/23485 - 87s - loss: 24.4973 - val_loss: 22.6312\n",
      "Epoch 45/1000\n",
      "23485/23485 - 89s - loss: 24.4864 - val_loss: 22.5892\n",
      "Epoch 46/1000\n",
      "23485/23485 - 87s - loss: 24.4733 - val_loss: 22.9714\n",
      "Epoch 47/1000\n",
      "23485/23485 - 87s - loss: 24.4683 - val_loss: 22.2574\n",
      "Epoch 48/1000\n",
      "23485/23485 - 87s - loss: 24.4467 - val_loss: 22.3637\n",
      "Epoch 49/1000\n",
      "23485/23485 - 87s - loss: 24.4463 - val_loss: 22.2696\n",
      "Epoch 50/1000\n",
      "23485/23485 - 87s - loss: 24.4350 - val_loss: 22.4440\n",
      "Epoch 51/1000\n",
      "23485/23485 - 87s - loss: 24.4304 - val_loss: 22.3821\n",
      "Epoch 52/1000\n",
      "23485/23485 - 88s - loss: 24.4040 - val_loss: 22.4597\n",
      "Epoch 53/1000\n",
      "23485/23485 - 87s - loss: 24.4042 - val_loss: 22.2395\n",
      "Epoch 54/1000\n",
      "23485/23485 - 88s - loss: 24.3897 - val_loss: 22.1026\n",
      "Epoch 55/1000\n",
      "23485/23485 - 89s - loss: 24.3824 - val_loss: 22.2321\n",
      "Epoch 56/1000\n",
      "23485/23485 - 88s - loss: 24.3711 - val_loss: 22.4843\n",
      "Epoch 57/1000\n",
      "23485/23485 - 87s - loss: 24.3763 - val_loss: 22.1638\n",
      "Epoch 58/1000\n",
      "23485/23485 - 88s - loss: 24.3684 - val_loss: 22.3309\n",
      "Epoch 59/1000\n",
      "23485/23485 - 89s - loss: 24.3644 - val_loss: 22.5446\n",
      "Epoch 60/1000\n",
      "23485/23485 - 88s - loss: 24.3542 - val_loss: 22.4246\n",
      "Epoch 61/1000\n",
      "23485/23485 - 87s - loss: 24.3377 - val_loss: 22.1654\n",
      "Epoch 62/1000\n",
      "23485/23485 - 88s - loss: 24.3319 - val_loss: 22.3591\n",
      "Epoch 63/1000\n",
      "23485/23485 - 89s - loss: 24.3296 - val_loss: 22.2343\n",
      "Epoch 64/1000\n",
      "23485/23485 - 88s - loss: 24.3248 - val_loss: 22.4958\n",
      "Epoch 65/1000\n",
      "23485/23485 - 88s - loss: 24.3111 - val_loss: 22.3152\n",
      "Epoch 66/1000\n",
      "23485/23485 - 89s - loss: 24.3031 - val_loss: 22.2477\n",
      "Epoch 67/1000\n",
      "23485/23485 - 88s - loss: 24.3018 - val_loss: 22.2184\n",
      "Epoch 68/1000\n",
      "23485/23485 - 90s - loss: 24.3003 - val_loss: 22.1740\n",
      "Epoch 69/1000\n",
      "23485/23485 - 90s - loss: 24.2896 - val_loss: 22.3012\n",
      "Epoch 70/1000\n",
      "23485/23485 - 92s - loss: 24.2911 - val_loss: 22.1744\n",
      "Epoch 71/1000\n",
      "23485/23485 - 93s - loss: 24.2810 - val_loss: 22.3180\n",
      "Epoch 72/1000\n",
      "23485/23485 - 93s - loss: 24.2740 - val_loss: 22.1450\n",
      "Epoch 73/1000\n",
      "23485/23485 - 92s - loss: 24.2636 - val_loss: 22.1206\n",
      "Epoch 74/1000\n",
      "23485/23485 - 92s - loss: 24.2560 - val_loss: 22.1545\n",
      "Epoch 75/1000\n",
      "23485/23485 - 91s - loss: 24.2447 - val_loss: 21.9629\n",
      "Epoch 76/1000\n",
      "23485/23485 - 93s - loss: 24.2349 - val_loss: 22.1951\n",
      "Epoch 77/1000\n",
      "23485/23485 - 92s - loss: 24.2318 - val_loss: 22.4071\n",
      "Epoch 78/1000\n",
      "23485/23485 - 91s - loss: 24.2189 - val_loss: 22.2942\n",
      "Epoch 79/1000\n",
      "23485/23485 - 92s - loss: 24.2155 - val_loss: 22.0030\n",
      "Epoch 80/1000\n",
      "23485/23485 - 91s - loss: 24.1840 - val_loss: 22.1111\n",
      "Epoch 81/1000\n",
      "23485/23485 - 92s - loss: 24.1664 - val_loss: 22.1140\n",
      "Epoch 82/1000\n",
      "23485/23485 - 92s - loss: 24.1675 - val_loss: 21.9333\n",
      "Epoch 83/1000\n",
      "23485/23485 - 92s - loss: 24.1504 - val_loss: 21.9025\n",
      "Epoch 84/1000\n",
      "23485/23485 - 91s - loss: 24.1425 - val_loss: 21.9773\n",
      "Epoch 85/1000\n",
      "23485/23485 - 91s - loss: 24.1322 - val_loss: 22.1414\n",
      "Epoch 86/1000\n",
      "23485/23485 - 91s - loss: 24.1314 - val_loss: 22.0887\n",
      "Epoch 87/1000\n",
      "23485/23485 - 92s - loss: 24.1217 - val_loss: 22.2418\n",
      "Epoch 88/1000\n",
      "23485/23485 - 93s - loss: 24.1127 - val_loss: 22.1660\n",
      "Epoch 89/1000\n",
      "23485/23485 - 94s - loss: 24.1164 - val_loss: 21.9768\n",
      "Epoch 90/1000\n",
      "23485/23485 - 95s - loss: 24.1033 - val_loss: 21.9258\n",
      "Epoch 91/1000\n",
      "23485/23485 - 92s - loss: 24.1015 - val_loss: 22.0804\n",
      "Epoch 92/1000\n",
      "23485/23485 - 92s - loss: 24.0933 - val_loss: 22.0816\n",
      "Epoch 93/1000\n",
      "23485/23485 - 90s - loss: 24.0851 - val_loss: 22.1423\n",
      "Epoch 94/1000\n",
      "23485/23485 - 92s - loss: 24.0837 - val_loss: 21.9033\n",
      "Epoch 95/1000\n",
      "23485/23485 - 92s - loss: 24.0753 - val_loss: 22.1024\n",
      "Epoch 96/1000\n",
      "23485/23485 - 93s - loss: 24.0428 - val_loss: 21.8551\n",
      "Epoch 97/1000\n",
      "23485/23485 - 92s - loss: 24.0323 - val_loss: 21.9874\n",
      "Epoch 98/1000\n",
      "23485/23485 - 92s - loss: 24.0237 - val_loss: 21.8744\n",
      "Epoch 99/1000\n",
      "23485/23485 - 94s - loss: 24.0138 - val_loss: 21.9971\n",
      "Epoch 100/1000\n",
      "23485/23485 - 91s - loss: 24.0098 - val_loss: 21.8169\n",
      "Epoch 101/1000\n",
      "23485/23485 - 91s - loss: 24.0044 - val_loss: 22.1311\n",
      "Epoch 102/1000\n",
      "23485/23485 - 92s - loss: 24.0051 - val_loss: 21.8462\n",
      "Epoch 103/1000\n",
      "23485/23485 - 91s - loss: 23.9956 - val_loss: 21.7136\n",
      "Epoch 104/1000\n",
      "23485/23485 - 94s - loss: 23.9931 - val_loss: 21.8533\n",
      "Epoch 105/1000\n",
      "23485/23485 - 94s - loss: 23.9889 - val_loss: 21.9743\n",
      "Epoch 106/1000\n",
      "23485/23485 - 92s - loss: 23.9851 - val_loss: 21.8552\n",
      "Epoch 107/1000\n",
      "23485/23485 - 93s - loss: 23.9561 - val_loss: 21.7769\n",
      "Epoch 108/1000\n",
      "23485/23485 - 90s - loss: 23.9410 - val_loss: 21.6659\n",
      "Epoch 109/1000\n",
      "23485/23485 - 91s - loss: 23.9362 - val_loss: 21.7809\n",
      "Epoch 110/1000\n",
      "23485/23485 - 90s - loss: 23.9320 - val_loss: 21.6699\n",
      "Epoch 111/1000\n",
      "23485/23485 - 90s - loss: 23.9357 - val_loss: 21.9018\n",
      "Epoch 112/1000\n",
      "23485/23485 - 91s - loss: 23.9288 - val_loss: 21.6895\n",
      "Epoch 113/1000\n",
      "23485/23485 - 92s - loss: 23.9267 - val_loss: 21.9724\n",
      "Epoch 114/1000\n",
      "23485/23485 - 91s - loss: 23.9172 - val_loss: 21.7992\n",
      "Epoch 115/1000\n",
      "23485/23485 - 91s - loss: 23.9249 - val_loss: 21.6915\n",
      "Epoch 116/1000\n",
      "23485/23485 - 92s - loss: 23.9151 - val_loss: 21.6701\n",
      "Epoch 117/1000\n",
      "23485/23485 - 91s - loss: 23.9153 - val_loss: 21.6583\n",
      "Epoch 118/1000\n",
      "23485/23485 - 92s - loss: 23.9112 - val_loss: 21.7471\n",
      "Epoch 119/1000\n",
      "23485/23485 - 91s - loss: 23.9057 - val_loss: 21.7398\n",
      "Epoch 120/1000\n",
      "23485/23485 - 92s - loss: 23.9091 - val_loss: 21.7033\n",
      "Epoch 121/1000\n",
      "23485/23485 - 92s - loss: 23.8990 - val_loss: 21.6284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/1000\n",
      "23485/23485 - 91s - loss: 23.9036 - val_loss: 21.8092\n",
      "Epoch 123/1000\n",
      "23485/23485 - 93s - loss: 23.8949 - val_loss: 21.8116\n",
      "Epoch 124/1000\n",
      "23485/23485 - 98s - loss: 23.8849 - val_loss: 21.7652\n",
      "Epoch 125/1000\n",
      "23485/23485 - 98s - loss: 23.8813 - val_loss: 21.8026\n",
      "Epoch 126/1000\n",
      "23485/23485 - 96s - loss: 23.8802 - val_loss: 21.7338\n",
      "Epoch 127/1000\n",
      "23485/23485 - 98s - loss: 23.8671 - val_loss: 21.7358\n",
      "Epoch 128/1000\n",
      "23485/23485 - 96s - loss: 23.8548 - val_loss: 21.6918\n",
      "Epoch 129/1000\n",
      "23485/23485 - 97s - loss: 23.8524 - val_loss: 21.5582\n",
      "Epoch 130/1000\n",
      "23485/23485 - 94s - loss: 23.8464 - val_loss: 21.7005\n",
      "Epoch 131/1000\n",
      "23485/23485 - 96s - loss: 23.8370 - val_loss: 21.4639\n",
      "Epoch 132/1000\n",
      "23485/23485 - 94s - loss: 23.8359 - val_loss: 21.6135\n",
      "Epoch 133/1000\n",
      "23485/23485 - 94s - loss: 23.8393 - val_loss: 21.7673\n",
      "Epoch 134/1000\n",
      "23485/23485 - 93s - loss: 23.8248 - val_loss: 21.5993\n",
      "Epoch 135/1000\n",
      "23485/23485 - 90s - loss: 23.8044 - val_loss: 21.7312\n",
      "Epoch 136/1000\n",
      "23485/23485 - 91s - loss: 23.7877 - val_loss: 21.6654\n",
      "Epoch 137/1000\n",
      "23485/23485 - 93s - loss: 23.7697 - val_loss: 21.5819\n",
      "Epoch 138/1000\n",
      "23485/23485 - 94s - loss: 23.7499 - val_loss: 21.3929\n",
      "Epoch 139/1000\n",
      "23485/23485 - 93s - loss: 23.7368 - val_loss: 21.6375\n",
      "Epoch 140/1000\n",
      "23485/23485 - 88s - loss: 23.7304 - val_loss: 21.4998\n",
      "Epoch 141/1000\n",
      "23485/23485 - 90s - loss: 23.7184 - val_loss: 21.5018\n",
      "Epoch 142/1000\n",
      "23485/23485 - 89s - loss: 23.7189 - val_loss: 21.4344\n",
      "Epoch 143/1000\n",
      "23485/23485 - 89s - loss: 23.7072 - val_loss: 21.3913\n",
      "Epoch 144/1000\n",
      "23485/23485 - 90s - loss: 23.6910 - val_loss: 21.7218\n",
      "Epoch 145/1000\n",
      "23485/23485 - 90s - loss: 23.6965 - val_loss: 21.3807\n",
      "Epoch 146/1000\n",
      "23485/23485 - 90s - loss: 23.6848 - val_loss: 21.4902\n",
      "Epoch 147/1000\n",
      "23485/23485 - 90s - loss: 23.6761 - val_loss: 21.5167\n",
      "Epoch 148/1000\n",
      "23485/23485 - 90s - loss: 23.6718 - val_loss: 21.4599\n",
      "Epoch 149/1000\n",
      "23485/23485 - 90s - loss: 23.6674 - val_loss: 21.5715\n",
      "Epoch 150/1000\n",
      "23485/23485 - 90s - loss: 23.6607 - val_loss: 21.5198\n",
      "Epoch 151/1000\n",
      "23485/23485 - 90s - loss: 23.6552 - val_loss: 21.5544\n",
      "Epoch 152/1000\n",
      "23485/23485 - 91s - loss: 23.6313 - val_loss: 21.5042\n",
      "Epoch 153/1000\n",
      "23485/23485 - 90s - loss: 23.6403 - val_loss: 21.5059\n",
      "Epoch 154/1000\n",
      "23485/23485 - 91s - loss: 23.6337 - val_loss: 21.4991\n",
      "Epoch 155/1000\n",
      "23485/23485 - 91s - loss: 23.6256 - val_loss: 21.4096\n",
      "Epoch 156/1000\n",
      "23485/23485 - 92s - loss: 23.6320 - val_loss: 21.4909\n",
      "Epoch 157/1000\n",
      "23485/23485 - 90s - loss: 23.6230 - val_loss: 21.3741\n",
      "Epoch 158/1000\n",
      "23485/23485 - 93s - loss: 23.6056 - val_loss: 21.4593\n",
      "Epoch 159/1000\n",
      "23485/23485 - 96s - loss: 23.6117 - val_loss: 21.4989\n",
      "Epoch 160/1000\n",
      "23485/23485 - 99s - loss: 23.6036 - val_loss: 21.6683\n",
      "Epoch 161/1000\n",
      "23485/23485 - 97s - loss: 23.6032 - val_loss: 21.2619\n",
      "Epoch 162/1000\n",
      "23485/23485 - 94s - loss: 23.6088 - val_loss: 21.2854\n",
      "Epoch 163/1000\n",
      "23485/23485 - 93s - loss: 23.5917 - val_loss: 21.4262\n",
      "Epoch 164/1000\n",
      "23485/23485 - 94s - loss: 23.5934 - val_loss: 21.4019\n",
      "Epoch 165/1000\n",
      "23485/23485 - 93s - loss: 23.5961 - val_loss: 21.5501\n",
      "Epoch 166/1000\n",
      "23485/23485 - 91s - loss: 23.5905 - val_loss: 21.4473\n",
      "Epoch 167/1000\n",
      "23485/23485 - 90s - loss: 23.5881 - val_loss: 21.5399\n",
      "Epoch 168/1000\n",
      "23485/23485 - 88s - loss: 23.5856 - val_loss: 21.5542\n",
      "Epoch 169/1000\n",
      "23485/23485 - 88s - loss: 23.5838 - val_loss: 21.4853\n",
      "Epoch 170/1000\n",
      "23485/23485 - 88s - loss: 23.5807 - val_loss: 21.4973\n",
      "Epoch 171/1000\n",
      "23485/23485 - 90s - loss: 23.5665 - val_loss: 21.3263\n",
      "Epoch 172/1000\n",
      "23485/23485 - 89s - loss: 23.5857 - val_loss: 21.4410\n",
      "Epoch 173/1000\n",
      "23485/23485 - 89s - loss: 23.5743 - val_loss: 21.2653\n",
      "Epoch 174/1000\n",
      "23485/23485 - 88s - loss: 23.5788 - val_loss: 21.4171\n",
      "Epoch 175/1000\n",
      "23485/23485 - 88s - loss: 23.5716 - val_loss: 21.4222\n",
      "Epoch 176/1000\n",
      "23485/23485 - 88s - loss: 23.5636 - val_loss: 21.4007\n",
      "Epoch 177/1000\n",
      "23485/23485 - 88s - loss: 23.5732 - val_loss: 21.5256\n",
      "Epoch 178/1000\n",
      "23485/23485 - 88s - loss: 23.5567 - val_loss: 21.4706\n",
      "Epoch 179/1000\n",
      "23485/23485 - 94s - loss: 23.5635 - val_loss: 21.5911\n",
      "Epoch 180/1000\n",
      "23485/23485 - 99s - loss: 23.5608 - val_loss: 21.4548\n",
      "Epoch 181/1000\n",
      "23485/23485 - 95s - loss: 23.5636 - val_loss: 21.2737\n",
      "Epoch 182/1000\n",
      "23485/23485 - 96s - loss: 23.5609 - val_loss: 21.1857\n",
      "Epoch 183/1000\n",
      "23485/23485 - 99s - loss: 23.5583 - val_loss: 21.5665\n",
      "Epoch 184/1000\n",
      "23485/23485 - 101s - loss: 23.5511 - val_loss: 21.4171\n",
      "Epoch 185/1000\n",
      "23485/23485 - 99s - loss: 23.5631 - val_loss: 21.4006\n",
      "Epoch 186/1000\n",
      "23485/23485 - 100s - loss: 23.5501 - val_loss: 21.3705\n",
      "Epoch 187/1000\n",
      "23485/23485 - 89s - loss: 23.5325 - val_loss: 21.2752\n",
      "Epoch 188/1000\n",
      "23485/23485 - 89s - loss: 23.5260 - val_loss: 21.3111\n",
      "Epoch 189/1000\n",
      "23485/23485 - 91s - loss: 23.5109 - val_loss: 21.4053\n",
      "Epoch 190/1000\n",
      "23485/23485 - 92s - loss: 23.4969 - val_loss: 21.4225\n",
      "Epoch 191/1000\n",
      "23485/23485 - 91s - loss: 23.5026 - val_loss: 21.3595\n",
      "Epoch 192/1000\n",
      "23485/23485 - 91s - loss: 23.4895 - val_loss: 21.2538\n",
      "Epoch 193/1000\n",
      "23485/23485 - 91s - loss: 23.4911 - val_loss: 21.3338\n",
      "Epoch 194/1000\n",
      "23485/23485 - 91s - loss: 23.4874 - val_loss: 21.4156\n",
      "Epoch 195/1000\n",
      "23485/23485 - 91s - loss: 23.4762 - val_loss: 21.5379\n",
      "Epoch 196/1000\n",
      "23485/23485 - 91s - loss: 23.4877 - val_loss: 21.0358\n",
      "Epoch 197/1000\n",
      "23485/23485 - 92s - loss: 23.4829 - val_loss: 21.3815\n",
      "Epoch 198/1000\n",
      "23485/23485 - 91s - loss: 23.4798 - val_loss: 21.2100\n",
      "Epoch 199/1000\n",
      "23485/23485 - 91s - loss: 23.4808 - val_loss: 21.5267\n",
      "Epoch 200/1000\n",
      "23485/23485 - 94s - loss: 23.4704 - val_loss: 21.2273\n",
      "Epoch 201/1000\n",
      "23485/23485 - 91s - loss: 23.4654 - val_loss: 21.3024\n",
      "Epoch 202/1000\n",
      "23485/23485 - 91s - loss: 23.4684 - val_loss: 21.2194\n",
      "Epoch 203/1000\n",
      "23485/23485 - 92s - loss: 23.4620 - val_loss: 21.2439\n",
      "Epoch 204/1000\n",
      "23485/23485 - 92s - loss: 23.4691 - val_loss: 21.4028\n",
      "Epoch 205/1000\n",
      "23485/23485 - 92s - loss: 23.4536 - val_loss: 21.2216\n",
      "Epoch 206/1000\n",
      "23485/23485 - 91s - loss: 23.4650 - val_loss: 21.3925\n",
      "Epoch 207/1000\n",
      "23485/23485 - 91s - loss: 23.4605 - val_loss: 21.2517\n",
      "Epoch 208/1000\n",
      "23485/23485 - 91s - loss: 23.4622 - val_loss: 21.3502\n",
      "Epoch 209/1000\n",
      "23485/23485 - 91s - loss: 23.4595 - val_loss: 21.1606\n",
      "Epoch 210/1000\n",
      "23485/23485 - 92s - loss: 23.4488 - val_loss: 21.3187\n",
      "Epoch 211/1000\n",
      "23485/23485 - 92s - loss: 23.4565 - val_loss: 21.1576\n",
      "Epoch 212/1000\n",
      "23485/23485 - 92s - loss: 23.4433 - val_loss: 21.3961\n",
      "Epoch 213/1000\n",
      "23485/23485 - 95s - loss: 23.4485 - val_loss: 21.3556\n",
      "Epoch 214/1000\n",
      "23485/23485 - 91s - loss: 23.4450 - val_loss: 21.3853\n",
      "Epoch 215/1000\n",
      "23485/23485 - 91s - loss: 23.4375 - val_loss: 21.2582\n",
      "Epoch 216/1000\n",
      "23485/23485 - 92s - loss: 23.4371 - val_loss: 21.1778\n",
      "Epoch 217/1000\n",
      "23485/23485 - 91s - loss: 23.4383 - val_loss: 21.2310\n",
      "Epoch 218/1000\n",
      "23485/23485 - 91s - loss: 23.4337 - val_loss: 21.3872\n",
      "Epoch 219/1000\n",
      "23485/23485 - 92s - loss: 23.4307 - val_loss: 21.1838\n",
      "Epoch 220/1000\n",
      "23485/23485 - 99s - loss: 23.4255 - val_loss: 21.1233\n",
      "Epoch 221/1000\n",
      "23485/23485 - 98s - loss: 23.4343 - val_loss: 21.2235\n",
      "Epoch 222/1000\n",
      "23485/23485 - 97s - loss: 23.4228 - val_loss: 21.0771\n",
      "Epoch 223/1000\n",
      "23485/23485 - 100s - loss: 23.4249 - val_loss: 21.2193\n",
      "Epoch 224/1000\n",
      "23485/23485 - 91s - loss: 23.4240 - val_loss: 21.2530\n",
      "Epoch 225/1000\n",
      "23485/23485 - 90s - loss: 23.4306 - val_loss: 21.0326\n",
      "Epoch 226/1000\n",
      "23485/23485 - 91s - loss: 23.4314 - val_loss: 21.2358\n",
      "Epoch 227/1000\n",
      "23485/23485 - 90s - loss: 23.4145 - val_loss: 21.5781\n",
      "Epoch 228/1000\n",
      "23485/23485 - 92s - loss: 23.4235 - val_loss: 21.1942\n",
      "Epoch 229/1000\n",
      "23485/23485 - 89s - loss: 23.4079 - val_loss: 21.0751\n",
      "Epoch 230/1000\n",
      "23485/23485 - 89s - loss: 23.4112 - val_loss: 21.2049\n",
      "Epoch 231/1000\n",
      "23485/23485 - 88s - loss: 23.4071 - val_loss: 21.2045\n",
      "Epoch 232/1000\n",
      "23485/23485 - 89s - loss: 23.4024 - val_loss: 21.3177\n",
      "Epoch 233/1000\n",
      "23485/23485 - 88s - loss: 23.4123 - val_loss: 21.3068\n",
      "Epoch 234/1000\n",
      "23485/23485 - 87s - loss: 23.4091 - val_loss: 21.1319\n",
      "Epoch 235/1000\n",
      "23485/23485 - 88s - loss: 23.4032 - val_loss: 21.1411\n",
      "Epoch 236/1000\n",
      "23485/23485 - 88s - loss: 23.3994 - val_loss: 21.0856\n",
      "Epoch 237/1000\n",
      "23485/23485 - 83s - loss: 23.4009 - val_loss: 21.0602\n",
      "Epoch 238/1000\n",
      "23485/23485 - 70s - loss: 23.3946 - val_loss: 21.1098\n",
      "Epoch 239/1000\n",
      "23485/23485 - 70s - loss: 23.4005 - val_loss: 21.0483\n",
      "Epoch 240/1000\n",
      "23485/23485 - 70s - loss: 23.3983 - val_loss: 21.0957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "23485/23485 - 70s - loss: 23.3991 - val_loss: 21.4068\n",
      "Epoch 242/1000\n",
      "23485/23485 - 70s - loss: 23.3885 - val_loss: 21.1833\n",
      "Epoch 243/1000\n",
      "23485/23485 - 70s - loss: 23.3882 - val_loss: 21.2588\n",
      "Epoch 244/1000\n",
      "23485/23485 - 70s - loss: 23.3920 - val_loss: 21.1644\n",
      "Epoch 245/1000\n",
      "23485/23485 - 70s - loss: 23.3817 - val_loss: 21.0525\n",
      "Epoch 246/1000\n",
      "23485/23485 - 70s - loss: 23.3705 - val_loss: 21.1492\n",
      "Epoch 247/1000\n",
      "23485/23485 - 70s - loss: 23.3762 - val_loss: 21.0787\n",
      "Epoch 248/1000\n",
      "23485/23485 - 70s - loss: 23.3605 - val_loss: 21.1250\n",
      "Epoch 249/1000\n",
      "23485/23485 - 70s - loss: 23.3535 - val_loss: 21.2853\n",
      "Epoch 250/1000\n",
      "23485/23485 - 70s - loss: 23.3445 - val_loss: 21.1460\n",
      "Epoch 251/1000\n",
      "23485/23485 - 70s - loss: 23.3562 - val_loss: 21.2048\n",
      "Epoch 252/1000\n",
      "23485/23485 - 71s - loss: 23.3436 - val_loss: 21.2632\n",
      "Epoch 253/1000\n",
      "23485/23485 - 69s - loss: 23.3330 - val_loss: 21.0399\n",
      "Epoch 254/1000\n",
      "23485/23485 - 69s - loss: 23.3219 - val_loss: 20.9591\n",
      "Epoch 255/1000\n",
      "23485/23485 - 69s - loss: 23.3050 - val_loss: 20.9575\n",
      "Epoch 256/1000\n",
      "23485/23485 - 70s - loss: 23.2928 - val_loss: 21.0581\n",
      "Epoch 257/1000\n",
      "23485/23485 - 70s - loss: 23.2747 - val_loss: 21.0389\n",
      "Epoch 258/1000\n",
      "23485/23485 - 69s - loss: 23.2756 - val_loss: 21.1801\n",
      "Epoch 259/1000\n",
      "23485/23485 - 69s - loss: 23.2600 - val_loss: 20.9632\n",
      "Epoch 260/1000\n",
      "23485/23485 - 71s - loss: 23.2582 - val_loss: 20.9989\n",
      "Epoch 261/1000\n",
      "23485/23485 - 70s - loss: 23.2451 - val_loss: 21.1486\n",
      "Epoch 262/1000\n",
      "23485/23485 - 71s - loss: 23.2460 - val_loss: 20.8912\n",
      "Epoch 263/1000\n",
      "23485/23485 - 70s - loss: 23.2367 - val_loss: 21.2229\n",
      "Epoch 264/1000\n",
      "23485/23485 - 70s - loss: 23.2401 - val_loss: 20.8930\n",
      "Epoch 265/1000\n",
      "23485/23485 - 70s - loss: 23.2246 - val_loss: 21.0007\n",
      "Epoch 266/1000\n",
      "23485/23485 - 70s - loss: 23.2379 - val_loss: 20.9083\n",
      "Epoch 267/1000\n",
      "23485/23485 - 70s - loss: 23.2297 - val_loss: 20.9521\n",
      "Epoch 268/1000\n",
      "23485/23485 - 70s - loss: 23.2301 - val_loss: 20.9487\n",
      "Epoch 269/1000\n",
      "23485/23485 - 70s - loss: 23.2294 - val_loss: 21.1043\n",
      "Epoch 270/1000\n",
      "23485/23485 - 70s - loss: 23.2225 - val_loss: 21.0283\n",
      "Epoch 271/1000\n",
      "23485/23485 - 70s - loss: 23.2245 - val_loss: 21.1672\n",
      "Epoch 272/1000\n",
      "23485/23485 - 72s - loss: 23.2244 - val_loss: 20.9692\n",
      "Epoch 273/1000\n",
      "23485/23485 - 70s - loss: 23.2246 - val_loss: 21.0427\n",
      "Epoch 274/1000\n",
      "23485/23485 - 70s - loss: 23.2279 - val_loss: 20.9838\n",
      "Epoch 275/1000\n",
      "23485/23485 - 71s - loss: 23.2120 - val_loss: 20.9740\n",
      "Epoch 276/1000\n",
      "23485/23485 - 76s - loss: 23.2098 - val_loss: 21.1900\n",
      "Epoch 277/1000\n",
      "23485/23485 - 73s - loss: 23.2189 - val_loss: 21.0025\n",
      "Epoch 278/1000\n",
      "23485/23485 - 73s - loss: 23.2185 - val_loss: 21.0114\n",
      "Epoch 279/1000\n",
      "23485/23485 - 73s - loss: 23.2106 - val_loss: 20.9217\n",
      "Epoch 280/1000\n",
      "23485/23485 - 74s - loss: 23.2127 - val_loss: 20.9777\n",
      "Epoch 281/1000\n",
      "23485/23485 - 84s - loss: 23.2071 - val_loss: 21.1440\n",
      "Epoch 282/1000\n",
      "23485/23485 - 90s - loss: 23.2105 - val_loss: 21.0030\n",
      "Epoch 283/1000\n",
      "23485/23485 - 87s - loss: 23.2097 - val_loss: 21.0248\n",
      "Epoch 284/1000\n",
      "23485/23485 - 86s - loss: 23.2164 - val_loss: 20.9801\n",
      "Epoch 285/1000\n",
      "23485/23485 - 81s - loss: 23.2129 - val_loss: 21.1252\n",
      "Epoch 286/1000\n",
      "23485/23485 - 79s - loss: 23.1995 - val_loss: 21.2990\n",
      "Epoch 287/1000\n",
      "23485/23485 - 80s - loss: 23.1987 - val_loss: 20.8894\n",
      "Epoch 288/1000\n",
      "23485/23485 - 79s - loss: 23.2007 - val_loss: 20.9586\n",
      "Epoch 289/1000\n",
      "23485/23485 - 79s - loss: 23.2008 - val_loss: 20.9198\n",
      "Epoch 290/1000\n",
      "23485/23485 - 89s - loss: 23.2044 - val_loss: 20.9543\n",
      "Epoch 291/1000\n",
      "23485/23485 - 88s - loss: 23.2016 - val_loss: 20.9791\n",
      "Epoch 292/1000\n",
      "23485/23485 - 83s - loss: 23.2009 - val_loss: 20.9401\n",
      "Epoch 293/1000\n",
      "23485/23485 - 75s - loss: 23.2016 - val_loss: 21.0342\n",
      "Epoch 294/1000\n",
      "23485/23485 - 73s - loss: 23.1954 - val_loss: 21.1001\n",
      "Epoch 295/1000\n",
      "23485/23485 - 74s - loss: 23.1996 - val_loss: 21.1249\n",
      "Epoch 296/1000\n",
      "23485/23485 - 73s - loss: 23.1993 - val_loss: 20.9198\n",
      "Epoch 297/1000\n",
      "23485/23485 - 76s - loss: 23.1874 - val_loss: 20.8722\n",
      "Epoch 298/1000\n",
      "23485/23485 - 73s - loss: 23.1964 - val_loss: 21.0067\n",
      "Epoch 299/1000\n",
      "23485/23485 - 74s - loss: 23.1875 - val_loss: 21.1660\n",
      "Epoch 300/1000\n",
      "23485/23485 - 74s - loss: 23.2069 - val_loss: 20.8962\n",
      "Epoch 301/1000\n",
      "23485/23485 - 79s - loss: 23.1893 - val_loss: 21.1767\n",
      "Epoch 302/1000\n",
      "23485/23485 - 81s - loss: 23.1919 - val_loss: 21.0510\n",
      "Epoch 303/1000\n",
      "23485/23485 - 84s - loss: 23.1977 - val_loss: 21.3138\n",
      "Epoch 304/1000\n",
      "23485/23485 - 85s - loss: 23.1891 - val_loss: 20.9389\n",
      "Epoch 305/1000\n",
      "23485/23485 - 71s - loss: 23.1901 - val_loss: 20.9988\n",
      "Epoch 306/1000\n",
      "23485/23485 - 69s - loss: 23.1840 - val_loss: 20.7734\n",
      "Epoch 307/1000\n",
      "23485/23485 - 71s - loss: 23.1944 - val_loss: 20.8638\n",
      "Epoch 308/1000\n",
      "23485/23485 - 70s - loss: 23.1904 - val_loss: 20.8811\n",
      "Epoch 309/1000\n",
      "23485/23485 - 69s - loss: 23.1782 - val_loss: 20.9330\n",
      "Epoch 310/1000\n",
      "23485/23485 - 69s - loss: 23.1872 - val_loss: 20.9606\n",
      "Epoch 311/1000\n",
      "23485/23485 - 69s - loss: 23.1856 - val_loss: 20.7962\n",
      "Epoch 312/1000\n",
      "23485/23485 - 69s - loss: 23.1851 - val_loss: 20.9308\n",
      "Epoch 313/1000\n",
      "23485/23485 - 69s - loss: 23.1809 - val_loss: 20.9907\n",
      "Epoch 314/1000\n",
      "23485/23485 - 69s - loss: 23.1847 - val_loss: 20.9039\n",
      "Epoch 315/1000\n",
      "23485/23485 - 69s - loss: 23.1781 - val_loss: 21.1528\n",
      "Epoch 316/1000\n",
      "23485/23485 - 69s - loss: 23.1755 - val_loss: 20.8328\n",
      "Epoch 317/1000\n",
      "23485/23485 - 69s - loss: 23.1818 - val_loss: 20.9630\n",
      "Epoch 318/1000\n",
      "23485/23485 - 69s - loss: 23.1758 - val_loss: 20.8396\n",
      "Epoch 319/1000\n",
      "23485/23485 - 69s - loss: 23.1730 - val_loss: 21.1039\n",
      "Epoch 320/1000\n",
      "23485/23485 - 71s - loss: 23.1876 - val_loss: 20.7920\n",
      "Epoch 321/1000\n",
      "23485/23485 - 71s - loss: 23.1717 - val_loss: 20.9027\n",
      "Epoch 322/1000\n",
      "23485/23485 - 69s - loss: 23.1694 - val_loss: 21.1389\n",
      "Epoch 323/1000\n",
      "23485/23485 - 69s - loss: 23.1715 - val_loss: 20.8559\n",
      "Epoch 324/1000\n",
      "23485/23485 - 69s - loss: 23.1673 - val_loss: 20.8520\n",
      "Epoch 325/1000\n",
      "23485/23485 - 69s - loss: 23.1627 - val_loss: 21.0345\n",
      "Epoch 326/1000\n",
      "23485/23485 - 69s - loss: 23.1662 - val_loss: 20.8083\n",
      "Epoch 327/1000\n",
      "23485/23485 - 69s - loss: 23.1613 - val_loss: 20.9976\n",
      "Epoch 328/1000\n",
      "23485/23485 - 69s - loss: 23.1589 - val_loss: 20.8970\n",
      "Epoch 329/1000\n",
      "23485/23485 - 69s - loss: 23.1664 - val_loss: 20.7493\n",
      "Epoch 330/1000\n",
      "23485/23485 - 69s - loss: 23.1698 - val_loss: 21.2222\n",
      "Epoch 331/1000\n",
      "23485/23485 - 69s - loss: 23.1648 - val_loss: 20.9638\n",
      "Epoch 332/1000\n",
      "23485/23485 - 69s - loss: 23.1534 - val_loss: 20.9335\n",
      "Epoch 333/1000\n",
      "23485/23485 - 69s - loss: 23.1459 - val_loss: 20.9485\n",
      "Epoch 334/1000\n",
      "23485/23485 - 70s - loss: 23.1508 - val_loss: 21.0086\n",
      "Epoch 335/1000\n",
      "23485/23485 - 69s - loss: 23.1496 - val_loss: 21.1475\n",
      "Epoch 336/1000\n",
      "23485/23485 - 73s - loss: 23.1507 - val_loss: 20.8045\n",
      "Epoch 337/1000\n",
      "23485/23485 - 73s - loss: 23.1531 - val_loss: 20.7365\n",
      "Epoch 338/1000\n",
      "23485/23485 - 70s - loss: 23.1555 - val_loss: 20.9883\n",
      "Epoch 339/1000\n",
      "23485/23485 - 69s - loss: 23.1435 - val_loss: 20.9933\n",
      "Epoch 340/1000\n",
      "23485/23485 - 69s - loss: 23.1498 - val_loss: 20.8952\n",
      "Epoch 341/1000\n",
      "23485/23485 - 69s - loss: 23.1439 - val_loss: 20.8394\n",
      "Epoch 342/1000\n",
      "23485/23485 - 69s - loss: 23.1409 - val_loss: 21.0768\n",
      "Epoch 343/1000\n",
      "23485/23485 - 69s - loss: 23.1457 - val_loss: 20.8331\n",
      "Epoch 344/1000\n",
      "23485/23485 - 69s - loss: 23.1517 - val_loss: 20.8030\n",
      "Epoch 345/1000\n",
      "23485/23485 - 70s - loss: 23.1476 - val_loss: 20.7634\n",
      "Epoch 346/1000\n",
      "23485/23485 - 69s - loss: 23.1478 - val_loss: 21.0819\n",
      "Epoch 347/1000\n",
      "23485/23485 - 70s - loss: 23.1440 - val_loss: 20.9906\n",
      "Epoch 348/1000\n",
      "23485/23485 - 70s - loss: 23.1434 - val_loss: 21.1163\n",
      "Epoch 349/1000\n",
      "23485/23485 - 72s - loss: 23.1433 - val_loss: 20.9476\n",
      "Epoch 350/1000\n",
      "23485/23485 - 84s - loss: 23.1497 - val_loss: 20.9673\n",
      "Epoch 351/1000\n",
      "23485/23485 - 83s - loss: 23.1442 - val_loss: 21.0187\n",
      "Epoch 352/1000\n",
      "23485/23485 - 83s - loss: 23.1467 - val_loss: 21.2702\n",
      "Epoch 353/1000\n",
      "23485/23485 - 69s - loss: 23.1505 - val_loss: 20.7665\n",
      "Epoch 354/1000\n",
      "23485/23485 - 70s - loss: 23.1423 - val_loss: 20.9854\n",
      "Epoch 355/1000\n",
      "23485/23485 - 70s - loss: 23.1399 - val_loss: 20.9182\n",
      "Epoch 356/1000\n",
      "23485/23485 - 69s - loss: 23.1537 - val_loss: 20.9791\n",
      "Epoch 357/1000\n",
      "23485/23485 - 69s - loss: 23.1504 - val_loss: 21.0261\n",
      "Epoch 358/1000\n",
      "23485/23485 - 70s - loss: 23.1398 - val_loss: 21.0324\n",
      "Epoch 359/1000\n",
      "23485/23485 - 70s - loss: 23.1383 - val_loss: 20.8227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/1000\n",
      "23485/23485 - 69s - loss: 23.1378 - val_loss: 21.0697\n",
      "Epoch 361/1000\n",
      "23485/23485 - 70s - loss: 23.1484 - val_loss: 20.8507\n",
      "Epoch 362/1000\n",
      "23485/23485 - 69s - loss: 23.1360 - val_loss: 20.9990\n",
      "Epoch 363/1000\n",
      "23485/23485 - 70s - loss: 23.1365 - val_loss: 20.6949\n",
      "Epoch 364/1000\n",
      "23485/23485 - 69s - loss: 23.1435 - val_loss: 20.9696\n",
      "Epoch 365/1000\n",
      "23485/23485 - 69s - loss: 23.1382 - val_loss: 20.8015\n",
      "Epoch 366/1000\n",
      "23485/23485 - 69s - loss: 23.1402 - val_loss: 20.9786\n",
      "Epoch 367/1000\n",
      "23485/23485 - 69s - loss: 23.1372 - val_loss: 20.8186\n",
      "Epoch 368/1000\n",
      "23485/23485 - 70s - loss: 23.1320 - val_loss: 20.9283\n",
      "Epoch 369/1000\n",
      "23485/23485 - 73s - loss: 23.1369 - val_loss: 20.8489\n",
      "Epoch 370/1000\n",
      "23485/23485 - 70s - loss: 23.1326 - val_loss: 20.8800\n",
      "Epoch 371/1000\n",
      "23485/23485 - 70s - loss: 23.1323 - val_loss: 20.8033\n",
      "Epoch 372/1000\n",
      "23485/23485 - 71s - loss: 23.1403 - val_loss: 21.2034\n",
      "Epoch 373/1000\n",
      "23485/23485 - 70s - loss: 23.1314 - val_loss: 20.9265\n",
      "Epoch 374/1000\n",
      "23485/23485 - 71s - loss: 23.1241 - val_loss: 20.8198\n",
      "Epoch 375/1000\n",
      "23485/23485 - 70s - loss: 23.1267 - val_loss: 20.9643\n",
      "Epoch 376/1000\n",
      "23485/23485 - 70s - loss: 23.1273 - val_loss: 20.9187\n",
      "Epoch 377/1000\n",
      "23485/23485 - 70s - loss: 23.1276 - val_loss: 20.8660\n",
      "Epoch 378/1000\n",
      "23485/23485 - 70s - loss: 23.1333 - val_loss: 21.0244\n",
      "Epoch 379/1000\n",
      "23485/23485 - 70s - loss: 23.1278 - val_loss: 20.6533\n",
      "Epoch 380/1000\n",
      "23485/23485 - 70s - loss: 23.1237 - val_loss: 20.8203\n",
      "Epoch 381/1000\n",
      "23485/23485 - 70s - loss: 23.1209 - val_loss: 20.8625\n",
      "Epoch 382/1000\n",
      "23485/23485 - 70s - loss: 23.1308 - val_loss: 21.0049\n",
      "Epoch 383/1000\n",
      "23485/23485 - 70s - loss: 23.1231 - val_loss: 20.7955\n",
      "Epoch 384/1000\n",
      "23485/23485 - 70s - loss: 23.1193 - val_loss: 20.7765\n",
      "Epoch 385/1000\n",
      "23485/23485 - 70s - loss: 23.1228 - val_loss: 20.7137\n",
      "Epoch 386/1000\n",
      "23485/23485 - 70s - loss: 23.1111 - val_loss: 20.8963\n",
      "Epoch 387/1000\n",
      "23485/23485 - 70s - loss: 23.1223 - val_loss: 20.7708\n",
      "Epoch 388/1000\n",
      "23485/23485 - 70s - loss: 23.1164 - val_loss: 20.9679\n",
      "Epoch 389/1000\n",
      "23485/23485 - 71s - loss: 23.1176 - val_loss: 20.9717\n",
      "Epoch 390/1000\n",
      "23485/23485 - 70s - loss: 23.1266 - val_loss: 20.8708\n",
      "Epoch 391/1000\n",
      "23485/23485 - 70s - loss: 23.1232 - val_loss: 20.8085\n",
      "Epoch 392/1000\n",
      "23485/23485 - 70s - loss: 23.1223 - val_loss: 20.8224\n",
      "Epoch 393/1000\n",
      "23485/23485 - 70s - loss: 23.1170 - val_loss: 21.2905\n",
      "Epoch 394/1000\n",
      "23485/23485 - 69s - loss: 23.1228 - val_loss: 20.9722\n",
      "Epoch 395/1000\n",
      "23485/23485 - 70s - loss: 23.1092 - val_loss: 20.8894\n",
      "Epoch 396/1000\n",
      "23485/23485 - 70s - loss: 23.1144 - val_loss: 20.6706\n",
      "Epoch 397/1000\n",
      "23485/23485 - 70s - loss: 23.1197 - val_loss: 20.9340\n",
      "Epoch 398/1000\n",
      "23485/23485 - 70s - loss: 23.1177 - val_loss: 20.8385\n",
      "Epoch 399/1000\n",
      "23485/23485 - 70s - loss: 23.1151 - val_loss: 20.8027\n",
      "Epoch 400/1000\n",
      "23485/23485 - 70s - loss: 23.1139 - val_loss: 20.7233\n",
      "Epoch 401/1000\n",
      "23485/23485 - 70s - loss: 23.1144 - val_loss: 20.7879\n",
      "Epoch 402/1000\n",
      "23485/23485 - 71s - loss: 23.1113 - val_loss: 20.9448\n",
      "Epoch 403/1000\n",
      "23485/23485 - 70s - loss: 23.1136 - val_loss: 20.8869\n",
      "Epoch 404/1000\n",
      "23485/23485 - 70s - loss: 23.1146 - val_loss: 20.8278\n",
      "Epoch 405/1000\n",
      "23485/23485 - 69s - loss: 23.1161 - val_loss: 21.2344\n",
      "Epoch 406/1000\n",
      "23485/23485 - 70s - loss: 23.1181 - val_loss: 20.7884\n",
      "Epoch 407/1000\n",
      "23485/23485 - 70s - loss: 23.1099 - val_loss: 20.9004\n",
      "Epoch 408/1000\n",
      "23485/23485 - 70s - loss: 23.1152 - val_loss: 20.8592\n",
      "Epoch 409/1000\n",
      "23485/23485 - 70s - loss: 23.1093 - val_loss: 20.8032\n",
      "Epoch 410/1000\n",
      "23485/23485 - 71s - loss: 23.1071 - val_loss: 20.9468\n",
      "Epoch 411/1000\n",
      "23485/23485 - 70s - loss: 23.1222 - val_loss: 21.0595\n",
      "Epoch 412/1000\n",
      "23485/23485 - 70s - loss: 23.1007 - val_loss: 20.9070\n",
      "Epoch 413/1000\n",
      "23485/23485 - 70s - loss: 23.1137 - val_loss: 20.8156\n",
      "Epoch 414/1000\n",
      "23485/23485 - 69s - loss: 23.1109 - val_loss: 20.7430\n",
      "Epoch 415/1000\n",
      "23485/23485 - 70s - loss: 23.1040 - val_loss: 20.6912\n",
      "Epoch 416/1000\n",
      "23485/23485 - 69s - loss: 23.1065 - val_loss: 20.8701\n",
      "Epoch 417/1000\n",
      "23485/23485 - 70s - loss: 23.1036 - val_loss: 20.6366\n",
      "Epoch 418/1000\n",
      "23485/23485 - 70s - loss: 23.1086 - val_loss: 20.9984\n",
      "Epoch 419/1000\n",
      "23485/23485 - 70s - loss: 23.1057 - val_loss: 20.8905\n",
      "Epoch 420/1000\n",
      "23485/23485 - 72s - loss: 23.1022 - val_loss: 20.7145\n",
      "Epoch 421/1000\n",
      "23485/23485 - 69s - loss: 23.1120 - val_loss: 20.8178\n",
      "Epoch 422/1000\n",
      "23485/23485 - 69s - loss: 23.1065 - val_loss: 20.9589\n",
      "Epoch 423/1000\n",
      "23485/23485 - 70s - loss: 23.1031 - val_loss: 20.5591\n",
      "Epoch 424/1000\n",
      "23485/23485 - 70s - loss: 23.1006 - val_loss: 20.7679\n",
      "Epoch 425/1000\n",
      "23485/23485 - 70s - loss: 23.0981 - val_loss: 20.7908\n",
      "Epoch 426/1000\n",
      "23485/23485 - 70s - loss: 23.1050 - val_loss: 20.7810\n",
      "Epoch 427/1000\n",
      "23485/23485 - 70s - loss: 23.1076 - val_loss: 20.7459\n",
      "Epoch 428/1000\n",
      "23485/23485 - 70s - loss: 23.1013 - val_loss: 20.7952\n",
      "Epoch 429/1000\n",
      "23485/23485 - 70s - loss: 23.1049 - val_loss: 20.8995\n",
      "Epoch 430/1000\n",
      "23485/23485 - 70s - loss: 23.0998 - val_loss: 20.8135\n",
      "Epoch 431/1000\n",
      "23485/23485 - 70s - loss: 23.1021 - val_loss: 20.8392\n",
      "Epoch 432/1000\n",
      "23485/23485 - 69s - loss: 23.1000 - val_loss: 20.7543\n",
      "Epoch 433/1000\n",
      "23485/23485 - 69s - loss: 23.1080 - val_loss: 20.7784\n",
      "Epoch 434/1000\n",
      "23485/23485 - 70s - loss: 23.1069 - val_loss: 20.7939\n",
      "Epoch 435/1000\n",
      "23485/23485 - 69s - loss: 23.0969 - val_loss: 20.9960\n",
      "Epoch 436/1000\n",
      "23485/23485 - 69s - loss: 23.1117 - val_loss: 20.7337\n",
      "Epoch 437/1000\n",
      "23485/23485 - 70s - loss: 23.0939 - val_loss: 20.7638\n",
      "Epoch 438/1000\n",
      "23485/23485 - 70s - loss: 23.1019 - val_loss: 20.8031\n",
      "Epoch 439/1000\n",
      "23485/23485 - 70s - loss: 23.1058 - val_loss: 20.8761\n",
      "Epoch 440/1000\n",
      "23485/23485 - 70s - loss: 23.1050 - val_loss: 20.5684\n",
      "Epoch 441/1000\n",
      "23485/23485 - 70s - loss: 23.1082 - val_loss: 20.7452\n",
      "Epoch 442/1000\n",
      "23485/23485 - 70s - loss: 23.1014 - val_loss: 20.9358\n",
      "Epoch 443/1000\n",
      "23485/23485 - 70s - loss: 23.0969 - val_loss: 20.9429\n",
      "Epoch 444/1000\n",
      "23485/23485 - 70s - loss: 23.0926 - val_loss: 20.7951\n",
      "Epoch 445/1000\n",
      "23485/23485 - 70s - loss: 23.1006 - val_loss: 20.6880\n",
      "Epoch 446/1000\n",
      "23485/23485 - 75s - loss: 23.0983 - val_loss: 20.6882\n",
      "Epoch 447/1000\n",
      "23485/23485 - 86s - loss: 23.1037 - val_loss: 20.9767\n",
      "Epoch 448/1000\n",
      "23485/23485 - 82s - loss: 23.0986 - val_loss: 20.6884\n",
      "Epoch 449/1000\n",
      "23485/23485 - 73s - loss: 23.0897 - val_loss: 20.6864\n",
      "Epoch 450/1000\n",
      "23485/23485 - 72s - loss: 23.0923 - val_loss: 20.8532\n",
      "Epoch 451/1000\n",
      "23485/23485 - 72s - loss: 23.0983 - val_loss: 20.7099\n",
      "Epoch 452/1000\n",
      "23485/23485 - 75s - loss: 23.0941 - val_loss: 20.7838\n",
      "Epoch 453/1000\n",
      "23485/23485 - 76s - loss: 23.0974 - val_loss: 20.9386\n",
      "Epoch 454/1000\n",
      "23485/23485 - 87s - loss: 23.0988 - val_loss: 20.6551\n",
      "Epoch 455/1000\n",
      "23485/23485 - 85s - loss: 23.1004 - val_loss: 20.7361\n",
      "Epoch 456/1000\n",
      "23485/23485 - 84s - loss: 23.1029 - val_loss: 20.8805\n",
      "Epoch 457/1000\n",
      "23485/23485 - 80s - loss: 23.0894 - val_loss: 20.9829\n",
      "Epoch 458/1000\n",
      "23485/23485 - 73s - loss: 23.0785 - val_loss: 20.8787\n",
      "Epoch 459/1000\n",
      "23485/23485 - 78s - loss: 23.0988 - val_loss: 20.7005\n",
      "Epoch 460/1000\n",
      "23485/23485 - 81s - loss: 23.0981 - val_loss: 20.6063\n",
      "Epoch 461/1000\n",
      "23485/23485 - 73s - loss: 23.1021 - val_loss: 20.6374\n",
      "Epoch 462/1000\n",
      "23485/23485 - 73s - loss: 23.0886 - val_loss: 20.9576\n",
      "Epoch 463/1000\n",
      "23485/23485 - 73s - loss: 23.0931 - val_loss: 20.7066\n",
      "Epoch 464/1000\n",
      "23485/23485 - 74s - loss: 23.0946 - val_loss: 20.9518\n",
      "Epoch 465/1000\n",
      "23485/23485 - 73s - loss: 23.0940 - val_loss: 20.7016\n",
      "Epoch 466/1000\n",
      "23485/23485 - 76s - loss: 23.0965 - val_loss: 20.7981\n",
      "Epoch 467/1000\n",
      "23485/23485 - 76s - loss: 23.0889 - val_loss: 20.8108\n",
      "Epoch 468/1000\n",
      "23485/23485 - 77s - loss: 23.1011 - val_loss: 20.9077\n",
      "Epoch 469/1000\n",
      "23485/23485 - 75s - loss: 23.0938 - val_loss: 20.6211\n",
      "Epoch 470/1000\n",
      "23485/23485 - 76s - loss: 23.0935 - val_loss: 21.0042\n",
      "Epoch 471/1000\n",
      "23485/23485 - 76s - loss: 23.0934 - val_loss: 21.0010\n",
      "Epoch 472/1000\n",
      "23485/23485 - 76s - loss: 23.0980 - val_loss: 20.8085\n",
      "Epoch 473/1000\n",
      "23485/23485 - 75s - loss: 23.0870 - val_loss: 20.6528\n",
      "Epoch 474/1000\n",
      "23485/23485 - 73s - loss: 23.0915 - val_loss: 20.6251\n",
      "Epoch 475/1000\n",
      "23485/23485 - 72s - loss: 23.0842 - val_loss: 20.7106\n",
      "Epoch 476/1000\n",
      "23485/23485 - 77s - loss: 23.0878 - val_loss: 20.8929\n",
      "Epoch 477/1000\n",
      "23485/23485 - 76s - loss: 23.0950 - val_loss: 20.9215\n",
      "Epoch 478/1000\n",
      "23485/23485 - 74s - loss: 23.0883 - val_loss: 20.6393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/1000\n",
      "23485/23485 - 74s - loss: 23.0927 - val_loss: 20.7745\n",
      "Epoch 480/1000\n",
      "23485/23485 - 74s - loss: 23.0931 - val_loss: 20.7766\n",
      "Epoch 481/1000\n",
      "23485/23485 - 74s - loss: 23.0920 - val_loss: 20.6794\n",
      "Epoch 482/1000\n",
      "23485/23485 - 73s - loss: 23.0878 - val_loss: 20.7189\n",
      "Epoch 483/1000\n",
      "23485/23485 - 74s - loss: 23.0883 - val_loss: 20.6416\n",
      "Epoch 484/1000\n",
      "23485/23485 - 74s - loss: 23.0841 - val_loss: 20.7749\n",
      "Epoch 485/1000\n",
      "23485/23485 - 74s - loss: 23.0886 - val_loss: 20.8961\n",
      "Epoch 486/1000\n",
      "23485/23485 - 74s - loss: 23.0948 - val_loss: 20.6792\n",
      "Epoch 487/1000\n",
      "23485/23485 - 81s - loss: 23.0868 - val_loss: 20.7020\n",
      "Epoch 488/1000\n",
      "23485/23485 - 76s - loss: 23.0878 - val_loss: 20.9738\n",
      "Epoch 489/1000\n",
      "23485/23485 - 75s - loss: 23.0928 - val_loss: 20.9504\n",
      "Epoch 490/1000\n",
      "23485/23485 - 74s - loss: 23.0829 - val_loss: 20.8366\n",
      "Epoch 491/1000\n",
      "23485/23485 - 75s - loss: 23.0896 - val_loss: 20.7240\n",
      "Epoch 492/1000\n",
      "23485/23485 - 75s - loss: 23.0840 - val_loss: 20.7569\n",
      "Epoch 493/1000\n",
      "23485/23485 - 78s - loss: 23.0805 - val_loss: 20.8581\n",
      "Epoch 494/1000\n",
      "23485/23485 - 74s - loss: 23.0846 - val_loss: 20.7327\n",
      "Epoch 495/1000\n",
      "23485/23485 - 80s - loss: 23.0809 - val_loss: 20.9113\n",
      "Epoch 496/1000\n",
      "23485/23485 - 74s - loss: 23.0810 - val_loss: 20.8266\n",
      "Epoch 497/1000\n",
      "23485/23485 - 78s - loss: 23.0787 - val_loss: 20.6703\n",
      "Epoch 498/1000\n",
      "23485/23485 - 76s - loss: 23.1016 - val_loss: 20.8397\n",
      "Epoch 499/1000\n",
      "23485/23485 - 76s - loss: 23.0911 - val_loss: 20.8971\n",
      "Epoch 500/1000\n",
      "23485/23485 - 79s - loss: 23.0801 - val_loss: 20.7476\n",
      "Epoch 501/1000\n",
      "23485/23485 - 76s - loss: 23.0840 - val_loss: 20.7217\n",
      "Epoch 502/1000\n",
      "23485/23485 - 78s - loss: 23.0822 - val_loss: 20.7864\n",
      "Epoch 503/1000\n",
      "23485/23485 - 76s - loss: 23.0905 - val_loss: 20.7625\n",
      "Epoch 504/1000\n",
      "23485/23485 - 74s - loss: 23.0856 - val_loss: 20.7620\n",
      "Epoch 505/1000\n",
      "23485/23485 - 75s - loss: 23.0832 - val_loss: 20.9117\n",
      "Epoch 506/1000\n",
      "23485/23485 - 77s - loss: 23.0780 - val_loss: 20.7478\n",
      "Epoch 507/1000\n",
      "23485/23485 - 76s - loss: 23.0774 - val_loss: 20.8213\n",
      "Epoch 508/1000\n",
      "23485/23485 - 72s - loss: 23.0847 - val_loss: 20.6234\n",
      "Epoch 509/1000\n",
      "23485/23485 - 73s - loss: 23.0759 - val_loss: 20.5573\n",
      "Epoch 510/1000\n",
      "23485/23485 - 74s - loss: 23.0803 - val_loss: 20.6172\n",
      "Epoch 511/1000\n",
      "23485/23485 - 75s - loss: 23.0752 - val_loss: 20.7865\n",
      "Epoch 512/1000\n",
      "23485/23485 - 76s - loss: 23.0694 - val_loss: 20.6375\n",
      "Epoch 513/1000\n",
      "23485/23485 - 75s - loss: 23.0772 - val_loss: 20.7776\n",
      "Epoch 514/1000\n",
      "23485/23485 - 75s - loss: 23.0789 - val_loss: 20.8041\n",
      "Epoch 515/1000\n",
      "23485/23485 - 75s - loss: 23.0770 - val_loss: 20.8509\n",
      "Epoch 516/1000\n",
      "23485/23485 - 75s - loss: 23.0836 - val_loss: 20.9060\n",
      "Epoch 517/1000\n",
      "23485/23485 - 75s - loss: 23.0880 - val_loss: 20.6957\n",
      "Epoch 518/1000\n",
      "23485/23485 - 75s - loss: 23.0785 - val_loss: 20.9972\n",
      "Epoch 519/1000\n",
      "23485/23485 - 74s - loss: 23.0769 - val_loss: 20.7561\n",
      "Epoch 520/1000\n",
      "23485/23485 - 75s - loss: 23.0846 - val_loss: 20.8034\n",
      "Epoch 521/1000\n",
      "23485/23485 - 75s - loss: 23.0784 - val_loss: 20.8296\n",
      "Epoch 522/1000\n",
      "23485/23485 - 76s - loss: 23.0843 - val_loss: 20.5971\n",
      "Epoch 523/1000\n",
      "23485/23485 - 70s - loss: 23.0786 - val_loss: 20.7409\n",
      "Epoch 524/1000\n",
      "23485/23485 - 70s - loss: 23.0737 - val_loss: 20.7198\n",
      "Epoch 525/1000\n",
      "23485/23485 - 70s - loss: 23.0790 - val_loss: 20.7869\n",
      "Epoch 526/1000\n",
      "23485/23485 - 71s - loss: 23.0801 - val_loss: 20.6755\n",
      "Epoch 527/1000\n",
      "23485/23485 - 80s - loss: 23.0753 - val_loss: 20.7669\n",
      "Epoch 528/1000\n",
      "23485/23485 - 77s - loss: 23.0759 - val_loss: 20.9431\n",
      "Epoch 529/1000\n",
      "23485/23485 - 71s - loss: 23.0778 - val_loss: 20.6201\n",
      "Epoch 530/1000\n",
      "23485/23485 - 70s - loss: 23.0730 - val_loss: 20.6427\n",
      "Epoch 531/1000\n",
      "23485/23485 - 71s - loss: 23.0719 - val_loss: 20.5430\n",
      "Epoch 532/1000\n",
      "23485/23485 - 71s - loss: 23.0682 - val_loss: 20.8293\n",
      "Epoch 533/1000\n",
      "23485/23485 - 71s - loss: 23.0780 - val_loss: 20.8508\n",
      "Epoch 534/1000\n",
      "23485/23485 - 70s - loss: 23.0625 - val_loss: 20.5867\n",
      "Epoch 535/1000\n",
      "23485/23485 - 81s - loss: 23.0699 - val_loss: 20.7016\n",
      "Epoch 536/1000\n",
      "23485/23485 - 81s - loss: 23.0528 - val_loss: 20.8335\n",
      "Epoch 537/1000\n",
      "23485/23485 - 79s - loss: 23.0396 - val_loss: 20.5218\n",
      "Epoch 538/1000\n",
      "23485/23485 - 80s - loss: 23.0362 - val_loss: 20.6012\n",
      "Epoch 539/1000\n",
      "23485/23485 - 86s - loss: 23.0284 - val_loss: 20.4051\n",
      "Epoch 540/1000\n",
      "23485/23485 - 92s - loss: 23.0240 - val_loss: 20.6985\n",
      "Epoch 541/1000\n",
      "23485/23485 - 87s - loss: 23.0174 - val_loss: 20.5161\n",
      "Epoch 542/1000\n",
      "23485/23485 - 86s - loss: 23.0201 - val_loss: 20.7951\n",
      "Epoch 543/1000\n",
      "23485/23485 - 82s - loss: 23.0053 - val_loss: 20.4627\n",
      "Epoch 544/1000\n",
      "23485/23485 - 86s - loss: 23.0010 - val_loss: 20.4817\n",
      "Epoch 545/1000\n",
      "23485/23485 - 80s - loss: 23.0037 - val_loss: 20.6777\n",
      "Epoch 546/1000\n",
      "23485/23485 - 83s - loss: 22.9993 - val_loss: 20.7495\n",
      "Epoch 547/1000\n",
      "23485/23485 - 82s - loss: 22.9896 - val_loss: 20.6382\n",
      "Epoch 548/1000\n",
      "23485/23485 - 81s - loss: 22.9909 - val_loss: 20.6969\n",
      "Epoch 549/1000\n",
      "23485/23485 - 89s - loss: 22.9976 - val_loss: 20.4990\n",
      "Epoch 550/1000\n",
      "23485/23485 - 77s - loss: 22.9964 - val_loss: 20.7155\n",
      "Epoch 551/1000\n",
      "23485/23485 - 72s - loss: 22.9879 - val_loss: 20.6628\n",
      "Epoch 552/1000\n",
      "23485/23485 - 76s - loss: 22.9750 - val_loss: 20.7011\n",
      "Epoch 553/1000\n",
      "23485/23485 - 74s - loss: 22.9811 - val_loss: 20.7954\n",
      "Epoch 554/1000\n",
      "23485/23485 - 81s - loss: 22.9862 - val_loss: 20.6891\n",
      "Epoch 555/1000\n",
      "23485/23485 - 76s - loss: 22.9842 - val_loss: 20.5291\n",
      "Epoch 556/1000\n",
      "23485/23485 - 73s - loss: 22.9826 - val_loss: 20.4722\n",
      "Epoch 557/1000\n",
      "23485/23485 - 76s - loss: 22.9768 - val_loss: 20.4646\n",
      "Epoch 558/1000\n",
      "23485/23485 - 73s - loss: 22.9783 - val_loss: 20.4054\n",
      "Epoch 559/1000\n",
      "23485/23485 - 71s - loss: 22.9878 - val_loss: 20.4294\n",
      "Epoch 560/1000\n",
      "23485/23485 - 72s - loss: 22.9805 - val_loss: 20.7996\n",
      "Epoch 561/1000\n",
      "23485/23485 - 72s - loss: 22.9781 - val_loss: 20.5452\n",
      "Epoch 562/1000\n",
      "23485/23485 - 80s - loss: 22.9818 - val_loss: 20.6631\n",
      "Epoch 563/1000\n",
      "23485/23485 - 78s - loss: 22.9768 - val_loss: 20.5945\n",
      "Epoch 564/1000\n",
      "23485/23485 - 74s - loss: 22.9793 - val_loss: 20.4928\n",
      "Epoch 565/1000\n",
      "23485/23485 - 78s - loss: 22.9793 - val_loss: 20.5776\n",
      "Epoch 566/1000\n",
      "23485/23485 - 76s - loss: 22.9714 - val_loss: 20.4453\n",
      "Epoch 567/1000\n",
      "23485/23485 - 79s - loss: 22.9746 - val_loss: 20.4835\n",
      "Epoch 568/1000\n",
      "23485/23485 - 75s - loss: 22.9780 - val_loss: 20.6145\n",
      "Epoch 569/1000\n",
      "23485/23485 - 73s - loss: 22.9574 - val_loss: 20.5754\n",
      "Epoch 570/1000\n",
      "23485/23485 - 74s - loss: 22.9383 - val_loss: 20.6413\n",
      "Epoch 571/1000\n",
      "23485/23485 - 82s - loss: 22.9332 - val_loss: 20.5298\n",
      "Epoch 572/1000\n",
      "23485/23485 - 86s - loss: 22.9332 - val_loss: 20.7295\n",
      "Epoch 573/1000\n",
      "23485/23485 - 80s - loss: 22.9273 - val_loss: 20.4827\n",
      "Epoch 574/1000\n",
      "23485/23485 - 77s - loss: 22.9211 - val_loss: 20.5866\n",
      "Epoch 575/1000\n",
      "23485/23485 - 77s - loss: 22.9271 - val_loss: 20.6558\n",
      "Epoch 576/1000\n",
      "23485/23485 - 76s - loss: 22.9310 - val_loss: 20.4841\n",
      "Epoch 577/1000\n",
      "23485/23485 - 74s - loss: 22.9295 - val_loss: 20.5835\n",
      "Epoch 578/1000\n",
      "23485/23485 - 76s - loss: 22.9238 - val_loss: 20.7906\n",
      "Epoch 579/1000\n",
      "23485/23485 - 75s - loss: 22.9165 - val_loss: 20.4958\n",
      "Epoch 580/1000\n",
      "23485/23485 - 75s - loss: 22.9187 - val_loss: 20.7073\n",
      "Epoch 581/1000\n",
      "23485/23485 - 76s - loss: 22.9286 - val_loss: 20.5155\n",
      "Epoch 582/1000\n",
      "23485/23485 - 74s - loss: 22.9124 - val_loss: 20.7037\n",
      "Epoch 583/1000\n",
      "23485/23485 - 71s - loss: 22.9233 - val_loss: 20.4341\n",
      "Epoch 584/1000\n",
      "23485/23485 - 71s - loss: 22.9255 - val_loss: 20.3907\n",
      "Epoch 585/1000\n",
      "23485/23485 - 72s - loss: 22.9216 - val_loss: 20.4093\n",
      "Epoch 586/1000\n",
      "23485/23485 - 71s - loss: 22.9168 - val_loss: 20.7006\n",
      "Epoch 587/1000\n",
      "23485/23485 - 71s - loss: 22.9130 - val_loss: 20.5006\n",
      "Epoch 588/1000\n",
      "23485/23485 - 71s - loss: 22.9247 - val_loss: 20.4652\n",
      "Epoch 589/1000\n",
      "23485/23485 - 71s - loss: 22.9134 - val_loss: 20.4114\n",
      "Epoch 590/1000\n",
      "23485/23485 - 71s - loss: 22.9209 - val_loss: 20.4849\n",
      "Epoch 591/1000\n",
      "23485/23485 - 71s - loss: 22.9267 - val_loss: 20.6214\n",
      "Epoch 592/1000\n",
      "23485/23485 - 71s - loss: 22.9129 - val_loss: 20.4440\n",
      "Epoch 593/1000\n",
      "23485/23485 - 71s - loss: 22.9178 - val_loss: 20.4826\n",
      "Epoch 594/1000\n",
      "23485/23485 - 71s - loss: 22.9170 - val_loss: 20.5687\n",
      "Epoch 595/1000\n",
      "23485/23485 - 71s - loss: 22.9142 - val_loss: 20.5684\n",
      "Epoch 596/1000\n",
      "23485/23485 - 72s - loss: 22.9147 - val_loss: 20.5394\n",
      "Epoch 597/1000\n",
      "23485/23485 - 71s - loss: 22.9107 - val_loss: 20.5969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598/1000\n",
      "23485/23485 - 71s - loss: 22.9145 - val_loss: 20.7104\n",
      "Epoch 599/1000\n",
      "23485/23485 - 71s - loss: 22.9069 - val_loss: 20.5075\n",
      "Epoch 600/1000\n",
      "23485/23485 - 71s - loss: 22.9114 - val_loss: 20.5054\n",
      "Epoch 601/1000\n",
      "23485/23485 - 71s - loss: 22.9051 - val_loss: 20.6697\n",
      "Epoch 602/1000\n",
      "23485/23485 - 70s - loss: 22.9110 - val_loss: 20.6199\n",
      "Epoch 603/1000\n",
      "23485/23485 - 72s - loss: 22.8990 - val_loss: 20.3901\n",
      "Epoch 604/1000\n",
      "23485/23485 - 71s - loss: 22.9022 - val_loss: 20.5167\n",
      "Epoch 605/1000\n",
      "23485/23485 - 71s - loss: 22.8992 - val_loss: 20.4882\n",
      "Epoch 606/1000\n",
      "23485/23485 - 71s - loss: 22.8994 - val_loss: 20.6355\n",
      "Epoch 607/1000\n",
      "23485/23485 - 70s - loss: 22.8980 - val_loss: 20.5512\n",
      "Epoch 608/1000\n",
      "23485/23485 - 71s - loss: 22.8983 - val_loss: 20.5350\n",
      "Epoch 609/1000\n",
      "23485/23485 - 71s - loss: 22.8936 - val_loss: 20.3229\n",
      "Epoch 610/1000\n",
      "23485/23485 - 71s - loss: 22.9027 - val_loss: 20.2782\n",
      "Epoch 611/1000\n",
      "23485/23485 - 70s - loss: 22.8921 - val_loss: 20.5493\n",
      "Epoch 612/1000\n",
      "23485/23485 - 70s - loss: 22.8851 - val_loss: 20.5047\n",
      "Epoch 613/1000\n",
      "23485/23485 - 71s - loss: 22.8893 - val_loss: 20.3668\n",
      "Epoch 614/1000\n",
      "23485/23485 - 70s - loss: 22.8956 - val_loss: 20.5247\n",
      "Epoch 615/1000\n",
      "23485/23485 - 71s - loss: 22.8955 - val_loss: 20.4653\n",
      "Epoch 616/1000\n",
      "23485/23485 - 70s - loss: 22.8901 - val_loss: 20.5327\n",
      "Epoch 617/1000\n",
      "23485/23485 - 70s - loss: 22.8962 - val_loss: 20.3950\n",
      "Epoch 618/1000\n",
      "23485/23485 - 70s - loss: 22.8918 - val_loss: 20.6663\n",
      "Epoch 619/1000\n",
      "23485/23485 - 70s - loss: 22.8941 - val_loss: 20.7325\n",
      "Epoch 620/1000\n",
      "23485/23485 - 70s - loss: 22.8974 - val_loss: 20.5459\n",
      "Epoch 621/1000\n",
      "23485/23485 - 70s - loss: 22.8887 - val_loss: 20.6128\n",
      "Epoch 622/1000\n",
      "23485/23485 - 71s - loss: 22.8864 - val_loss: 20.7983\n",
      "Epoch 623/1000\n",
      "23485/23485 - 78s - loss: 22.8957 - val_loss: 20.4962\n",
      "Epoch 624/1000\n",
      "23485/23485 - 86s - loss: 22.8852 - val_loss: 20.4631\n",
      "Epoch 625/1000\n",
      "23485/23485 - 82s - loss: 22.8827 - val_loss: 20.5695\n",
      "Epoch 626/1000\n",
      "23485/23485 - 80s - loss: 22.8848 - val_loss: 20.4468\n",
      "Epoch 627/1000\n",
      "23485/23485 - 80s - loss: 22.8863 - val_loss: 20.5104\n",
      "Epoch 628/1000\n",
      "23485/23485 - 81s - loss: 22.8808 - val_loss: 20.7110\n",
      "Epoch 629/1000\n",
      "23485/23485 - 79s - loss: 22.8899 - val_loss: 20.4199\n",
      "Epoch 630/1000\n",
      "23485/23485 - 79s - loss: 22.8839 - val_loss: 20.6736\n",
      "Epoch 631/1000\n",
      "23485/23485 - 81s - loss: 22.8819 - val_loss: 20.7818\n",
      "Epoch 632/1000\n",
      "23485/23485 - 78s - loss: 22.8952 - val_loss: 20.7188\n",
      "Epoch 633/1000\n",
      "23485/23485 - 80s - loss: 22.8911 - val_loss: 20.6834\n",
      "Epoch 634/1000\n",
      "23485/23485 - 78s - loss: 22.8916 - val_loss: 20.5666\n",
      "Epoch 635/1000\n",
      "23485/23485 - 79s - loss: 22.8861 - val_loss: 20.5892\n",
      "Epoch 636/1000\n",
      "23485/23485 - 79s - loss: 22.8890 - val_loss: 20.6498\n",
      "Epoch 637/1000\n",
      "23485/23485 - 81s - loss: 22.8848 - val_loss: 20.5888\n",
      "Epoch 638/1000\n",
      "23485/23485 - 76s - loss: 22.8863 - val_loss: 20.7198\n",
      "Epoch 639/1000\n",
      "23485/23485 - 73s - loss: 22.8953 - val_loss: 20.5445\n",
      "Epoch 640/1000\n",
      "23485/23485 - 74s - loss: 22.8843 - val_loss: 20.4954\n",
      "Epoch 641/1000\n",
      "23485/23485 - 74s - loss: 22.8826 - val_loss: 20.5508\n",
      "Epoch 642/1000\n",
      "23485/23485 - 74s - loss: 22.8812 - val_loss: 20.5260\n",
      "Epoch 643/1000\n",
      "23485/23485 - 75s - loss: 22.8845 - val_loss: 20.3800\n",
      "Epoch 644/1000\n",
      "23485/23485 - 79s - loss: 22.8739 - val_loss: 20.5026\n",
      "Epoch 645/1000\n",
      "23485/23485 - 79s - loss: 22.8807 - val_loss: 20.3666\n",
      "Epoch 646/1000\n",
      "23485/23485 - 76s - loss: 22.8802 - val_loss: 20.4452\n",
      "Epoch 647/1000\n",
      "23485/23485 - 76s - loss: 22.8840 - val_loss: 20.6354\n",
      "Epoch 648/1000\n",
      "23485/23485 - 78s - loss: 22.8813 - val_loss: 20.3945\n",
      "Epoch 649/1000\n",
      "23485/23485 - 77s - loss: 22.8788 - val_loss: 20.4846\n",
      "Epoch 650/1000\n",
      "23485/23485 - 76s - loss: 22.8805 - val_loss: 20.4456\n",
      "Epoch 651/1000\n",
      "23485/23485 - 77s - loss: 22.8836 - val_loss: 20.3876\n",
      "Epoch 652/1000\n",
      "23485/23485 - 76s - loss: 22.8874 - val_loss: 20.5429\n",
      "Epoch 653/1000\n",
      "23485/23485 - 76s - loss: 22.8793 - val_loss: 20.5485\n",
      "Epoch 654/1000\n",
      "23485/23485 - 80s - loss: 22.8825 - val_loss: 20.6342\n",
      "Epoch 655/1000\n",
      "23485/23485 - 78s - loss: 22.8746 - val_loss: 20.8686\n",
      "Epoch 656/1000\n",
      "23485/23485 - 75s - loss: 22.8728 - val_loss: 20.4399\n",
      "Epoch 657/1000\n",
      "23485/23485 - 75s - loss: 22.8842 - val_loss: 20.4760\n",
      "Epoch 658/1000\n",
      "23485/23485 - 74s - loss: 22.8739 - val_loss: 20.5897\n",
      "Epoch 659/1000\n",
      "23485/23485 - 75s - loss: 22.8857 - val_loss: 20.3949\n",
      "Epoch 660/1000\n",
      "23485/23485 - 74s - loss: 22.8781 - val_loss: 20.4089\n",
      "Epoch 661/1000\n",
      "23485/23485 - 76s - loss: 22.8783 - val_loss: 20.6122\n",
      "Epoch 662/1000\n",
      "23485/23485 - 83s - loss: 22.8882 - val_loss: 20.3396\n",
      "Epoch 663/1000\n",
      "23485/23485 - 81s - loss: 22.8715 - val_loss: 20.5169\n",
      "Epoch 664/1000\n",
      "23485/23485 - 81s - loss: 22.8688 - val_loss: 20.5079\n",
      "Epoch 665/1000\n",
      "23485/23485 - 77s - loss: 22.8716 - val_loss: 20.6297\n",
      "Epoch 666/1000\n",
      "23485/23485 - 79s - loss: 22.8746 - val_loss: 20.3171\n",
      "Epoch 667/1000\n",
      "23485/23485 - 77s - loss: 22.8770 - val_loss: 20.3949\n",
      "Epoch 668/1000\n",
      "23485/23485 - 90s - loss: 22.8862 - val_loss: 20.3771\n",
      "Epoch 669/1000\n",
      "23485/23485 - 74s - loss: 22.8775 - val_loss: 20.4712\n",
      "Epoch 670/1000\n",
      "23485/23485 - 84s - loss: 22.8857 - val_loss: 20.5058\n",
      "Epoch 671/1000\n",
      "23485/23485 - 79s - loss: 22.8756 - val_loss: 20.6552\n",
      "Epoch 672/1000\n",
      "23485/23485 - 81s - loss: 22.8759 - val_loss: 20.4801\n",
      "Epoch 673/1000\n",
      "23485/23485 - 75s - loss: 22.8814 - val_loss: 20.5616\n",
      "Epoch 674/1000\n",
      "23485/23485 - 75s - loss: 22.8749 - val_loss: 20.6353\n",
      "Epoch 675/1000\n",
      "23485/23485 - 74s - loss: 22.8793 - val_loss: 20.4425\n",
      "Epoch 676/1000\n",
      "23485/23485 - 76s - loss: 22.8682 - val_loss: 20.5455\n",
      "Epoch 677/1000\n",
      "23485/23485 - 76s - loss: 22.8720 - val_loss: 20.6394\n",
      "Epoch 678/1000\n",
      "23485/23485 - 76s - loss: 22.8736 - val_loss: 20.4625\n",
      "Epoch 679/1000\n",
      "23485/23485 - 78s - loss: 22.8641 - val_loss: 20.5987\n",
      "Epoch 680/1000\n",
      "23485/23485 - 76s - loss: 22.8805 - val_loss: 20.6397\n",
      "Epoch 681/1000\n",
      "23485/23485 - 77s - loss: 22.8670 - val_loss: 20.6399\n",
      "Epoch 682/1000\n",
      "23485/23485 - 76s - loss: 22.8802 - val_loss: 20.5190\n",
      "Epoch 683/1000\n",
      "23485/23485 - 78s - loss: 22.8753 - val_loss: 20.5336\n",
      "Epoch 684/1000\n",
      "23485/23485 - 78s - loss: 22.8824 - val_loss: 20.5326\n",
      "Epoch 685/1000\n",
      "23485/23485 - 81s - loss: 22.8705 - val_loss: 20.5816\n",
      "Epoch 686/1000\n",
      "23485/23485 - 79s - loss: 22.8822 - val_loss: 20.5849\n",
      "Epoch 687/1000\n",
      "23485/23485 - 82s - loss: 22.8671 - val_loss: 20.5537\n",
      "Epoch 688/1000\n",
      "23485/23485 - 80s - loss: 22.8697 - val_loss: 20.6202\n",
      "Epoch 689/1000\n",
      "23485/23485 - 81s - loss: 22.8756 - val_loss: 20.6271\n",
      "Epoch 690/1000\n",
      "23485/23485 - 79s - loss: 22.8681 - val_loss: 20.5612\n",
      "Epoch 691/1000\n",
      "23485/23485 - 77s - loss: 22.8661 - val_loss: 20.3947\n",
      "Epoch 692/1000\n",
      "23485/23485 - 76s - loss: 22.8670 - val_loss: 20.5308\n",
      "Epoch 693/1000\n",
      "23485/23485 - 77s - loss: 22.8706 - val_loss: 20.5287\n",
      "Epoch 694/1000\n",
      "23485/23485 - 80s - loss: 22.8648 - val_loss: 20.5857\n",
      "Epoch 695/1000\n",
      "23485/23485 - 77s - loss: 22.8669 - val_loss: 20.5514\n",
      "Epoch 696/1000\n",
      "23485/23485 - 78s - loss: 22.8585 - val_loss: 20.5142\n",
      "Epoch 697/1000\n",
      "23485/23485 - 77s - loss: 22.8631 - val_loss: 20.5192\n",
      "Epoch 698/1000\n",
      "23485/23485 - 79s - loss: 22.8620 - val_loss: 20.4267\n",
      "Epoch 699/1000\n",
      "23485/23485 - 80s - loss: 22.8683 - val_loss: 20.6723\n",
      "Epoch 700/1000\n",
      "23485/23485 - 84s - loss: 22.8656 - val_loss: 20.6140\n",
      "Epoch 701/1000\n",
      "23485/23485 - 83s - loss: 22.8604 - val_loss: 20.4660\n",
      "Epoch 702/1000\n",
      "23485/23485 - 79s - loss: 22.8642 - val_loss: 20.5378\n",
      "Epoch 703/1000\n",
      "23485/23485 - 80s - loss: 22.8557 - val_loss: 20.4575\n",
      "Epoch 704/1000\n",
      "23485/23485 - 84s - loss: 22.8746 - val_loss: 20.5918\n",
      "Epoch 705/1000\n",
      "23485/23485 - 79s - loss: 22.8602 - val_loss: 20.2686\n",
      "Epoch 706/1000\n",
      "23485/23485 - 76s - loss: 22.8715 - val_loss: 20.4741\n",
      "Epoch 707/1000\n",
      "23485/23485 - 84s - loss: 22.8618 - val_loss: 20.4878\n",
      "Epoch 708/1000\n",
      "23485/23485 - 82s - loss: 22.8624 - val_loss: 20.5817\n",
      "Epoch 709/1000\n",
      "23485/23485 - 84s - loss: 22.8655 - val_loss: 20.5350\n",
      "Epoch 710/1000\n",
      "23485/23485 - 80s - loss: 22.8590 - val_loss: 20.6262\n",
      "Epoch 711/1000\n",
      "23485/23485 - 77s - loss: 22.8518 - val_loss: 20.5047\n",
      "Epoch 712/1000\n",
      "23485/23485 - 71s - loss: 22.8686 - val_loss: 20.3336\n",
      "Epoch 713/1000\n",
      "23485/23485 - 71s - loss: 22.8692 - val_loss: 20.6797\n",
      "Epoch 714/1000\n",
      "23485/23485 - 71s - loss: 22.8653 - val_loss: 20.3622\n",
      "Epoch 715/1000\n",
      "23485/23485 - 72s - loss: 22.8653 - val_loss: 20.8910\n",
      "Epoch 716/1000\n",
      "23485/23485 - 71s - loss: 22.8738 - val_loss: 20.4227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 717/1000\n",
      "23485/23485 - 71s - loss: 22.8680 - val_loss: 20.4508\n",
      "Epoch 718/1000\n",
      "23485/23485 - 71s - loss: 22.8701 - val_loss: 20.4909\n",
      "Epoch 719/1000\n",
      "23485/23485 - 71s - loss: 22.8717 - val_loss: 20.5306\n",
      "Epoch 720/1000\n",
      "23485/23485 - 70s - loss: 22.8635 - val_loss: 20.3103\n",
      "Epoch 721/1000\n",
      "23485/23485 - 71s - loss: 22.8534 - val_loss: 20.4867\n",
      "Epoch 722/1000\n",
      "23485/23485 - 71s - loss: 22.8589 - val_loss: 20.3454\n",
      "Epoch 723/1000\n",
      "23485/23485 - 70s - loss: 22.8609 - val_loss: 20.4491\n",
      "Epoch 724/1000\n",
      "23485/23485 - 71s - loss: 22.8665 - val_loss: 20.3130\n",
      "Epoch 725/1000\n",
      "23485/23485 - 71s - loss: 22.8671 - val_loss: 20.4733\n",
      "Epoch 726/1000\n",
      "23485/23485 - 71s - loss: 22.8612 - val_loss: 20.7764\n",
      "Epoch 727/1000\n",
      "23485/23485 - 70s - loss: 22.8682 - val_loss: 20.4306\n",
      "Epoch 728/1000\n",
      "23485/23485 - 71s - loss: 22.8606 - val_loss: 20.5554\n",
      "Epoch 729/1000\n",
      "23485/23485 - 71s - loss: 22.8614 - val_loss: 20.4211\n",
      "Epoch 730/1000\n",
      "23485/23485 - 71s - loss: 22.8667 - val_loss: 20.5843\n",
      "Epoch 731/1000\n",
      "23485/23485 - 71s - loss: 22.8700 - val_loss: 20.4656\n",
      "Epoch 732/1000\n",
      "23485/23485 - 71s - loss: 22.8656 - val_loss: 20.5519\n",
      "Epoch 733/1000\n",
      "23485/23485 - 71s - loss: 22.8739 - val_loss: 20.4339\n",
      "Epoch 734/1000\n",
      "23485/23485 - 72s - loss: 22.8568 - val_loss: 20.3824\n",
      "Epoch 735/1000\n",
      "23485/23485 - 71s - loss: 22.8605 - val_loss: 20.5712\n",
      "Epoch 736/1000\n",
      "23485/23485 - 70s - loss: 22.8622 - val_loss: 20.3915\n",
      "Epoch 737/1000\n",
      "23485/23485 - 70s - loss: 22.8650 - val_loss: 20.5195\n",
      "Epoch 738/1000\n",
      "23485/23485 - 70s - loss: 22.8660 - val_loss: 20.7762\n",
      "Epoch 739/1000\n",
      "23485/23485 - 70s - loss: 22.8521 - val_loss: 20.5382\n",
      "Epoch 740/1000\n",
      "23485/23485 - 71s - loss: 22.8547 - val_loss: 20.7509\n",
      "Epoch 741/1000\n",
      "23485/23485 - 71s - loss: 22.8684 - val_loss: 20.4538\n",
      "Epoch 742/1000\n",
      "23485/23485 - 71s - loss: 22.8643 - val_loss: 20.6212\n",
      "Epoch 743/1000\n",
      "23485/23485 - 71s - loss: 22.8588 - val_loss: 20.4925\n",
      "Epoch 744/1000\n",
      "23485/23485 - 70s - loss: 22.8622 - val_loss: 20.4040\n",
      "Epoch 745/1000\n",
      "23485/23485 - 71s - loss: 22.8546 - val_loss: 20.7022\n",
      "Epoch 746/1000\n",
      "23485/23485 - 72s - loss: 22.8551 - val_loss: 20.4647\n",
      "Epoch 747/1000\n",
      "23485/23485 - 70s - loss: 22.8578 - val_loss: 20.4917\n",
      "Epoch 748/1000\n",
      "23485/23485 - 71s - loss: 22.8495 - val_loss: 20.4619\n",
      "Epoch 749/1000\n",
      "23485/23485 - 71s - loss: 22.8617 - val_loss: 20.5940\n",
      "Epoch 750/1000\n",
      "23485/23485 - 71s - loss: 22.8587 - val_loss: 20.5752\n",
      "Epoch 751/1000\n",
      "23485/23485 - 71s - loss: 22.8613 - val_loss: 20.4811\n",
      "Epoch 752/1000\n",
      "23485/23485 - 71s - loss: 22.8649 - val_loss: 20.6134\n",
      "Epoch 753/1000\n",
      "23485/23485 - 70s - loss: 22.8533 - val_loss: 20.4233\n",
      "Epoch 754/1000\n",
      "23485/23485 - 71s - loss: 22.8613 - val_loss: 20.3766\n",
      "Epoch 755/1000\n",
      "23485/23485 - 70s - loss: 22.8545 - val_loss: 20.5288\n",
      "Epoch 756/1000\n",
      "23485/23485 - 70s - loss: 22.8569 - val_loss: 20.5815\n",
      "Epoch 757/1000\n",
      "23485/23485 - 70s - loss: 22.8632 - val_loss: 20.4813\n",
      "Epoch 758/1000\n",
      "23485/23485 - 70s - loss: 22.8498 - val_loss: 20.3506\n",
      "Epoch 759/1000\n",
      "23485/23485 - 70s - loss: 22.8584 - val_loss: 20.3500\n",
      "Epoch 760/1000\n",
      "23485/23485 - 70s - loss: 22.8491 - val_loss: 20.3304\n",
      "Epoch 761/1000\n",
      "23485/23485 - 70s - loss: 22.8627 - val_loss: 20.4097\n",
      "Epoch 762/1000\n",
      "23485/23485 - 70s - loss: 22.8540 - val_loss: 20.2678\n",
      "Epoch 763/1000\n",
      "23485/23485 - 70s - loss: 22.8559 - val_loss: 20.3301\n",
      "Epoch 764/1000\n",
      "23485/23485 - 71s - loss: 22.8533 - val_loss: 20.4926\n",
      "Epoch 765/1000\n",
      "23485/23485 - 71s - loss: 22.8624 - val_loss: 20.4134\n",
      "Epoch 766/1000\n",
      "23485/23485 - 71s - loss: 22.8576 - val_loss: 20.7117\n",
      "Epoch 767/1000\n",
      "23485/23485 - 71s - loss: 22.8577 - val_loss: 20.6633\n",
      "Epoch 768/1000\n",
      "23485/23485 - 70s - loss: 22.8529 - val_loss: 20.6296\n",
      "Epoch 769/1000\n",
      "23485/23485 - 70s - loss: 22.8567 - val_loss: 20.4125\n",
      "Epoch 770/1000\n",
      "23485/23485 - 71s - loss: 22.8487 - val_loss: 20.4431\n",
      "Epoch 771/1000\n",
      "23485/23485 - 70s - loss: 22.8494 - val_loss: 20.7269\n",
      "Epoch 772/1000\n",
      "23485/23485 - 70s - loss: 22.8617 - val_loss: 20.6870\n",
      "Epoch 773/1000\n",
      "23485/23485 - 70s - loss: 22.8453 - val_loss: 20.4703\n",
      "Epoch 774/1000\n",
      "23485/23485 - 70s - loss: 22.8601 - val_loss: 20.6906\n",
      "Epoch 775/1000\n",
      "23485/23485 - 70s - loss: 22.8487 - val_loss: 20.2815\n",
      "Epoch 776/1000\n",
      "23485/23485 - 70s - loss: 22.8577 - val_loss: 20.5187\n",
      "Epoch 777/1000\n",
      "23485/23485 - 71s - loss: 22.8539 - val_loss: 20.3751\n",
      "Epoch 778/1000\n",
      "23485/23485 - 71s - loss: 22.8502 - val_loss: 20.5984\n",
      "Epoch 779/1000\n",
      "23485/23485 - 72s - loss: 22.8440 - val_loss: 20.3831\n",
      "Epoch 780/1000\n",
      "23485/23485 - 71s - loss: 22.8601 - val_loss: 20.5281\n",
      "Epoch 781/1000\n",
      "23485/23485 - 71s - loss: 22.8604 - val_loss: 20.5080\n",
      "Epoch 782/1000\n",
      "23485/23485 - 71s - loss: 22.8494 - val_loss: 20.4782\n",
      "Epoch 783/1000\n",
      "23485/23485 - 71s - loss: 22.8486 - val_loss: 20.4070\n",
      "Epoch 784/1000\n",
      "23485/23485 - 71s - loss: 22.8507 - val_loss: 20.5694\n",
      "Epoch 785/1000\n",
      "23485/23485 - 71s - loss: 22.8617 - val_loss: 20.6747\n",
      "Epoch 786/1000\n",
      "23485/23485 - 70s - loss: 22.8620 - val_loss: 20.5332\n",
      "Epoch 787/1000\n",
      "23485/23485 - 71s - loss: 22.8446 - val_loss: 20.6586\n",
      "Epoch 788/1000\n",
      "23485/23485 - 71s - loss: 22.8545 - val_loss: 20.3283\n",
      "Epoch 789/1000\n",
      "23485/23485 - 71s - loss: 22.8483 - val_loss: 20.4271\n",
      "Epoch 790/1000\n",
      "23485/23485 - 70s - loss: 22.8500 - val_loss: 20.2908\n",
      "Epoch 791/1000\n",
      "23485/23485 - 71s - loss: 22.8473 - val_loss: 20.5189\n",
      "Epoch 792/1000\n",
      "23485/23485 - 71s - loss: 22.8468 - val_loss: 20.3803\n",
      "Epoch 793/1000\n",
      "23485/23485 - 70s - loss: 22.8539 - val_loss: 20.3359\n",
      "Epoch 794/1000\n",
      "23485/23485 - 70s - loss: 22.8530 - val_loss: 20.3814\n",
      "Epoch 795/1000\n",
      "23485/23485 - 70s - loss: 22.8518 - val_loss: 20.4592\n",
      "Epoch 796/1000\n",
      "23485/23485 - 70s - loss: 22.8398 - val_loss: 20.4098\n",
      "Epoch 797/1000\n",
      "23485/23485 - 71s - loss: 22.8522 - val_loss: 20.3034\n",
      "Epoch 798/1000\n",
      "23485/23485 - 70s - loss: 22.8509 - val_loss: 20.7463\n",
      "Epoch 799/1000\n",
      "23485/23485 - 71s - loss: 22.8580 - val_loss: 20.5538\n",
      "Epoch 800/1000\n",
      "23485/23485 - 71s - loss: 22.8412 - val_loss: 20.5956\n",
      "Epoch 801/1000\n",
      "23485/23485 - 71s - loss: 22.8552 - val_loss: 20.4407\n",
      "Epoch 802/1000\n",
      "23485/23485 - 71s - loss: 22.8518 - val_loss: 20.6171\n",
      "Epoch 803/1000\n",
      "23485/23485 - 71s - loss: 22.8497 - val_loss: 20.4977\n",
      "Epoch 804/1000\n",
      "23485/23485 - 70s - loss: 22.8426 - val_loss: 20.3006\n",
      "Epoch 805/1000\n",
      "23485/23485 - 71s - loss: 22.8577 - val_loss: 20.2692\n",
      "Epoch 806/1000\n",
      "23485/23485 - 70s - loss: 22.8467 - val_loss: 20.5097\n",
      "Epoch 807/1000\n",
      "23485/23485 - 70s - loss: 22.8458 - val_loss: 20.5537\n",
      "Epoch 808/1000\n",
      "23485/23485 - 70s - loss: 22.8423 - val_loss: 20.6044\n",
      "Epoch 809/1000\n",
      "23485/23485 - 71s - loss: 22.8440 - val_loss: 20.2953\n",
      "Epoch 810/1000\n",
      "23485/23485 - 71s - loss: 22.8473 - val_loss: 20.3589\n",
      "Epoch 811/1000\n",
      "23485/23485 - 70s - loss: 22.8403 - val_loss: 20.5690\n",
      "Epoch 812/1000\n",
      "23485/23485 - 70s - loss: 22.8508 - val_loss: 20.3700\n",
      "Epoch 813/1000\n",
      "23485/23485 - 71s - loss: 22.8501 - val_loss: 20.5160\n",
      "Epoch 814/1000\n",
      "23485/23485 - 71s - loss: 22.8449 - val_loss: 20.4157\n",
      "Epoch 815/1000\n",
      "23485/23485 - 71s - loss: 22.8460 - val_loss: 20.5512\n",
      "Epoch 816/1000\n",
      "23485/23485 - 71s - loss: 22.8442 - val_loss: 20.6969\n",
      "Epoch 817/1000\n",
      "23485/23485 - 70s - loss: 22.8434 - val_loss: 20.4936\n",
      "Epoch 818/1000\n",
      "23485/23485 - 71s - loss: 22.8417 - val_loss: 20.4278\n",
      "Epoch 819/1000\n",
      "23485/23485 - 71s - loss: 22.8457 - val_loss: 20.5703\n",
      "Epoch 820/1000\n",
      "23485/23485 - 71s - loss: 22.8516 - val_loss: 20.4841\n",
      "Epoch 821/1000\n",
      "23485/23485 - 72s - loss: 22.8403 - val_loss: 20.5687\n",
      "Epoch 822/1000\n",
      "23485/23485 - 71s - loss: 22.8506 - val_loss: 20.5495\n",
      "Epoch 823/1000\n",
      "23485/23485 - 71s - loss: 22.8523 - val_loss: 20.4645\n",
      "Epoch 824/1000\n",
      "23485/23485 - 71s - loss: 22.8363 - val_loss: 20.8030\n",
      "Epoch 825/1000\n",
      "23485/23485 - 70s - loss: 22.8338 - val_loss: 20.5641\n",
      "Epoch 826/1000\n",
      "23485/23485 - 70s - loss: 22.8504 - val_loss: 20.5676\n",
      "Epoch 827/1000\n",
      "23485/23485 - 70s - loss: 22.8376 - val_loss: 20.5104\n",
      "Epoch 828/1000\n",
      "23485/23485 - 71s - loss: 22.8403 - val_loss: 20.5411\n",
      "Epoch 829/1000\n",
      "23485/23485 - 70s - loss: 22.8453 - val_loss: 20.6813\n",
      "Epoch 830/1000\n",
      "23485/23485 - 70s - loss: 22.8337 - val_loss: 20.5960\n",
      "Epoch 831/1000\n",
      "23485/23485 - 71s - loss: 22.8461 - val_loss: 20.3936\n",
      "Epoch 832/1000\n",
      "23485/23485 - 71s - loss: 22.8445 - val_loss: 20.6161\n",
      "Epoch 833/1000\n",
      "23485/23485 - 71s - loss: 22.8408 - val_loss: 20.4100\n",
      "Epoch 834/1000\n",
      "23485/23485 - 71s - loss: 22.8389 - val_loss: 20.2680\n",
      "Epoch 835/1000\n",
      "23485/23485 - 71s - loss: 22.8363 - val_loss: 20.3377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1000\n",
      "23485/23485 - 71s - loss: 22.8389 - val_loss: 20.4109\n",
      "Epoch 837/1000\n",
      "23485/23485 - 70s - loss: 22.8421 - val_loss: 20.3596\n",
      "Epoch 838/1000\n",
      "23485/23485 - 71s - loss: 22.8478 - val_loss: 20.4310\n",
      "Epoch 839/1000\n",
      "23485/23485 - 70s - loss: 22.8474 - val_loss: 20.4675\n",
      "Epoch 840/1000\n",
      "23485/23485 - 71s - loss: 22.8321 - val_loss: 20.3071\n",
      "Epoch 841/1000\n",
      "23485/23485 - 71s - loss: 22.8448 - val_loss: 20.5273\n",
      "Epoch 842/1000\n",
      "23485/23485 - 71s - loss: 22.8413 - val_loss: 20.5211\n",
      "Epoch 843/1000\n",
      "23485/23485 - 71s - loss: 22.8525 - val_loss: 20.3335\n",
      "Epoch 844/1000\n",
      "23485/23485 - 71s - loss: 22.8439 - val_loss: 20.5071\n",
      "Epoch 845/1000\n",
      "23485/23485 - 71s - loss: 22.8401 - val_loss: 20.5419\n",
      "Epoch 846/1000\n",
      "23485/23485 - 71s - loss: 22.8415 - val_loss: 20.3312\n",
      "Epoch 847/1000\n",
      "23485/23485 - 70s - loss: 22.8380 - val_loss: 20.2956\n",
      "Epoch 848/1000\n",
      "23485/23485 - 70s - loss: 22.8349 - val_loss: 20.5435\n",
      "Epoch 849/1000\n",
      "23485/23485 - 71s - loss: 22.8467 - val_loss: 20.4035\n",
      "Epoch 850/1000\n",
      "23485/23485 - 70s - loss: 22.8457 - val_loss: 20.4014\n",
      "Epoch 851/1000\n",
      "23485/23485 - 70s - loss: 22.8471 - val_loss: 20.2750\n",
      "Epoch 852/1000\n",
      "23485/23485 - 70s - loss: 22.8337 - val_loss: 20.3530\n",
      "Epoch 853/1000\n",
      "23485/23485 - 71s - loss: 22.8353 - val_loss: 20.5896\n",
      "Epoch 854/1000\n",
      "23485/23485 - 71s - loss: 22.8375 - val_loss: 20.3998\n",
      "Epoch 855/1000\n",
      "23485/23485 - 71s - loss: 22.8316 - val_loss: 20.3067\n",
      "Epoch 856/1000\n",
      "23485/23485 - 71s - loss: 22.8367 - val_loss: 20.1652\n",
      "Epoch 857/1000\n",
      "23485/23485 - 71s - loss: 22.8348 - val_loss: 20.4368\n",
      "Epoch 858/1000\n",
      "23485/23485 - 71s - loss: 22.8372 - val_loss: 20.3352\n",
      "Epoch 859/1000\n",
      "23485/23485 - 71s - loss: 22.8307 - val_loss: 20.3946\n",
      "Epoch 860/1000\n",
      "23485/23485 - 71s - loss: 22.8414 - val_loss: 20.3168\n",
      "Epoch 861/1000\n",
      "23485/23485 - 71s - loss: 22.8344 - val_loss: 20.2847\n",
      "Epoch 862/1000\n",
      "23485/23485 - 70s - loss: 22.8318 - val_loss: 20.3901\n",
      "Epoch 863/1000\n",
      "23485/23485 - 70s - loss: 22.8365 - val_loss: 20.5053\n",
      "Epoch 864/1000\n",
      "23485/23485 - 71s - loss: 22.8436 - val_loss: 20.4319\n",
      "Epoch 865/1000\n",
      "23485/23485 - 71s - loss: 22.8298 - val_loss: 20.2996\n",
      "Epoch 866/1000\n",
      "23485/23485 - 70s - loss: 22.8309 - val_loss: 20.4070\n",
      "Epoch 867/1000\n",
      "23485/23485 - 70s - loss: 22.8385 - val_loss: 20.3647\n",
      "Epoch 868/1000\n",
      "23485/23485 - 70s - loss: 22.8377 - val_loss: 20.3368\n",
      "Epoch 869/1000\n",
      "23485/23485 - 71s - loss: 22.8288 - val_loss: 20.5090\n",
      "Epoch 870/1000\n",
      "23485/23485 - 71s - loss: 22.8357 - val_loss: 20.5153\n",
      "Epoch 871/1000\n",
      "23485/23485 - 71s - loss: 22.8289 - val_loss: 20.4155\n",
      "Epoch 872/1000\n",
      "23485/23485 - 71s - loss: 22.8344 - val_loss: 20.3905\n",
      "Epoch 873/1000\n",
      "23485/23485 - 71s - loss: 22.8129 - val_loss: 20.2664\n",
      "Epoch 874/1000\n",
      "23485/23485 - 71s - loss: 22.8125 - val_loss: 20.3713\n",
      "Epoch 875/1000\n",
      "23485/23485 - 71s - loss: 22.8136 - val_loss: 20.2410\n",
      "Epoch 876/1000\n",
      "23485/23485 - 71s - loss: 22.8190 - val_loss: 20.2903\n",
      "Epoch 877/1000\n",
      "23485/23485 - 72s - loss: 22.8099 - val_loss: 20.2753\n",
      "Epoch 878/1000\n",
      "23485/23485 - 85s - loss: 22.7986 - val_loss: 20.4140\n",
      "Epoch 879/1000\n",
      "23485/23485 - 76s - loss: 22.8084 - val_loss: 20.5148\n",
      "Epoch 880/1000\n",
      "23485/23485 - 70s - loss: 22.7995 - val_loss: 20.2220\n",
      "Epoch 881/1000\n",
      "23485/23485 - 72s - loss: 22.8016 - val_loss: 20.4794\n",
      "Epoch 882/1000\n",
      "23485/23485 - 71s - loss: 22.7966 - val_loss: 20.2238\n",
      "Epoch 883/1000\n",
      "23485/23485 - 70s - loss: 22.7769 - val_loss: 20.1811\n",
      "Epoch 884/1000\n",
      "23485/23485 - 71s - loss: 22.7688 - val_loss: 20.3051\n",
      "Epoch 885/1000\n",
      "23485/23485 - 71s - loss: 22.7543 - val_loss: 20.1625\n",
      "Epoch 886/1000\n",
      "23485/23485 - 71s - loss: 22.7539 - val_loss: 20.3361\n",
      "Epoch 887/1000\n",
      "23485/23485 - 70s - loss: 22.7561 - val_loss: 20.1668\n",
      "Epoch 888/1000\n",
      "23485/23485 - 71s - loss: 22.7552 - val_loss: 20.5011\n",
      "Epoch 889/1000\n",
      "23485/23485 - 71s - loss: 22.7482 - val_loss: 20.2629\n",
      "Epoch 890/1000\n",
      "23485/23485 - 71s - loss: 22.7494 - val_loss: 20.2290\n",
      "Epoch 891/1000\n",
      "23485/23485 - 71s - loss: 22.7419 - val_loss: 20.5029\n",
      "Epoch 892/1000\n",
      "23485/23485 - 71s - loss: 22.7382 - val_loss: 20.2004\n",
      "Epoch 893/1000\n",
      "23485/23485 - 71s - loss: 22.7386 - val_loss: 20.2443\n",
      "Epoch 894/1000\n",
      "23485/23485 - 72s - loss: 22.7416 - val_loss: 20.4312\n",
      "Epoch 895/1000\n",
      "23485/23485 - 71s - loss: 22.7331 - val_loss: 20.2027\n",
      "Epoch 896/1000\n",
      "23485/23485 - 70s - loss: 22.7222 - val_loss: 20.5163\n",
      "Epoch 897/1000\n",
      "23485/23485 - 71s - loss: 22.7237 - val_loss: 20.2568\n",
      "Epoch 898/1000\n",
      "23485/23485 - 71s - loss: 22.7327 - val_loss: 20.4046\n",
      "Epoch 899/1000\n",
      "23485/23485 - 71s - loss: 22.7181 - val_loss: 20.4276\n",
      "Epoch 900/1000\n",
      "23485/23485 - 71s - loss: 22.7308 - val_loss: 20.2516\n",
      "Epoch 901/1000\n",
      "23485/23485 - 71s - loss: 22.7234 - val_loss: 20.1945\n",
      "Epoch 902/1000\n",
      "23485/23485 - 71s - loss: 22.7173 - val_loss: 20.3646\n",
      "Epoch 903/1000\n",
      "23485/23485 - 70s - loss: 22.7210 - val_loss: 20.1973\n",
      "Epoch 904/1000\n",
      "23485/23485 - 71s - loss: 22.7083 - val_loss: 20.4062\n",
      "Epoch 905/1000\n",
      "23485/23485 - 70s - loss: 22.7165 - val_loss: 20.1107\n",
      "Epoch 906/1000\n",
      "23485/23485 - 70s - loss: 22.7063 - val_loss: 20.1880\n",
      "Epoch 907/1000\n",
      "23485/23485 - 71s - loss: 22.6990 - val_loss: 20.2644\n",
      "Epoch 908/1000\n",
      "23485/23485 - 70s - loss: 22.7114 - val_loss: 20.3056\n",
      "Epoch 909/1000\n",
      "23485/23485 - 70s - loss: 22.7071 - val_loss: 20.2955\n",
      "Epoch 910/1000\n",
      "23485/23485 - 70s - loss: 22.7106 - val_loss: 20.0625\n",
      "Epoch 911/1000\n",
      "23485/23485 - 70s - loss: 22.7020 - val_loss: 20.1730\n",
      "Epoch 912/1000\n",
      "23485/23485 - 70s - loss: 22.6867 - val_loss: 20.2216\n",
      "Epoch 913/1000\n",
      "23485/23485 - 71s - loss: 22.6817 - val_loss: 20.4275\n",
      "Epoch 914/1000\n",
      "23485/23485 - 71s - loss: 22.6848 - val_loss: 20.6950\n",
      "Epoch 915/1000\n",
      "23485/23485 - 71s - loss: 22.6878 - val_loss: 20.2842\n",
      "Epoch 916/1000\n",
      "23485/23485 - 71s - loss: 22.6739 - val_loss: 20.0819\n",
      "Epoch 917/1000\n",
      "23485/23485 - 70s - loss: 22.6756 - val_loss: 20.0894\n",
      "Epoch 918/1000\n",
      "23485/23485 - 71s - loss: 22.6720 - val_loss: 20.2492\n",
      "Epoch 919/1000\n",
      "23485/23485 - 71s - loss: 22.6674 - val_loss: 20.1633\n",
      "Epoch 920/1000\n",
      "23485/23485 - 70s - loss: 22.6586 - val_loss: 20.2180\n",
      "Epoch 921/1000\n",
      "23485/23485 - 70s - loss: 22.6586 - val_loss: 20.2050\n",
      "Epoch 922/1000\n",
      "23485/23485 - 71s - loss: 22.6532 - val_loss: 20.1740\n",
      "Epoch 923/1000\n",
      "23485/23485 - 71s - loss: 22.6457 - val_loss: 20.2423\n",
      "Epoch 924/1000\n",
      "23485/23485 - 71s - loss: 22.6522 - val_loss: 20.2589\n",
      "Epoch 925/1000\n",
      "23485/23485 - 71s - loss: 22.6419 - val_loss: 20.1476\n",
      "Epoch 926/1000\n",
      "23485/23485 - 70s - loss: 22.6451 - val_loss: 20.1860\n",
      "Epoch 927/1000\n",
      "23485/23485 - 71s - loss: 22.6391 - val_loss: 20.1791\n",
      "Epoch 928/1000\n",
      "23485/23485 - 71s - loss: 22.6298 - val_loss: 20.0684\n",
      "Epoch 929/1000\n",
      "23485/23485 - 71s - loss: 22.6412 - val_loss: 20.2030\n",
      "Epoch 930/1000\n",
      "23485/23485 - 71s - loss: 22.6315 - val_loss: 20.2219\n",
      "Epoch 931/1000\n",
      "23485/23485 - 71s - loss: 22.6263 - val_loss: 20.3800\n",
      "Epoch 932/1000\n",
      "23485/23485 - 70s - loss: 22.6282 - val_loss: 20.2955\n",
      "Epoch 933/1000\n",
      "23485/23485 - 71s - loss: 22.6350 - val_loss: 20.5085\n",
      "Epoch 934/1000\n",
      "23485/23485 - 71s - loss: 22.6323 - val_loss: 20.3497\n",
      "Epoch 935/1000\n",
      "23485/23485 - 70s - loss: 22.6327 - val_loss: 20.5961\n",
      "Epoch 936/1000\n",
      "23485/23485 - 70s - loss: 22.6287 - val_loss: 20.2804\n",
      "Epoch 937/1000\n",
      "23485/23485 - 70s - loss: 22.6326 - val_loss: 20.3502\n",
      "Epoch 938/1000\n",
      "23485/23485 - 71s - loss: 22.6247 - val_loss: 20.2450\n",
      "Epoch 939/1000\n",
      "23485/23485 - 70s - loss: 22.6237 - val_loss: 20.2137\n",
      "Epoch 940/1000\n",
      "23485/23485 - 71s - loss: 22.6225 - val_loss: 20.2011\n",
      "Epoch 941/1000\n",
      "23485/23485 - 71s - loss: 22.6133 - val_loss: 20.2336\n",
      "Epoch 942/1000\n",
      "23485/23485 - 70s - loss: 22.6180 - val_loss: 20.4665\n",
      "Epoch 943/1000\n",
      "23485/23485 - 70s - loss: 22.6196 - val_loss: 20.2408\n",
      "Epoch 944/1000\n",
      "23485/23485 - 71s - loss: 22.6109 - val_loss: 20.6279\n",
      "Epoch 945/1000\n",
      "23485/23485 - 70s - loss: 22.6077 - val_loss: 20.3151\n",
      "Epoch 946/1000\n",
      "23485/23485 - 71s - loss: 22.6067 - val_loss: 20.2562\n",
      "Epoch 947/1000\n",
      "23485/23485 - 71s - loss: 22.5985 - val_loss: 20.6226\n",
      "Epoch 948/1000\n",
      "23485/23485 - 71s - loss: 22.6005 - val_loss: 20.3726\n",
      "Epoch 949/1000\n",
      "23485/23485 - 70s - loss: 22.5967 - val_loss: 20.3795\n",
      "Epoch 950/1000\n",
      "23485/23485 - 72s - loss: 22.5992 - val_loss: 20.2741\n",
      "Epoch 951/1000\n",
      "23485/23485 - 71s - loss: 22.5898 - val_loss: 20.3463\n",
      "Epoch 952/1000\n",
      "23485/23485 - 71s - loss: 22.5857 - val_loss: 20.1026\n",
      "Epoch 953/1000\n",
      "23485/23485 - 71s - loss: 22.5862 - val_loss: 20.2718\n",
      "Epoch 954/1000\n",
      "23485/23485 - 71s - loss: 22.5790 - val_loss: 20.3479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 955/1000\n",
      "23485/23485 - 71s - loss: 22.5727 - val_loss: 20.2883\n",
      "Epoch 956/1000\n",
      "23485/23485 - 70s - loss: 22.5800 - val_loss: 20.2731\n",
      "Epoch 957/1000\n",
      "23485/23485 - 71s - loss: 22.5738 - val_loss: 20.2407\n",
      "Epoch 958/1000\n",
      "23485/23485 - 71s - loss: 22.5667 - val_loss: 20.3917\n",
      "Epoch 959/1000\n",
      "23485/23485 - 71s - loss: 22.5716 - val_loss: 20.0477\n",
      "Epoch 960/1000\n",
      "23485/23485 - 70s - loss: 22.5695 - val_loss: 20.1499\n",
      "Epoch 961/1000\n",
      "23485/23485 - 70s - loss: 22.5628 - val_loss: 20.3846\n",
      "Epoch 962/1000\n",
      "23485/23485 - 70s - loss: 22.5601 - val_loss: 20.1169\n",
      "Epoch 963/1000\n",
      "23485/23485 - 71s - loss: 22.5531 - val_loss: 20.3899\n",
      "Epoch 964/1000\n",
      "23485/23485 - 71s - loss: 22.5587 - val_loss: 20.1628\n",
      "Epoch 965/1000\n",
      "23485/23485 - 71s - loss: 22.5505 - val_loss: 20.1944\n",
      "Epoch 966/1000\n",
      "23485/23485 - 71s - loss: 22.5478 - val_loss: 20.2386\n",
      "Epoch 967/1000\n",
      "23485/23485 - 71s - loss: 22.5389 - val_loss: 20.3878\n",
      "Epoch 968/1000\n",
      "23485/23485 - 71s - loss: 22.5397 - val_loss: 20.3268\n",
      "Epoch 969/1000\n",
      "23485/23485 - 71s - loss: 22.5303 - val_loss: 20.4042\n",
      "Epoch 970/1000\n",
      "23485/23485 - 71s - loss: 22.5395 - val_loss: 20.2234\n",
      "Epoch 971/1000\n",
      "23485/23485 - 71s - loss: 22.5315 - val_loss: 20.0847\n",
      "Epoch 972/1000\n",
      "23485/23485 - 71s - loss: 22.5380 - val_loss: 20.1519\n",
      "Epoch 973/1000\n",
      "23485/23485 - 71s - loss: 22.5300 - val_loss: 20.2686\n",
      "Epoch 974/1000\n",
      "23485/23485 - 71s - loss: 22.5344 - val_loss: 20.1833\n",
      "Epoch 975/1000\n",
      "23485/23485 - 71s - loss: 22.5255 - val_loss: 20.1569\n",
      "Epoch 976/1000\n",
      "23485/23485 - 71s - loss: 22.5299 - val_loss: 20.1932\n",
      "Epoch 977/1000\n",
      "23485/23485 - 71s - loss: 22.5284 - val_loss: 20.2860\n",
      "Epoch 978/1000\n",
      "23485/23485 - 71s - loss: 22.5239 - val_loss: 20.4293\n",
      "Epoch 979/1000\n",
      "23485/23485 - 71s - loss: 22.5118 - val_loss: 20.3527\n",
      "Epoch 980/1000\n",
      "23485/23485 - 71s - loss: 22.5130 - val_loss: 20.2788\n",
      "Epoch 981/1000\n",
      "23485/23485 - 71s - loss: 22.5123 - val_loss: 20.2435\n",
      "Epoch 982/1000\n",
      "23485/23485 - 70s - loss: 22.5166 - val_loss: 20.2248\n",
      "Epoch 983/1000\n",
      "23485/23485 - 70s - loss: 22.5206 - val_loss: 20.0983\n",
      "Epoch 984/1000\n",
      "23485/23485 - 71s - loss: 22.5126 - val_loss: 20.1209\n",
      "Epoch 985/1000\n",
      "23485/23485 - 71s - loss: 22.5073 - val_loss: 20.3100\n",
      "Epoch 986/1000\n",
      "23485/23485 - 71s - loss: 22.5024 - val_loss: 20.1385\n",
      "Epoch 987/1000\n",
      "23485/23485 - 71s - loss: 22.5062 - val_loss: 20.4627\n",
      "Epoch 988/1000\n",
      "23485/23485 - 70s - loss: 22.4998 - val_loss: 20.2168\n",
      "Epoch 989/1000\n",
      "23485/23485 - 70s - loss: 22.5108 - val_loss: 20.2651\n",
      "Epoch 990/1000\n",
      "23485/23485 - 71s - loss: 22.4994 - val_loss: 20.0602\n",
      "Epoch 991/1000\n",
      "23485/23485 - 71s - loss: 22.5075 - val_loss: 20.2830\n",
      "Epoch 992/1000\n",
      "23485/23485 - 71s - loss: 22.4940 - val_loss: 20.5856\n",
      "Epoch 993/1000\n",
      "23485/23485 - 71s - loss: 22.5020 - val_loss: 20.4527\n",
      "Epoch 994/1000\n",
      "23485/23485 - 71s - loss: 22.4908 - val_loss: 20.2322\n",
      "Epoch 995/1000\n",
      "23485/23485 - 71s - loss: 22.4939 - val_loss: 20.2515\n",
      "Epoch 996/1000\n",
      "23485/23485 - 71s - loss: 22.4993 - val_loss: 20.3496\n",
      "Epoch 997/1000\n",
      "23485/23485 - 71s - loss: 22.4883 - val_loss: 20.4581\n",
      "Epoch 998/1000\n",
      "23485/23485 - 70s - loss: 22.4938 - val_loss: 20.0916\n",
      "Epoch 999/1000\n",
      "23485/23485 - 70s - loss: 22.4934 - val_loss: 20.3621\n",
      "Epoch 1000/1000\n",
      "23485/23485 - 70s - loss: 22.4874 - val_loss: 20.4807\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# train autoencoder for classification with no compression in the bottleneck layer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "n_inputs = X_train.shape[1]\n",
    "# define encoder\n",
    "visible = Input(shape=(n_inputs,))\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs/2)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# encoder level 3\n",
    "e = Dense(n_inputs/4)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "# bottleneck\n",
    "n_bottleneck = n_inputs/4\n",
    "#decoder\n",
    "encoder = Dense(n_bottleneck,activation='relu')(e)\n",
    "# define decoder, level 1\n",
    "d = Dense(n_inputs/4)(encoder)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# define decoder, level 1\n",
    "d = Dense(n_inputs/2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# output layer\n",
    "decoder = Dense(n_inputs, activation='linear')(d)\n",
    "# define autoencoder model\n",
    "autoencoder_model = Model(inputs=visible, outputs=decoder)\n",
    "autoencoder_model.compile(optimizer='adam', loss='mse')\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = autoencoder_model.fit(X_train, X_train, epochs=1000, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "encoder_model = Model(inputs=visible, outputs=encoder, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Layer\n",
    "# from keras.layers import InputSpec\n",
    "# from keras import backend as K\n",
    "# !pip install Keras\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import InputSpec\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D \n",
    "from tensorflow.keras import backend as K \n",
    "# #from keras.engine.topology import Layer\n",
    "# from keras import initializers, regularizers, constraints\n",
    "\n",
    "# from keras.layers import Dense, Input, LSTM, Bidirectional, Activation, Conv1D, GRU, TimeDistributed\n",
    "# from keras.layers import Dropout, Embedding, GlobalMaxPooling1D, MaxPooling1D, Add, Flatten, SpatialDropout1D\n",
    "# from keras.layers import GlobalAveragePooling1D, BatchNormalization, concatenate\n",
    "# from keras.layers import Reshape, merge, Concatenate, Lambda, Average\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.initializers import Constant\n",
    "# from keras.layers.merge import add\n",
    "\n",
    "class ClusteringLayer(Layer):\n",
    "    \"\"\"\n",
    "    Clustering layer converts input sample (feature) to soft label.\n",
    "\n",
    "    # Example\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=10))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters: number of clusters.\n",
    "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "        alpha: degrees of freedom parameter in Student's t-distribution. Default to 1.0.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(n_samples, n_features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.        \n",
    "                 q_ij = 1/(1+dist(x_i, _j)^2), then normalize it.\n",
    "                 q_ij can be interpreted as the probability of assigning sample i to cluster j.\n",
    "                 (i.e., a soft assignment)\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters=250\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder_model.output)\n",
    "model = Model(inputs=encoder_model.input, outputs=clustering_layer)\n",
    "model.compile(optimizer='sgd', loss='kld')\n",
    "# Initialize cluster centers using k-means.\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder_model.predict(X_train))\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(individual, data):\n",
    "    temp=0;\n",
    "    cNum=1\n",
    "    for x in data:\n",
    "        if temp < x['score']:\n",
    "            temp=x['score']\n",
    "            cNum=x['clusterNum']\n",
    "    return cNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clusterNum': 2, 'score': 0.08279703}\n",
      "{'clusterNum': 3, 'score': 0.065472275}\n",
      "{'clusterNum': 4, 'score': 0.052816484}\n",
      "{'clusterNum': 5, 'score': 0.033827476}\n",
      "{'clusterNum': 6, 'score': 0.031714022}\n",
      "{'clusterNum': 7, 'score': 0.03325826}\n",
      "{'clusterNum': 8, 'score': 0.030340286}\n",
      "{'clusterNum': 9, 'score': 0.026403513}\n",
      "{'clusterNum': 10, 'score': 0.024153903}\n",
      "{'clusterNum': 11, 'score': 0.020815453}\n",
      "{'clusterNum': 12, 'score': 0.023682274}\n",
      "{'clusterNum': 13, 'score': 0.018991252}\n",
      "{'clusterNum': 14, 'score': 0.020513605}\n",
      "{'clusterNum': 15, 'score': 0.020326935}\n",
      "{'clusterNum': 16, 'score': 0.019100837}\n",
      "{'clusterNum': 17, 'score': 0.018145313}\n",
      "{'clusterNum': 18, 'score': 0.019966992}\n",
      "{'clusterNum': 19, 'score': 0.017728714}\n",
      "{'clusterNum': 20, 'score': 0.017355058}\n",
      "{'clusterNum': 21, 'score': 0.018310202}\n",
      "{'clusterNum': 22, 'score': 0.016394017}\n",
      "{'clusterNum': 23, 'score': 0.015835784}\n",
      "{'clusterNum': 24, 'score': 0.011750261}\n",
      "{'clusterNum': 25, 'score': 0.0175289}\n",
      "{'clusterNum': 26, 'score': 0.018159455}\n",
      "{'clusterNum': 27, 'score': 0.014023866}\n",
      "{'clusterNum': 28, 'score': 0.015938485}\n",
      "{'clusterNum': 29, 'score': 0.017982978}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pyeasyga' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-e257ffe6bc31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'clusterNum'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#initialise the GA with data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyeasyga\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneticAlgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mga\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness\u001b[0m               \u001b[1;31m# set the GA's fitness function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mga\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                    \u001b[1;31m# run the GA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyeasyga' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "X=encoder_model.predict(df_[0:2000])\n",
    "#print(X.head(5))\n",
    "start = time.time()\n",
    "arr=[];\n",
    "for i in range(2,30):\n",
    "    cluster_labels = KMeans(n_clusters=i, init='k-means++').fit_predict(X)\n",
    "    arr.append({'clusterNum': i , 'score': silhouette_score(X, cluster_labels)})\n",
    "    print({'clusterNum': i , 'score': silhouette_score(X, cluster_labels)})\n",
    "#initialise the GA with data\n",
    "ga = pyeasyga.GeneticAlgorithm(arr)\n",
    "ga.fitness_function = fitness               # set the GA's fitness function\n",
    "ga.run()                                    # run the GA\n",
    "print(ga.best_individual())\n",
    "end = time.time()\n",
    "print(\"Time for executing Kmeans++ with GA\")\n",
    "print(end - start)\n",
    "print(\" in seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[218.35074, 238.46147, 209.62473, ..., 158.76715, 297.82574,\n",
       "        128.0083 ],\n",
       "       [242.47176, 225.0784 , 179.73982, ..., 173.0789 , 325.35913,\n",
       "        153.7043 ],\n",
       "       [152.77275, 179.80351, 150.23215, ..., 141.12296, 304.0989 ,\n",
       "         71.23606],\n",
       "       ...,\n",
       "       [127.69785, 173.18985, 138.73279, ..., 225.3144 , 351.1016 ,\n",
       "         96.55894],\n",
       "       [207.21248, 139.05693, 132.87915, ..., 124.99063, 349.92264,\n",
       "        170.51465],\n",
       "       [165.12537, 168.60078, 185.4943 , ..., 173.34608, 277.58966,\n",
       "        156.5632 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# computing an auxiliary target distribution\n",
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.T / weight.sum(1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26095</th>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12902</th>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9683</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26003</th>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34863</th>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13670</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26092</th>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36032</th>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22079 rows  300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  290  291  292  \\\n",
       "1537    29   31   25   25   31   29   29   29   25   25  ...   25   31   29   \n",
       "26095   29   12   31   25   12   29   25   31   29   25  ...   12   31   29   \n",
       "12902   29   31   29   31   12   25   29   31   31   29  ...   31   25   12   \n",
       "9683    29   29   12   31   31   29   25   25   25   25  ...   25   29   29   \n",
       "26003   12   29   31   29   25   29   29   25   25   31  ...   29   29   25   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "34863   29   25   25   25   25   29   25   25   12   12  ...   31   29   31   \n",
       "13670   12   12   29   31   25   31   29   29   25   31  ...   31   12   29   \n",
       "26092   25   31   12   29   31   31   29   25   29   12  ...   29   25   31   \n",
       "36032   25   12   25   12   29   25   25   12   25   25  ...   29   31   31   \n",
       "6135    25   25   29   12   25   29   12   25   29   29  ...   25   29   29   \n",
       "\n",
       "       293  294  295  296  297  298  299  \n",
       "1537    29   25   25   25   29   31   29  \n",
       "26095   29   25   29   25   29   12   25  \n",
       "12902   12   25   29   29   29   25   12  \n",
       "9683    29   25   29   29   25   25   31  \n",
       "26003   31   29   12   31   29   12   29  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "34863   25   29   12   25   12   29   29  \n",
       "13670   12   12   25   25   31   25   31  \n",
       "26092   29   29   31   25   25   31   29  \n",
       "36032   25   25   29   29   25   25   25  \n",
       "6135    25   29   25   29   12   25   29  \n",
       "\n",
       "[22079 rows x 300 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "q = model.predict(X_test, verbose=0)\n",
    "p = target_distribution(q) \n",
    "y_pred = q.argmax(1)\n",
    "\n",
    "#score = silhouette_score(X_test, y_pred, metric='euclidean')\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3851"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[X_test['cluster']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mariavl\\anaconda3\\envs\\dev_env\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "157    CCCTTTGTCGAGCATCCCGGTCCAGCCCAGCGCGCGCAATCGTGGT...\n",
       "157    CCCTTTGTCGAGCATCCCGGTCCAGCCCAGCGCGCGCAATCGTGGT...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['cluster']=y_pred\n",
    "result=X_test['cluster']\n",
    "df_not_transform[0][157]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1537     1\n",
       "26095    1\n",
       "12902    0\n",
       "9683     1\n",
       "26003    1\n",
       "        ..\n",
       "34863    1\n",
       "13670    1\n",
       "26092    1\n",
       "36032    0\n",
       "6135     1\n",
       "Name: cluster, Length: 22079, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score = silhouette_score(X_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
